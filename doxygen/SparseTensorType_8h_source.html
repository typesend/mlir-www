<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: include/mlir/Dialect/SparseTensor/IR/SparseTensorType.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">17.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_5654f77406fb9ceec87e68ef828ceea2.html">mlir</a></li><li class="navelem"><a class="el" href="dir_d07a6fac82475a065a3b2953573f00a0.html">Dialect</a></li><li class="navelem"><a class="el" href="dir_7c9e596b47e1c22c48d5e546122486f8.html">SparseTensor</a></li><li class="navelem"><a class="el" href="dir_1d62783966c31f9bfe0b6de9057e0d76.html">IR</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">SparseTensorType.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="SparseTensorType_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===- SparseTensorType.h - Wrapper around RankedTensorType -----*- C++ -*-===//</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">// This header defines the `SparseTensorType` wrapper class.</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160; </div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#ifndef MLIR_DIALECT_SPARSETENSOR_IR_SPARSETENSORTYPE_H_</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#define MLIR_DIALECT_SPARSETENSOR_IR_SPARSETENSORTYPE_H_</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160; </div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h.html">mlir/Dialect/SparseTensor/IR/SparseTensor.h</a>&quot;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160; </div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacemlir.html">mlir</a> {</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="keyword">namespace </span>sparse_tensor {</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160; </div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span><span class="comment"></span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment">/// A wrapper around `RankedTensorType`, which has three goals:</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">/// (1) To provide a uniform API for querying aspects of sparse-tensor</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment">/// types; in particular, to make the &quot;dimension&quot; vs &quot;level&quot; distinction</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment">/// overt (i.e., explicit everywhere).  Thus, throughout the sparse-compiler</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">/// this class should be preferred over using `RankedTensorType` or</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment">/// `ShapedType` directly, since the methods of the latter do not make</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment">/// the &quot;dimension&quot; vs &quot;level&quot; distinction overt.</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment">/// (2) To provide a uniform abstraction over both sparse-tensor</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">/// types (i.e., `RankedTensorType` with `SparseTensorEncodingAttr`)</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">/// and dense-tensor types (i.e., `RankedTensorType` without an encoding).</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment">/// That is, we want to manipulate dense-tensor types using the same API</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">/// that we use for manipulating sparse-tensor types; both to keep the</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment">/// &quot;dimension&quot; vs &quot;level&quot; distinction overt, and to avoid needing to</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">/// handle certain cases specially in the sparse-compiler.</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">/// (3) To provide uniform handling of &quot;defaults&quot;.  In particular</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">/// this means that dense-tensors should always return the same answers</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">/// as sparse-tensors with a default encoding.  But it additionally means</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">/// that the answers should be normalized, so that there&#39;s no way to</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment">/// distinguish between non-provided data (which is filled in by default)</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment">/// vs explicitly-provided data which equals the defaults.</span></div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">   46</a></span>&#160;<span class="comment"></span><span class="keyword">class </span><a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> {</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="keyword">public</span>:</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;  <span class="comment">// We memoize `lvlRank` and `dim2lvl` to avoid repeating the</span></div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;  <span class="comment">// conditionals throughout the rest of the class.</span></div>
<div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a93121d975f00b0b379c15f6f98de4c83">   50</a></span>&#160;  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a93121d975f00b0b379c15f6f98de4c83">SparseTensorType</a>(RankedTensorType rtp)</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;      : rtp(rtp), enc(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a90cf107e240044ac0fbeb952ea3ae0f0">getSparseTensorEncoding</a>(rtp)),</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        lvlRank(enc ? enc.<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab08f577afef29840b7caf3d0be2c793f">getLvlRank</a>() : <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">getDimRank</a>()),</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        dim2lvl(enc.hasIdDimOrdering() ? <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a>() : enc.getDimOrdering()) {</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    assert(rtp &amp;&amp; <span class="stringliteral">&quot;got null RankedTensorType&quot;</span>);</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    assert((!<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">isIdentity</a>() || <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">getDimRank</a>() == lvlRank) &amp;&amp; <span class="stringliteral">&quot;Rank mismatch&quot;</span>);</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  }</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160; </div>
<div class="line"><a name="l00058"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a23343ec0bd74c0053ac63a606bb9c5d5">   58</a></span>&#160;  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a23343ec0bd74c0053ac63a606bb9c5d5">SparseTensorType</a>(ShapedType stp, SparseTensorEncodingAttr enc)</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;      : <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a>(</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;            RankedTensorType::<a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">get</a>(stp.<a class="code" href="Traits_8cpp.html#af226ab56dcfee54df5967680ce409c04">getShape</a>(), stp.<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1b1978fe33f8c6d90427aec0bb593f76">getElementType</a>(), enc)) {}</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160; </div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;  <span class="comment">// Copy-assignment would be implicitly deleted (because our fields</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;  <span class="comment">// are const), so we explicitly delete it for clarity.</span></div>
<div class="line"><a name="l00064"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af4d830b06b63a2f61566aaf98e9a868b">   64</a></span>&#160;  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af4d830b06b63a2f61566aaf98e9a868b">operator=</a>(<span class="keyword">const</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;  <span class="comment">// So we must explicitly define the copy-ctor to silence -Wdeprecated-copy.</span></div>
<div class="line"><a name="l00066"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5b5f50ad4b2427cc6270e8d8cfc18c44">   66</a></span>&#160;  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5b5f50ad4b2427cc6270e8d8cfc18c44">SparseTensorType</a>(<span class="keyword">const</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;) = <span class="keywordflow">default</span>;</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">  /// Constructs a new `SparseTensorType` with the same dimension-shape</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">  /// and element type, but with the encoding replaced by the given encoding.</span></div>
<div class="line"><a name="l00070"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a53f4e7b6bfb6fb188b9aef8d26bacfdd">   70</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a53f4e7b6bfb6fb188b9aef8d26bacfdd">withEncoding</a>(SparseTensorEncodingAttr newEnc)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a93121d975f00b0b379c15f6f98de4c83">SparseTensorType</a>(rtp, newEnc);</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;  }</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">  /// Constructs a new `SparseTensorType` with the same dimension-shape</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">  /// and element type, but with the encoding replaced by</span></div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">  /// `getEncoding().withoutOrdering()`.</span></div>
<div class="line"><a name="l00077"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a26bfd8ce2eaa18acc30fb81ce49894cc">   77</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a26bfd8ce2eaa18acc30fb81ce49894cc">withoutOrdering</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a53f4e7b6bfb6fb188b9aef8d26bacfdd">withEncoding</a>(enc.withoutOrdering());</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;  }</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">  /// Allow implicit conversion to `RankedTensorType`, `ShapedType`,</span></div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment">  /// and `Type`.  These are implicit to help alleviate the impedance</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment">  /// mismatch for code that has not been converted to use `SparseTensorType`</span></div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment">  /// directly.  Once more of the sparse compiler has been converted to</span></div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">  /// using `SparseTensorType`, we may want to make these explicit instead.</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">  /// WARNING: This user-defined-conversion method causes overload</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment">  /// ambiguity whenever passing a `SparseTensorType` directly to a</span></div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment">  /// function which is overloaded to accept either `Type` or `TypeRange`.</span></div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="comment">  /// In particular, this includes `RewriterBase::replaceOpWithNewOp&lt;OpTy&gt;`</span></div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment">  /// and `OpBuilder::create&lt;OpTy&gt;` whenever the `OpTy::build` is overloaded</span></div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment">  /// thus.  This happens because the `TypeRange&lt;T&gt;(T&amp;&amp;)` ctor is implicit</span></div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment">  /// as well, and there&#39;s no SFINAE we can add to this method that would</span></div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="comment">  /// block subsequent application of that ctor.  The only way to fix the</span></div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment">  /// overload ambiguity is to avoid *implicit* conversion at the callsite:</span></div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment">  /// e.g., by using `static_cast` to make the conversion explicit, by</span></div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment">  /// assigning the `SparseTensorType` to a temporary variable of the</span></div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="comment">  /// desired type, etc.</span></div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="comment"></span>  <span class="comment">//</span></div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;  <span class="comment">// NOTE: We implement this as a single templated user-defined-conversion</span></div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  <span class="comment">// function to avoid ambiguity problems when the desired result is `Type`</span></div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  <span class="comment">// (since both `RankedTensorType` and `ShapedType` can be implicitly</span></div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  <span class="comment">// converted to `Type`).</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> = std::enable_if_t&lt;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;                            std::is_convertible_v&lt;RankedTensorType, T&gt;&gt;&gt;</div>
<div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a6480eec7bd6676b1fe40f6bba14e459f">  106</a></span>&#160;  <span class="comment">/*implicit*/</span> <span class="keyword">operator</span> T()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    <span class="keywordflow">return</span> rtp;</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;  }</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment">  /// Explicitly convert to `RankedTensorType`.  This method is</span></div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">  /// a convenience for resolving overload-ambiguity issues with</span></div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">  /// implicit conversion.</span></div>
<div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a95575d193fe675edda63c79f876780b1">  113</a></span>&#160;<span class="comment"></span>  RankedTensorType <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a95575d193fe675edda63c79f876780b1">getRankedTensorType</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp; }</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160; </div>
<div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a51c04fd598aea23545eb45c17dd402c7">  115</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a51c04fd598aea23545eb45c17dd402c7">operator==</a>(<span class="keyword">const</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;other)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="comment">// All other fields are derived from `rtp` and therefore don&#39;t need</span></div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <span class="comment">// to be checked.</span></div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    <span class="keywordflow">return</span> rtp == other.rtp;</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;  }</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160; </div>
<div class="line"><a name="l00121"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2f37b4e8c855ffbb1fa8bd9649221059">  121</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2f37b4e8c855ffbb1fa8bd9649221059">operator!=</a>(<span class="keyword">const</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;other)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    <span class="keywordflow">return</span> !(*<span class="keyword">this</span> == other);</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;  }</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160; </div>
<div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">  125</a></span>&#160;  <a class="code" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">getContext</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.getContext(); }</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160; </div>
<div class="line"><a name="l00127"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1b1978fe33f8c6d90427aec0bb593f76">  127</a></span>&#160;  <a class="code" href="classmlir_1_1Type.html">Type</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1b1978fe33f8c6d90427aec0bb593f76">getElementType</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.getElementType(); }</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="comment">  /// Returns the encoding (or the null-attribute for dense-tensors).</span></div>
<div class="line"><a name="l00130"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad5f5b4b2f2357638129b5621a50e3503">  130</a></span>&#160;<span class="comment"></span>  SparseTensorEncodingAttr <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad5f5b4b2f2357638129b5621a50e3503">getEncoding</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> enc; }</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment">  /// Returns true for tensors which have an encoding, and false for</span></div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="comment">  /// those which do not.  Therefore tensors with an all-dense encoding</span></div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="comment">  /// return true.</span></div>
<div class="line"><a name="l00135"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a3dbbef399c0d42d883dd466f343bc43f">  135</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a3dbbef399c0d42d883dd466f343bc43f">hasEncoding</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="keyword">static_cast&lt;</span><span class="keywordtype">bool</span><span class="keyword">&gt;</span>(enc); }</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment">  /// Returns true for tensors where every level is dense.</span></div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment">  /// (This is always true for dense-tensors.)</span></div>
<div class="line"><a name="l00139"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5d188327d9f1d4a42a32585ce2876ce5">  139</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5d188327d9f1d4a42a32585ce2876ce5">isAllDense</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> enc.isAllDense(); }</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment">  /// Returns true for tensors where every level is ordered.</span></div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment">  /// (This is always true for dense-tensors.)</span></div>
<div class="line"><a name="l00143"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a44afa2cd918e7357236a62f4449f7899">  143</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a44afa2cd918e7357236a62f4449f7899">isAllOrdered</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> enc.isAllOrdered(); }</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment">  /// Returns true if the dimToLvl mapping is the identity.</span></div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="comment">  /// (This is always true for dense-tensors.)</span></div>
<div class="line"><a name="l00147"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">  147</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">isIdentity</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> !dim2lvl; }</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment">  /// Returns the dimToLvl mapping (or the null-map for the identity).</span></div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment">  /// If you intend to compare the results of this method for equality,</span></div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment">  /// see `hasSameDimToLvlMap` instead.</span></div>
<div class="line"><a name="l00152"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a86b332ec5dfa36e6358d8d0a1a084ece">  152</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a86b332ec5dfa36e6358d8d0a1a084ece">getDimToLvlMap</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> dim2lvl; }</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="comment">  /// Returns the dimToLvl mapping, where the identity map is expanded out</span></div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="comment">  /// into a full `AffineMap`.  This method is provided as a convenience,</span></div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="comment">  /// but for most purposes other methods (`isIdentity`, `getDimToLvlMap`,</span></div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment">  /// etc) will be more helpful.</span></div>
<div class="line"><a name="l00158"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aecb679e9765bf80b185a4d8da7ef4e3a">  158</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aecb679e9765bf80b185a4d8da7ef4e3a">getExpandedDimToLvlMap</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <span class="keywordflow">return</span> dim2lvl</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;               ? dim2lvl</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;               : <a class="code" href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">AffineMap::getMultiDimIdentityMap</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">getDimRank</a>(), <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">getContext</a>());</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;  }</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment">  /// Returns true iff the two types have the same mapping.  This method</span></div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment">  /// takes care to handle identity maps properly, so it should be preferred</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment">  /// over using `getDimToLvlMap` followed by `AffineMap::operator==`.</span></div>
<div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2d644dc98bff26d6a94d50ef76e302dd">  167</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2d644dc98bff26d6a94d50ef76e302dd">hasSameDimToLvlMap</a>(<span class="keyword">const</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> &amp;other)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    <span class="comment">// If the maps are the identity, then we need to check the rank</span></div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    <span class="comment">// to be sure they&#39;re the same size identity.  (And since identity</span></div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;    <span class="comment">// means dimRank==lvlRank, we use lvlRank as a minor optimization.)</span></div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">isIdentity</a>() ? (other.<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">isIdentity</a>() &amp;&amp; lvlRank == other.lvlRank)</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;                        : (dim2lvl == other.dim2lvl);</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;  }</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment">  /// Returns the dimension-rank.</span></div>
<div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">  176</a></span>&#160;<span class="comment"></span>  <a class="code" href="namespacemlir_1_1sparse__tensor.html#a39f7b45046f9cc6ee2490f64fdb564b0">Dimension</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">getDimRank</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.getRank(); }</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment">  /// Returns the level-rank.</span></div>
<div class="line"><a name="l00179"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab08f577afef29840b7caf3d0be2c793f">  179</a></span>&#160;<span class="comment"></span>  <a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab08f577afef29840b7caf3d0be2c793f">getLvlRank</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> lvlRank; }</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">  /// Returns the dimension-shape.</span></div>
<div class="line"><a name="l00182"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a9fbf738974b30d7842dd0f70010651eb">  182</a></span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;DynSize&gt;</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a9fbf738974b30d7842dd0f70010651eb">getDimShape</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.getShape(); }</div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">  /// Safely looks up the requested dimension-DynSize.  If you intend</span></div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">  /// to check the result with `ShapedType::isDynamic`, then see the</span></div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">  /// `getStaticDimSize` method instead.</span></div>
<div class="line"><a name="l00187"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aac28ffb358acbcebb563fcf4cc30ba13">  187</a></span>&#160;<span class="comment"></span>  <a class="code" href="namespacemlir_1_1sparse__tensor.html#a72af2f55731ef9bb6340ac83785ab58d">DynSize</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aac28ffb358acbcebb563fcf4cc30ba13">getDynamicDimSize</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a39f7b45046f9cc6ee2490f64fdb564b0">Dimension</a> d)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    assert(d &lt; <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">getDimRank</a>() &amp;&amp; <span class="stringliteral">&quot;Dimension is out of bounds&quot;</span>);</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a9fbf738974b30d7842dd0f70010651eb">getDimShape</a>()[d];</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;  }</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="comment">  /// Safely looks up the requested dimension-size, mapping dynamic</span></div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="comment">  /// sizes to `std::nullopt`.</span></div>
<div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a791fd189fb370c4ea23e35f269f73ce9">  194</a></span>&#160;<span class="comment"></span>  std::optional&lt;StaticSize&gt; <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a791fd189fb370c4ea23e35f269f73ce9">getStaticDimSize</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a39f7b45046f9cc6ee2490f64fdb564b0">Dimension</a> d)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a72af2f55731ef9bb6340ac83785ab58d">DynSize</a> sh = <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aac28ffb358acbcebb563fcf4cc30ba13">getDynamicDimSize</a>(d);</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;    <span class="keywordflow">return</span> ShapedType::isDynamic(sh) ? std::nullopt</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;                                     : std::optional&lt;StaticSize&gt;(sh);</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;  }</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="comment">  /// Returns true if no dimension has dynamic size.</span></div>
<div class="line"><a name="l00201"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa266e34e646e484bb842fc94e3f11084">  201</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa266e34e646e484bb842fc94e3f11084">hasStaticDimShape</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.hasStaticShape(); }</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="comment">  /// Returns true if any dimension has dynamic size.</span></div>
<div class="line"><a name="l00204"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a8e9f94e79a621d5b827e0ea4d535bdb6">  204</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a8e9f94e79a621d5b827e0ea4d535bdb6">hasDynamicDimShape</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> !<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa266e34e646e484bb842fc94e3f11084">hasStaticDimShape</a>(); }</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="comment">  /// Returns true if the given dimension has dynamic size.  If you</span></div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="comment">  /// intend to call `getDynamicDimSize` based on the result, then see</span></div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="comment">  /// the `getStaticDimSize` method instead.</span></div>
<div class="line"><a name="l00209"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad7626e19625af5dd5d73aacfb06061ba">  209</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad7626e19625af5dd5d73aacfb06061ba">isDynamicDim</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a39f7b45046f9cc6ee2490f64fdb564b0">Dimension</a> d)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <span class="comment">// We don&#39;t use `rtp.isDynamicDim(d)` because we want the</span></div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    <span class="comment">// OOB error message to be consistent with `getDynamicDimSize`.</span></div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    <span class="keywordflow">return</span> ShapedType::isDynamic(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aac28ffb358acbcebb563fcf4cc30ba13">getDynamicDimSize</a>(d));</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;  }</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment">  /// Returns the number of dimensions which have dynamic sizes.</span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment">  /// The return type is `int64_t` to maintain consistency with</span></div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment">  /// `ShapedType::Trait&lt;T&gt;::getNumDynamicDims`.</span></div>
<div class="line"><a name="l00218"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a748d3e463f079b23679e617b7120cf78">  218</a></span>&#160;<span class="comment"></span>  int64_t <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a748d3e463f079b23679e617b7120cf78">getNumDynamicDims</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> rtp.getNumDynamicDims(); }</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160; </div>
<div class="line"><a name="l00220"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">  220</a></span>&#160;  <a class="code" href="namespacemlir_1_1sparse__tensor.html#aa09f02b16598f192895bfa41d8032a95">DimLevelType</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    <span class="comment">// This OOB check is for dense-tensors, since this class knows</span></div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    <span class="comment">// their lvlRank (whereas STEA::getLvlType will/can only check</span></div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    <span class="comment">// OOB for sparse-tensors).</span></div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    assert(l &lt; lvlRank &amp;&amp; <span class="stringliteral">&quot;Level out of bounds&quot;</span>);</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;    <span class="keywordflow">return</span> enc.getLvlType(l);</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;  }</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160; </div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;  <span class="comment">// We can&#39;t just delegate these, since we want to use this class&#39;s</span></div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;  <span class="comment">// `getLvlType` method instead of STEA&#39;s.</span></div>
<div class="line"><a name="l00230"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#adb76fe88dff789854c105b3f5c710a9f">  230</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#adb76fe88dff789854c105b3f5c710a9f">isDenseLvl</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a53da6b21ba86f146f692f68f8aebd179">isDenseDLT</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(l)); }</div>
<div class="line"><a name="l00231"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa152af64c6577dcb3abd948006a6b1f3">  231</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa152af64c6577dcb3abd948006a6b1f3">isCompressedLvl</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">isCompressedDLT</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(l)); }</div>
<div class="line"><a name="l00232"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a052dd43add6a4d59d42b5ba51b686c05">  232</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a052dd43add6a4d59d42b5ba51b686c05">isSingletonLvl</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a385e5085ee3fe65734e12c584da4b0e3">isSingletonDLT</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(l)); }</div>
<div class="line"><a name="l00233"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af5f5a0c66c902927d30fa1d37df6573e">  233</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af5f5a0c66c902927d30fa1d37df6573e">isOrderedLvl</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#af7c34ecc544ddda5c59e20acff90a0f6">isOrderedDLT</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(l)); }</div>
<div class="line"><a name="l00234"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#afc6bd40237f4d3af041f2db05f7c8504">  234</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#afc6bd40237f4d3af041f2db05f7c8504">isUniqueLvl</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> l)<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a3e088056a0b56f5542c0fb2c0ece84b7">isUniqueDLT</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">getLvlType</a>(l)); }</div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">  /// Returns the coordinate-overhead bitwidth, defaulting to zero.</span></div>
<div class="line"><a name="l00237"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a29d71cb7ebe3b1e304f3e8a5bd8dd61b">  237</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">unsigned</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a29d71cb7ebe3b1e304f3e8a5bd8dd61b">getCrdWidth</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> enc ? enc.getCrdWidth() : 0; }</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment">  /// Returns the position-overhead bitwidth, defaulting to zero.</span></div>
<div class="line"><a name="l00240"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab55459c4e7398889a8bd3f9ce6e89c5d">  240</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">unsigned</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab55459c4e7398889a8bd3f9ce6e89c5d">getPosWidth</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> enc ? enc.getPosWidth() : 0; }</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="comment">  /// Returns the coordinate-overhead MLIR type, defaulting to `IndexType`.</span></div>
<div class="line"><a name="l00243"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a7b65a254882cd7c349675af7087845e9">  243</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Type.html">Type</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a7b65a254882cd7c349675af7087845e9">getCrdType</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#abcebe81a4dd4377bae192347fc15b31c">detail::getIntegerOrIndexType</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">getContext</a>(), <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a29d71cb7ebe3b1e304f3e8a5bd8dd61b">getCrdWidth</a>());</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;  }</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="comment">  /// Returns the position-overhead MLIR type, defaulting to `IndexType`.</span></div>
<div class="line"><a name="l00248"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af02457704b9e62b7d60579219105b87f">  248</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Type.html">Type</a> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af02457704b9e62b7d60579219105b87f">getPosType</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#abcebe81a4dd4377bae192347fc15b31c">detail::getIntegerOrIndexType</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">getContext</a>(), <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab55459c4e7398889a8bd3f9ce6e89c5d">getPosWidth</a>());</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;  }</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160; </div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="keyword">private</span>:</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;  <span class="comment">// These two must be const, to ensure coherence of the memoized fields.</span></div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;  <span class="keyword">const</span> RankedTensorType rtp;</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;  <span class="keyword">const</span> SparseTensorEncodingAttr enc;</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;  <span class="comment">// Memoized to avoid frequent redundant conditionals.</span></div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;  <span class="keyword">const</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">Level</a> lvlRank;</div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;  <span class="keyword">const</span> <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> dim2lvl;</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;};</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment">/// Convenience method to abbreviate wrapping `getRankedTensorType`.</span></div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment"></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><a name="l00263"></a><span class="lineno"><a class="line" href="namespacemlir_1_1sparse__tensor.html#a473dd1b8f7cd685339a650bae0edd0ee">  263</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a> <a class="code" href="namespacemlir_1_1sparse__tensor.html#a473dd1b8f7cd685339a650bae0edd0ee">getSparseTensorType</a>(T t) {</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">SparseTensorType</a>(<a class="code" href="namespacemlir_1_1sparse__tensor.html#a6dfe2a013e2f99634447245104af3e85">getRankedTensorType</a>(t));</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;}</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160; </div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;} <span class="comment">// namespace sparse_tensor</span></div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;} <span class="comment">// namespace mlir</span></div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160; </div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;<span class="preprocessor">#endif </span><span class="comment">// MLIR_DIALECT_SPARSETENSOR_IR_SPARSETENSORTYPE_H_</span></div>
<div class="ttc" id="aTraits_8cpp_html_af226ab56dcfee54df5967680ce409c04"><div class="ttname"><a href="Traits_8cpp.html#af226ab56dcfee54df5967680ce409c04">getShape</a></div><div class="ttdeci">static ArrayRef&lt; int64_t &gt; getShape(Type type)</div><div class="ttdoc">Returns the shape of the given type.</div><div class="ttdef"><b>Definition:</b> <a href="Traits_8cpp_source.html#l00118">Traits.cpp:118</a></div></div>
<div class="ttc" id="aclassllvm_1_1ArrayRef_html"><div class="ttname"><a href="classllvm_1_1ArrayRef.html">llvm::ArrayRef</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00046">LLVM.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html"><div class="ttname"><a href="classmlir_1_1AffineMap.html">mlir::AffineMap</a></div><div class="ttdoc">A multi-dimensional affine map Affine map's are immutable like Type's, and they are uniqued.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineMap_8h_source.html#l00043">AffineMap.h:43</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a39ed2c2a4c743450a4a999fa6db1bf84"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">mlir::AffineMap::getMultiDimIdentityMap</a></div><div class="ttdeci">static AffineMap getMultiDimIdentityMap(unsigned numDims, MLIRContext *context)</div><div class="ttdoc">Returns an AffineMap with 'numDims' identity result dim exprs.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00262">AffineMap.cpp:262</a></div></div>
<div class="ttc" id="aclassmlir_1_1MLIRContext_html"><div class="ttname"><a href="classmlir_1_1MLIRContext.html">mlir::MLIRContext</a></div><div class="ttdoc">MLIRContext is the top-level object for a collection of MLIR operations.</div><div class="ttdef"><b>Definition:</b> <a href="MLIRContext_8h_source.html#l00060">MLIRContext.h:60</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html"><div class="ttname"><a href="classmlir_1_1Type.html">mlir::Type</a></div><div class="ttdoc">Instances of the Type class are uniqued, have an immutable identifier and an optional mutable compone...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Types_8h_source.html#l00074">Types.h:74</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html">mlir::sparse_tensor::SparseTensorType</a></div><div class="ttdoc">A wrapper around RankedTensorType, which has three goals:</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00046">SparseTensorType.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a052dd43add6a4d59d42b5ba51b686c05"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a052dd43add6a4d59d42b5ba51b686c05">mlir::sparse_tensor::SparseTensorType::isSingletonLvl</a></div><div class="ttdeci">bool isSingletonLvl(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00232">SparseTensorType.h:232</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a05ce3c3cccfeb3f6f77416fa517c58b1"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a05ce3c3cccfeb3f6f77416fa517c58b1">mlir::sparse_tensor::SparseTensorType::getContext</a></div><div class="ttdeci">MLIRContext * getContext() const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00125">SparseTensorType.h:125</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a1740494762525f9d3582ab6aa6e1ff36"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1740494762525f9d3582ab6aa6e1ff36">mlir::sparse_tensor::SparseTensorType::getLvlType</a></div><div class="ttdeci">DimLevelType getLvlType(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00220">SparseTensorType.h:220</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a1b1978fe33f8c6d90427aec0bb593f76"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a1b1978fe33f8c6d90427aec0bb593f76">mlir::sparse_tensor::SparseTensorType::getElementType</a></div><div class="ttdeci">Type getElementType() const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00127">SparseTensorType.h:127</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a23343ec0bd74c0053ac63a606bb9c5d5"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a23343ec0bd74c0053ac63a606bb9c5d5">mlir::sparse_tensor::SparseTensorType::SparseTensorType</a></div><div class="ttdeci">SparseTensorType(ShapedType stp, SparseTensorEncodingAttr enc)</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00058">SparseTensorType.h:58</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a26bfd8ce2eaa18acc30fb81ce49894cc"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a26bfd8ce2eaa18acc30fb81ce49894cc">mlir::sparse_tensor::SparseTensorType::withoutOrdering</a></div><div class="ttdeci">SparseTensorType withoutOrdering() const</div><div class="ttdoc">Constructs a new SparseTensorType with the same dimension-shape and element type, but with the encodi...</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00077">SparseTensorType.h:77</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a29d71cb7ebe3b1e304f3e8a5bd8dd61b"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a29d71cb7ebe3b1e304f3e8a5bd8dd61b">mlir::sparse_tensor::SparseTensorType::getCrdWidth</a></div><div class="ttdeci">unsigned getCrdWidth() const</div><div class="ttdoc">Returns the coordinate-overhead bitwidth, defaulting to zero.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00237">SparseTensorType.h:237</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a2d644dc98bff26d6a94d50ef76e302dd"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2d644dc98bff26d6a94d50ef76e302dd">mlir::sparse_tensor::SparseTensorType::hasSameDimToLvlMap</a></div><div class="ttdeci">bool hasSameDimToLvlMap(const SparseTensorType &amp;other) const</div><div class="ttdoc">Returns true iff the two types have the same mapping.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00167">SparseTensorType.h:167</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a2f37b4e8c855ffbb1fa8bd9649221059"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a2f37b4e8c855ffbb1fa8bd9649221059">mlir::sparse_tensor::SparseTensorType::operator!=</a></div><div class="ttdeci">bool operator!=(const SparseTensorType &amp;other) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00121">SparseTensorType.h:121</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a3dbbef399c0d42d883dd466f343bc43f"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a3dbbef399c0d42d883dd466f343bc43f">mlir::sparse_tensor::SparseTensorType::hasEncoding</a></div><div class="ttdeci">bool hasEncoding() const</div><div class="ttdoc">Returns true for tensors which have an encoding, and false for those which do not.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00135">SparseTensorType.h:135</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a44afa2cd918e7357236a62f4449f7899"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a44afa2cd918e7357236a62f4449f7899">mlir::sparse_tensor::SparseTensorType::isAllOrdered</a></div><div class="ttdeci">bool isAllOrdered() const</div><div class="ttdoc">Returns true for tensors where every level is ordered.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00143">SparseTensorType.h:143</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a51c04fd598aea23545eb45c17dd402c7"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a51c04fd598aea23545eb45c17dd402c7">mlir::sparse_tensor::SparseTensorType::operator==</a></div><div class="ttdeci">bool operator==(const SparseTensorType &amp;other) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00115">SparseTensorType.h:115</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a53f4e7b6bfb6fb188b9aef8d26bacfdd"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a53f4e7b6bfb6fb188b9aef8d26bacfdd">mlir::sparse_tensor::SparseTensorType::withEncoding</a></div><div class="ttdeci">SparseTensorType withEncoding(SparseTensorEncodingAttr newEnc) const</div><div class="ttdoc">Constructs a new SparseTensorType with the same dimension-shape and element type, but with the encodi...</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00070">SparseTensorType.h:70</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a54f91f9843d18c1a714ccb66d462718d"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a54f91f9843d18c1a714ccb66d462718d">mlir::sparse_tensor::SparseTensorType::getDimRank</a></div><div class="ttdeci">Dimension getDimRank() const</div><div class="ttdoc">Returns the dimension-rank.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00176">SparseTensorType.h:176</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a5b5f50ad4b2427cc6270e8d8cfc18c44"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5b5f50ad4b2427cc6270e8d8cfc18c44">mlir::sparse_tensor::SparseTensorType::SparseTensorType</a></div><div class="ttdeci">SparseTensorType(const SparseTensorType &amp;)=default</div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a5d188327d9f1d4a42a32585ce2876ce5"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a5d188327d9f1d4a42a32585ce2876ce5">mlir::sparse_tensor::SparseTensorType::isAllDense</a></div><div class="ttdeci">bool isAllDense() const</div><div class="ttdoc">Returns true for tensors where every level is dense.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00139">SparseTensorType.h:139</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a748d3e463f079b23679e617b7120cf78"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a748d3e463f079b23679e617b7120cf78">mlir::sparse_tensor::SparseTensorType::getNumDynamicDims</a></div><div class="ttdeci">int64_t getNumDynamicDims() const</div><div class="ttdoc">Returns the number of dimensions which have dynamic sizes.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00218">SparseTensorType.h:218</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a791fd189fb370c4ea23e35f269f73ce9"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a791fd189fb370c4ea23e35f269f73ce9">mlir::sparse_tensor::SparseTensorType::getStaticDimSize</a></div><div class="ttdeci">std::optional&lt; StaticSize &gt; getStaticDimSize(Dimension d) const</div><div class="ttdoc">Safely looks up the requested dimension-size, mapping dynamic sizes to std::nullopt.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00194">SparseTensorType.h:194</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a7b65a254882cd7c349675af7087845e9"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a7b65a254882cd7c349675af7087845e9">mlir::sparse_tensor::SparseTensorType::getCrdType</a></div><div class="ttdeci">Type getCrdType() const</div><div class="ttdoc">Returns the coordinate-overhead MLIR type, defaulting to IndexType.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00243">SparseTensorType.h:243</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a839df43feb35ab6abf0136be0a7ee45e"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a839df43feb35ab6abf0136be0a7ee45e">mlir::sparse_tensor::SparseTensorType::isIdentity</a></div><div class="ttdeci">bool isIdentity() const</div><div class="ttdoc">Returns true if the dimToLvl mapping is the identity.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00147">SparseTensorType.h:147</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a86b332ec5dfa36e6358d8d0a1a084ece"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a86b332ec5dfa36e6358d8d0a1a084ece">mlir::sparse_tensor::SparseTensorType::getDimToLvlMap</a></div><div class="ttdeci">AffineMap getDimToLvlMap() const</div><div class="ttdoc">Returns the dimToLvl mapping (or the null-map for the identity).</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00152">SparseTensorType.h:152</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a8e9f94e79a621d5b827e0ea4d535bdb6"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a8e9f94e79a621d5b827e0ea4d535bdb6">mlir::sparse_tensor::SparseTensorType::hasDynamicDimShape</a></div><div class="ttdeci">bool hasDynamicDimShape() const</div><div class="ttdoc">Returns true if any dimension has dynamic size.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00204">SparseTensorType.h:204</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a93121d975f00b0b379c15f6f98de4c83"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a93121d975f00b0b379c15f6f98de4c83">mlir::sparse_tensor::SparseTensorType::SparseTensorType</a></div><div class="ttdeci">SparseTensorType(RankedTensorType rtp)</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00050">SparseTensorType.h:50</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a95575d193fe675edda63c79f876780b1"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a95575d193fe675edda63c79f876780b1">mlir::sparse_tensor::SparseTensorType::getRankedTensorType</a></div><div class="ttdeci">RankedTensorType getRankedTensorType() const</div><div class="ttdoc">Explicitly convert to RankedTensorType.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00113">SparseTensorType.h:113</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_a9fbf738974b30d7842dd0f70010651eb"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#a9fbf738974b30d7842dd0f70010651eb">mlir::sparse_tensor::SparseTensorType::getDimShape</a></div><div class="ttdeci">ArrayRef&lt; DynSize &gt; getDimShape() const</div><div class="ttdoc">Returns the dimension-shape.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00182">SparseTensorType.h:182</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_aa152af64c6577dcb3abd948006a6b1f3"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa152af64c6577dcb3abd948006a6b1f3">mlir::sparse_tensor::SparseTensorType::isCompressedLvl</a></div><div class="ttdeci">bool isCompressedLvl(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00231">SparseTensorType.h:231</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_aa266e34e646e484bb842fc94e3f11084"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aa266e34e646e484bb842fc94e3f11084">mlir::sparse_tensor::SparseTensorType::hasStaticDimShape</a></div><div class="ttdeci">bool hasStaticDimShape() const</div><div class="ttdoc">Returns true if no dimension has dynamic size.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00201">SparseTensorType.h:201</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_aac28ffb358acbcebb563fcf4cc30ba13"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aac28ffb358acbcebb563fcf4cc30ba13">mlir::sparse_tensor::SparseTensorType::getDynamicDimSize</a></div><div class="ttdeci">DynSize getDynamicDimSize(Dimension d) const</div><div class="ttdoc">Safely looks up the requested dimension-DynSize.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00187">SparseTensorType.h:187</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_ab08f577afef29840b7caf3d0be2c793f"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab08f577afef29840b7caf3d0be2c793f">mlir::sparse_tensor::SparseTensorType::getLvlRank</a></div><div class="ttdeci">Level getLvlRank() const</div><div class="ttdoc">Returns the level-rank.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00179">SparseTensorType.h:179</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_ab55459c4e7398889a8bd3f9ce6e89c5d"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ab55459c4e7398889a8bd3f9ce6e89c5d">mlir::sparse_tensor::SparseTensorType::getPosWidth</a></div><div class="ttdeci">unsigned getPosWidth() const</div><div class="ttdoc">Returns the position-overhead bitwidth, defaulting to zero.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00240">SparseTensorType.h:240</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_ad5f5b4b2f2357638129b5621a50e3503"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad5f5b4b2f2357638129b5621a50e3503">mlir::sparse_tensor::SparseTensorType::getEncoding</a></div><div class="ttdeci">SparseTensorEncodingAttr getEncoding() const</div><div class="ttdoc">Returns the encoding (or the null-attribute for dense-tensors).</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00130">SparseTensorType.h:130</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_ad7626e19625af5dd5d73aacfb06061ba"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#ad7626e19625af5dd5d73aacfb06061ba">mlir::sparse_tensor::SparseTensorType::isDynamicDim</a></div><div class="ttdeci">bool isDynamicDim(Dimension d) const</div><div class="ttdoc">Returns true if the given dimension has dynamic size.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00209">SparseTensorType.h:209</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_adb76fe88dff789854c105b3f5c710a9f"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#adb76fe88dff789854c105b3f5c710a9f">mlir::sparse_tensor::SparseTensorType::isDenseLvl</a></div><div class="ttdeci">bool isDenseLvl(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00230">SparseTensorType.h:230</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_aecb679e9765bf80b185a4d8da7ef4e3a"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#aecb679e9765bf80b185a4d8da7ef4e3a">mlir::sparse_tensor::SparseTensorType::getExpandedDimToLvlMap</a></div><div class="ttdeci">AffineMap getExpandedDimToLvlMap() const</div><div class="ttdoc">Returns the dimToLvl mapping, where the identity map is expanded out into a full AffineMap.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00158">SparseTensorType.h:158</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_af02457704b9e62b7d60579219105b87f"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af02457704b9e62b7d60579219105b87f">mlir::sparse_tensor::SparseTensorType::getPosType</a></div><div class="ttdeci">Type getPosType() const</div><div class="ttdoc">Returns the position-overhead MLIR type, defaulting to IndexType.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00248">SparseTensorType.h:248</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_af4d830b06b63a2f61566aaf98e9a868b"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af4d830b06b63a2f61566aaf98e9a868b">mlir::sparse_tensor::SparseTensorType::operator=</a></div><div class="ttdeci">SparseTensorType &amp; operator=(const SparseTensorType &amp;)=delete</div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_af5f5a0c66c902927d30fa1d37df6573e"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#af5f5a0c66c902927d30fa1d37df6573e">mlir::sparse_tensor::SparseTensorType::isOrderedLvl</a></div><div class="ttdeci">bool isOrderedLvl(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00233">SparseTensorType.h:233</a></div></div>
<div class="ttc" id="aclassmlir_1_1sparse__tensor_1_1SparseTensorType_html_afc6bd40237f4d3af041f2db05f7c8504"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorType.html#afc6bd40237f4d3af041f2db05f7c8504">mlir::sparse_tensor::SparseTensorType::isUniqueLvl</a></div><div class="ttdeci">bool isUniqueLvl(Level l) const</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00234">SparseTensorType.h:234</a></div></div>
<div class="ttc" id="amlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h_html"><div class="ttname"><a href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h.html">SparseTensor.h</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_1_1detail_html_abcebe81a4dd4377bae192347fc15b31c"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor_1_1detail.html#abcebe81a4dd4377bae192347fc15b31c">mlir::sparse_tensor::detail::getIntegerOrIndexType</a></div><div class="ttdeci">Type getIntegerOrIndexType(MLIRContext *ctx, unsigned bitwidth)</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorDialect_8cpp_source.html#l00117">SparseTensorDialect.cpp:117</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a385e5085ee3fe65734e12c584da4b0e3"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a385e5085ee3fe65734e12c584da4b0e3">mlir::sparse_tensor::isSingletonDLT</a></div><div class="ttdeci">constexpr bool isSingletonDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is singleton (regardless of properties).</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00274">Enums.h:274</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a39f7b45046f9cc6ee2490f64fdb564b0"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a39f7b45046f9cc6ee2490f64fdb564b0">mlir::sparse_tensor::Dimension</a></div><div class="ttdeci">uint64_t Dimension</div><div class="ttdoc">The type of dimension identifiers, and dimension-ranks.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h_source.html#l00039">SparseTensor.h:39</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a3e088056a0b56f5542c0fb2c0ece84b7"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a3e088056a0b56f5542c0fb2c0ece84b7">mlir::sparse_tensor::isUniqueDLT</a></div><div class="ttdeci">constexpr bool isUniqueDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is unique (regardless of storage format).</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00285">Enums.h:285</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a473dd1b8f7cd685339a650bae0edd0ee"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a473dd1b8f7cd685339a650bae0edd0ee">mlir::sparse_tensor::getSparseTensorType</a></div><div class="ttdeci">SparseTensorType getSparseTensorType(T t)</div><div class="ttdoc">Convenience method to abbreviate wrapping getRankedTensorType.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorType_8h_source.html#l00263">SparseTensorType.h:263</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a4eeeb1242c0500476bf0e6b6da6a30e2"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a4eeeb1242c0500476bf0e6b6da6a30e2">mlir::sparse_tensor::Level</a></div><div class="ttdeci">uint64_t Level</div><div class="ttdoc">The type of level identifiers, and level-ranks.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h_source.html#l00045">SparseTensor.h:45</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a53da6b21ba86f146f692f68f8aebd179"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a53da6b21ba86f146f692f68f8aebd179">mlir::sparse_tensor::isDenseDLT</a></div><div class="ttdeci">constexpr bool isDenseDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is dense.</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00253">Enums.h:253</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a6dfe2a013e2f99634447245104af3e85"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a6dfe2a013e2f99634447245104af3e85">mlir::sparse_tensor::getRankedTensorType</a></div><div class="ttdeci">RankedTensorType getRankedTensorType(T &amp;&amp;t)</div><div class="ttdoc">Convenience method to abbreviate casting getType().</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h_source.html#l00095">SparseTensor.h:95</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a72af2f55731ef9bb6340ac83785ab58d"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a72af2f55731ef9bb6340ac83785ab58d">mlir::sparse_tensor::DynSize</a></div><div class="ttdeci">int64_t DynSize</div><div class="ttdoc">The type for individual components of a compile-time shape.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Dialect_2SparseTensor_2IR_2SparseTensor_8h_source.html#l00051">SparseTensor.h:51</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_a90cf107e240044ac0fbeb952ea3ae0f0"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a90cf107e240044ac0fbeb952ea3ae0f0">mlir::sparse_tensor::getSparseTensorEncoding</a></div><div class="ttdeci">SparseTensorEncodingAttr getSparseTensorEncoding(Type type)</div><div class="ttdoc">Convenience method to get a sparse encoding attribute from a type.</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorDialect_8cpp_source.html#l00444">SparseTensorDialect.cpp:444</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_aa09f02b16598f192895bfa41d8032a95"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#aa09f02b16598f192895bfa41d8032a95">mlir::sparse_tensor::DimLevelType</a></div><div class="ttdeci">DimLevelType</div><div class="ttdoc">This enum defines all the sparse representations supportable by the SparseTensor dialect.</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00174">Enums.h:174</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_ac55329be9bb21947094bd053a2b6f4ce"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">mlir::sparse_tensor::isCompressedDLT</a></div><div class="ttdeci">constexpr bool isCompressedDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is compressed (regardless of properties).</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00262">Enums.h:262</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_html_af7c34ecc544ddda5c59e20acff90a0f6"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#af7c34ecc544ddda5c59e20acff90a0f6">mlir::sparse_tensor::isOrderedDLT</a></div><div class="ttdeci">constexpr bool isOrderedDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is ordered (regardless of storage format).</div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00280">Enums.h:280</a></div></div>
<div class="ttc" id="anamespacemlir_html"><div class="ttname"><a href="namespacemlir.html">mlir</a></div><div class="ttdoc">This header declares functions that assit transformations in the MemRef dialect.</div><div class="ttdef"><b>Definition:</b> <a href="LocalAliasAnalysis_8h_source.html#l00020">LocalAliasAnalysis.h:20</a></div></div>
<div class="ttc" id="anamespacemlir_html_ab4871db68c59a176135e0e35a3625e73"><div class="ttname"><a href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">mlir::get</a></div><div class="ttdeci">auto get(MLIRContext *context, Ts &amp;&amp;...params)</div><div class="ttdoc">Helper method that injects context only if needed, this helps unify some of the attribute constructio...</div><div class="ttdef"><b>Definition:</b> <a href="BytecodeImplementation_8h_source.html#l00368">BytecodeImplementation.h:368</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu May 4 2023 20:33:51 for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
