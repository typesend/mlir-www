<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Transform Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/Transform/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>Transform Dialect</h1><p>Fine-grain transformation control dialect.</p><p><nav id=TableOfContents><ul><li><a href=#disclaimer>Disclaimer</a></li><li><a href=#overview>Overview</a></li><li><a href=#dialect-extension-mechanism>Dialect Extension Mechanism</a></li><li><a href=#side-effects>Side Effects</a></li><li><a href=#execution-model>Execution Model</a></li><li><a href=#handle-invalidation>Handle Invalidation</a></li><li><a href=#intended-use-and-integrations>Intended Use and Integrations</a></li><li><a href=#effects-on-the-infrastructure>Effects on the Infrastructure</a></li><li><a href=#type-definitions>Type Definitions</a><ul><li><a href=#anyoptype>AnyOpType</a></li><li><a href=#anyvaluetype>AnyValueType</a></li><li><a href=#operationtype>OperationType</a></li><li><a href=#paramtype>ParamType</a></li></ul></li><li><a href=#core-operations>Core Operations</a><ul><li><a href=#transformalternatives-mlirtransformalternativesop><code>transform.alternatives</code> (::mlir::transform::AlternativesOp)</a></li><li><a href=#transformcast-mlirtransformcastop><code>transform.cast</code> (::mlir::transform::CastOp)</a></li><li><a href=#transformforeach_match-mlirtransformforeachmatchop><code>transform.foreach_match</code> (::mlir::transform::ForeachMatchOp)</a></li><li><a href=#transformforeach-mlirtransformforeachop><code>transform.foreach</code> (::mlir::transform::ForeachOp)</a></li><li><a href=#transformget_closest_isolated_parent-mlirtransformgetclosestisolatedparentop><code>transform.get_closest_isolated_parent</code> (::mlir::transform::GetClosestIsolatedParentOp)</a></li><li><a href=#transformget_consumers_of_result-mlirtransformgetconsumersofresult><code>transform.get_consumers_of_result</code> (::mlir::transform::GetConsumersOfResult)</a></li><li><a href=#transformget_defining_op-mlirtransformgetdefiningop><code>transform.get_defining_op</code> (::mlir::transform::GetDefiningOp)</a></li><li><a href=#transformget_producer_of_operand-mlirtransformgetproducerofoperand><code>transform.get_producer_of_operand</code> (::mlir::transform::GetProducerOfOperand)</a></li><li><a href=#transformget_result-mlirtransformgetresultop><code>transform.get_result</code> (::mlir::transform::GetResultOp)</a></li><li><a href=#transforminclude-mlirtransformincludeop><code>transform.include</code> (::mlir::transform::IncludeOp)</a></li><li><a href=#transformmatchoperation_name-mlirtransformmatchoperationnameop><code>transform.match.operation_name</code> (::mlir::transform::MatchOperationNameOp)</a></li><li><a href=#transformmatchparamcmpi-mlirtransformmatchparamcmpiop><code>transform.match.param.cmpi</code> (::mlir::transform::MatchParamCmpIOp)</a></li><li><a href=#transformmerge_handles-mlirtransformmergehandlesop><code>transform.merge_handles</code> (::mlir::transform::MergeHandlesOp)</a></li><li><a href=#transformnamed_sequence-mlirtransformnamedsequenceop><code>transform.named_sequence</code> (::mlir::transform::NamedSequenceOp)</a></li><li><a href=#transformpdl_match-mlirtransformpdlmatchop><code>transform.pdl_match</code> (::mlir::transform::PDLMatchOp)</a></li><li><a href=#transformparamconstant-mlirtransformparamconstantop><code>transform.param.constant</code> (::mlir::transform::ParamConstantOp)</a></li><li><a href=#transformprint-mlirtransformprintop><code>transform.print</code> (::mlir::transform::PrintOp)</a></li><li><a href=#transformreplicate-mlirtransformreplicateop><code>transform.replicate</code> (::mlir::transform::ReplicateOp)</a></li><li><a href=#transformsequence-mlirtransformsequenceop><code>transform.sequence</code> (::mlir::transform::SequenceOp)</a></li><li><a href=#transformsplit_handles-mlirtransformsplithandlesop><code>transform.split_handles</code> (::mlir::transform::SplitHandlesOp)</a></li><li><a href=#transformwith_pdl_patterns-mlirtransformwithpdlpatternsop><code>transform.with_pdl_patterns</code> (::mlir::transform::WithPDLPatternsOp)</a></li><li><a href=#transformyield-mlirtransformyieldop><code>transform.yield</code> (::mlir::transform::YieldOp)</a></li></ul></li><li><a href=#affine-transform-operations>Affine Transform Operations</a><ul><li><a href=#transformaffinesimplify_bounded_affine_ops-mlirtransformsimplifyboundedaffineopsop><code>transform.affine.simplify_bounded_affine_ops</code> (::mlir::transform::SimplifyBoundedAffineOpsOp)</a></li></ul></li><li><a href=#bufferization-transform-operations>Bufferization Transform Operations</a><ul><li><a href=#transformbufferizationeliminate_empty_tensors-mlirtransformeliminateemptytensorsop><code>transform.bufferization.eliminate_empty_tensors</code> (::mlir::transform::EliminateEmptyTensorsOp)</a></li><li><a href=#transformbufferizationempty_tensor_to_alloc_tensor-mlirtransformemptytensortoalloctensorop><code>transform.bufferization.empty_tensor_to_alloc_tensor</code> (::mlir::transform::EmptyTensorToAllocTensorOp)</a></li><li><a href=#transformbufferizationone_shot_bufferize-mlirtransformoneshotbufferizeop><code>transform.bufferization.one_shot_bufferize</code> (::mlir::transform::OneShotBufferizeOp)</a></li></ul></li><li><a href=#gpu-transform-operations>GPU Transform Operations</a><ul><li><a href=#transformgpumap_forall_to_blocks-mlirtransformmapforalltoblocks><code>transform.gpu.map_forall_to_blocks</code> (::mlir::transform::MapForallToBlocks)</a></li><li><a href=#transformgpumap_nested_forall_to_threads-mlirtransformmapnestedforalltothreads><code>transform.gpu.map_nested_forall_to_threads</code> (::mlir::transform::MapNestedForallToThreads)</a></li></ul></li><li><a href=#loop-scf-transform-operations>Loop (SCF) Transform Operations</a><ul><li><a href=#transformloopget_parent_for-mlirtransformgetparentforop><code>transform.loop.get_parent_for</code> (::mlir::transform::GetParentForOp)</a></li><li><a href=#transformloopcoalesce-mlirtransformloopcoalesceop><code>transform.loop.coalesce</code> (::mlir::transform::LoopCoalesceOp)</a></li><li><a href=#transformloopoutline-mlirtransformloopoutlineop><code>transform.loop.outline</code> (::mlir::transform::LoopOutlineOp)</a></li><li><a href=#transformlooppeel-mlirtransformlooppeelop><code>transform.loop.peel</code> (::mlir::transform::LoopPeelOp)</a></li><li><a href=#transformlooppipeline-mlirtransformlooppipelineop><code>transform.loop.pipeline</code> (::mlir::transform::LoopPipelineOp)</a></li><li><a href=#transformloopunroll-mlirtransformloopunrollop><code>transform.loop.unroll</code> (::mlir::transform::LoopUnrollOp)</a></li><li><a href=#transformscftake_assumed_branch-mlirtransformtakeassumedbranchop><code>transform.scf.take_assumed_branch</code> (::mlir::transform::TakeAssumedBranchOp)</a></li></ul></li><li><a href=#memref-transform-operations>MemRef Transform Operations</a><ul><li><a href=#transformmemrefextract_address_computations-mlirtransformmemrefextractaddresscomputationsop><code>transform.memref.extract_address_computations</code> (::mlir::transform::MemRefExtractAddressComputationsOp)</a></li><li><a href=#transformmemrefmake_loop_independent-mlirtransformmemrefmakeloopindependentop><code>transform.memref.make_loop_independent</code> (::mlir::transform::MemRefMakeLoopIndependentOp)</a></li><li><a href=#transformmemrefmultibuffer-mlirtransformmemrefmultibufferop><code>transform.memref.multibuffer</code> (::mlir::transform::MemRefMultiBufferOp)</a></li></ul></li><li><a href=#structured-linalg-match-operations>Structured (Linalg) Match Operations</a><ul><li><a href=#transformmatchstructuredbody-mlirtransformmatchstructuredbodyop><code>transform.match.structured.body</code> (::mlir::transform::MatchStructuredBodyOp)</a></li><li><a href=#transformmatchstructureddim-mlirtransformmatchstructureddimop><code>transform.match.structured.dim</code> (::mlir::transform::MatchStructuredDimOp)</a></li><li><a href=#transformmatchstructuredelemental_bitwidth-mlirtransformmatchstructuredelementalbitwidthop><code>transform.match.structured.elemental_bitwidth</code> (::mlir::transform::MatchStructuredElementalBitwidthOp)</a></li><li><a href=#transformmatchstructuredinit-mlirtransformmatchstructuredinitop><code>transform.match.structured.init</code> (::mlir::transform::MatchStructuredInitOp)</a></li><li><a href=#transformmatchstructuredinput-mlirtransformmatchstructuredinputop><code>transform.match.structured.input</code> (::mlir::transform::MatchStructuredInputOp)</a></li><li><a href=#transformmatchstructurednum_inits-mlirtransformmatchstructurednuminitsop><code>transform.match.structured.num_inits</code> (::mlir::transform::MatchStructuredNumInitsOp)</a></li><li><a href=#transformmatchstructurednum_inputs-mlirtransformmatchstructurednuminputsop><code>transform.match.structured.num_inputs</code> (::mlir::transform::MatchStructuredNumInputsOp)</a></li><li><a href=#transformmatchstructured-mlirtransformmatchstructuredop><code>transform.match.structured</code> (::mlir::transform::MatchStructuredOp)</a></li><li><a href=#transformmatchstructuredrank-mlirtransformmatchstructuredrankop><code>transform.match.structured.rank</code> (::mlir::transform::MatchStructuredRankOp)</a></li><li><a href=#transformmatchstructuredresult-mlirtransformmatchstructuredresultop><code>transform.match.structured.result</code> (::mlir::transform::MatchStructuredResultOp)</a></li><li><a href=#transformmatchstructuredyield-mlirtransformmatchstructuredyieldop><code>transform.match.structured.yield</code> (::mlir::transform::MatchStructuredYieldOp)</a></li></ul></li><li><a href=#structured-linalg-transform-operations>Structured (Linalg) Transform Operations</a><ul><li><a href=#transformstructuredbufferize_to_allocation-mlirtransformbufferizetoallocationop><code>transform.structured.bufferize_to_allocation</code> (::mlir::transform::BufferizeToAllocationOp)</a></li><li><a href=#transformstructuredconvert_conv2d_to_img2col-mlirtransformconvertconv2dtoimg2colop><code>transform.structured.convert_conv2d_to_img2col</code> (::mlir::transform::ConvertConv2DToImg2ColOp)</a></li><li><a href=#transformstructureddecompose-mlirtransformdecomposeop><code>transform.structured.decompose</code> (::mlir::transform::DecomposeOp)</a></li><li><a href=#transformstructuredfuse_into_containing_op-mlirtransformfuseintocontainingop><code>transform.structured.fuse_into_containing_op</code> (::mlir::transform::FuseIntoContainingOp)</a></li><li><a href=#transformstructuredfuse-mlirtransformfuseop><code>transform.structured.fuse</code> (::mlir::transform::FuseOp)</a></li><li><a href=#transformstructuredgeneralize-mlirtransformgeneralizeop><code>transform.structured.generalize</code> (::mlir::transform::GeneralizeOp)</a></li><li><a href=#transformstructuredhoist_padbuild_packing_loop_nest-mlirtransformhoistpadbuildpackingloopnestop><code>transform.structured.hoist_pad.build_packing_loop_nest</code> (::mlir::transform::HoistPadBuildPackingLoopNestOp)</a></li><li><a href=#transformstructuredhoist_pad-mlirtransformhoistpadop><code>transform.structured.hoist_pad</code> (::mlir::transform::HoistPadOp)</a></li><li><a href=#transformstructuredhoist_redundant_tensor_subsets-mlirtransformhoistredundanttensorsubsetsop><code>transform.structured.hoist_redundant_tensor_subsets</code> (::mlir::transform::HoistRedundantTensorSubsetsOp)</a></li><li><a href=#transformstructuredhoist_redundant_vector_transfers-mlirtransformhoistredundantvectortransfersop><code>transform.structured.hoist_redundant_vector_transfers</code> (::mlir::transform::HoistRedundantVectorTransfersOp)</a></li><li><a href=#transformstructuredinsert_slice_to_copy-mlirtransforminsertslicetocopyop><code>transform.structured.insert_slice_to_copy</code> (::mlir::transform::InsertSliceToCopyOp)</a></li><li><a href=#transformstructuredinterchange-mlirtransforminterchangeop><code>transform.structured.interchange</code> (::mlir::transform::InterchangeOp)</a></li><li><a href=#transformstructuredlower_pack-mlirtransformlowerpackop><code>transform.structured.lower_pack</code> (::mlir::transform::LowerPackOp)</a></li><li><a href=#transformstructuredlower_unpack-mlirtransformlowerunpackop><code>transform.structured.lower_unpack</code> (::mlir::transform::LowerUnPackOp)</a></li><li><a href=#transformstructuredmasked_vectorize-mlirtransformmaskedvectorizeop><code>transform.structured.masked_vectorize</code> (::mlir::transform::MaskedVectorizeOp)</a></li><li><a href=#transformstructuredmatch-mlirtransformmatchop><code>transform.structured.match</code> (::mlir::transform::MatchOp)</a></li><li><a href=#transformstructuredmultitile_sizes-mlirtransformmultitilesizesop><code>transform.structured.multitile_sizes</code> (::mlir::transform::MultiTileSizesOp)</a></li><li><a href=#transformstructuredpack_greedily-mlirtransformpackgreedilyop><code>transform.structured.pack_greedily</code> (::mlir::transform::PackGreedilyOp)</a></li><li><a href=#transformstructuredpack-mlirtransformpackop><code>transform.structured.pack</code> (::mlir::transform::PackOp)</a></li><li><a href=#transformstructuredpack_transpose-mlirtransformpacktransposeop><code>transform.structured.pack_transpose</code> (::mlir::transform::PackTransposeOp)</a></li><li><a href=#transformstructuredpad-mlirtransformpadop><code>transform.structured.pad</code> (::mlir::transform::PadOp)</a></li><li><a href=#transformstructuredpromote-mlirtransformpromoteop><code>transform.structured.promote</code> (::mlir::transform::PromoteOp)</a></li><li><a href=#transformstructuredreplace-mlirtransformreplaceop><code>transform.structured.replace</code> (::mlir::transform::ReplaceOp)</a></li><li><a href=#transformstructuredrewrite_in_destination_passing_style-mlirtransformrewriteindestinationpassingstyleop><code>transform.structured.rewrite_in_destination_passing_style</code> (::mlir::transform::RewriteInDestinationPassingStyleOp)</a></li><li><a href=#transformstructuredscalarize-mlirtransformscalarizeop><code>transform.structured.scalarize</code> (::mlir::transform::ScalarizeOp)</a></li><li><a href=#transformstructuredsplit-mlirtransformsplitop><code>transform.structured.split</code> (::mlir::transform::SplitOp)</a></li><li><a href=#transformstructuredsplit_reduction-mlirtransformsplitreductionop><code>transform.structured.split_reduction</code> (::mlir::transform::SplitReductionOp)</a></li><li><a href=#transformstructuredtile-mlirtransformtileop><code>transform.structured.tile</code> (::mlir::transform::TileOp)</a></li><li><a href=#transformstructuredtile_reduction_using_forall-mlirtransformtilereductionusingforallop><code>transform.structured.tile_reduction_using_forall</code> (::mlir::transform::TileReductionUsingForallOp)</a></li><li><a href=#transformstructuredtile_reduction_using_scf-mlirtransformtilereductionusingscfop><code>transform.structured.tile_reduction_using_scf</code> (::mlir::transform::TileReductionUsingScfOp)</a></li><li><a href=#transformstructuredtile_to_forall_op-mlirtransformtiletoforallop><code>transform.structured.tile_to_forall_op</code> (::mlir::transform::TileToForallOp)</a></li><li><a href=#transformstructuredtile_to_scf_for-mlirtransformtiletoscfforop><code>transform.structured.tile_to_scf_for</code> (::mlir::transform::TileToScfForOp)</a></li><li><a href=#transformstructuredvectorize-mlirtransformvectorizeop><code>transform.structured.vectorize</code> (::mlir::transform::VectorizeOp)</a></li></ul></li><li><a href=#vector-transform-operations>Vector Transform Operations</a><ul><li><a href=#transformvectorapply_rank_reducing_subview_patterns-mlirtransformapplyrankreducingsubviewpatternsop><code>transform.vector.apply_rank_reducing_subview_patterns</code> (::mlir::transform::ApplyRankReducingSubviewPatternsOp)</a></li><li><a href=#transformvectorapply_transfer_permutation_patterns-mlirtransformapplytransferpermutationpatternsop><code>transform.vector.apply_transfer_permutation_patterns</code> (::mlir::transform::ApplyTransferPermutationPatternsOp)</a></li><li><a href=#transformvectorlower_broadcast-mlirtransformlowerbroadcastop><code>transform.vector.lower_broadcast</code> (::mlir::transform::LowerBroadcastOp)</a></li><li><a href=#transformvectorlower_contraction-mlirtransformlowercontractionop><code>transform.vector.lower_contraction</code> (::mlir::transform::LowerContractionOp)</a></li><li><a href=#transformvectorlower_masked_transfers-mlirtransformlowermaskedtransfersop><code>transform.vector.lower_masked_transfers</code> (::mlir::transform::LowerMaskedTransfersOp)</a></li><li><a href=#transformvectorlower_masks-mlirtransformlowermasksop><code>transform.vector.lower_masks</code> (::mlir::transform::LowerMasksOp)</a></li><li><a href=#transformvectorlower_multi_reduction-mlirtransformlowermultireductionop><code>transform.vector.lower_multi_reduction</code> (::mlir::transform::LowerMultiReductionOp)</a></li><li><a href=#transformvectorlower_outerproduct-mlirtransformlowerouterproductop><code>transform.vector.lower_outerproduct</code> (::mlir::transform::LowerOuterProductOp)</a></li><li><a href=#transformvectorlower_shape_cast-mlirtransformlowershapecastop><code>transform.vector.lower_shape_cast</code> (::mlir::transform::LowerShapeCastOp)</a></li><li><a href=#transformvectorlower_transfer-mlirtransformlowertransferop><code>transform.vector.lower_transfer</code> (::mlir::transform::LowerTransferOp)</a></li><li><a href=#transformvectorlower_transpose-mlirtransformlowertransposeop><code>transform.vector.lower_transpose</code> (::mlir::transform::LowerTransposeOp)</a></li><li><a href=#transformvectormaterialize_masks-mlirtransformmaterializemasksop><code>transform.vector.materialize_masks</code> (::mlir::transform::MaterializeMasksOp)</a></li><li><a href=#transformvectorsplit_transfer_full_partial-mlirtransformsplittransferfullpartialop><code>transform.vector.split_transfer_full_partial</code> (::mlir::transform::SplitTransferFullPartialOp)</a></li><li><a href=#transformvectortransfer_to_scf-mlirtransformtransfertoscfop><code>transform.vector.transfer_to_scf</code> (::mlir::transform::TransferToScfOp)</a></li></ul></li><li><a href=#transformhandletypeinterface-transformhandletypeinterface>TransformHandleTypeInterface (<code>TransformHandleTypeInterface</code>)</a><ul><li><a href=#methods>Methods:</a></li></ul></li><li><a href=#transformparamtypeinterface-transformparamtypeinterface>TransformParamTypeInterface (<code>TransformParamTypeInterface</code>)</a><ul><li><a href=#methods-1>Methods:</a></li></ul></li><li><a href=#transformvaluehandletypeinterface-transformvaluehandletypeinterface>TransformValueHandleTypeInterface (<code>TransformValueHandleTypeInterface</code>)</a><ul><li><a href=#methods-2>Methods:</a></li></ul></li><li><a href=#transformopinterface-transformopinterface>TransformOpInterface (<code>TransformOpInterface</code>)</a><ul><li><a href=#methods-3>Methods:</a></li></ul></li></ul></nav><h2 id=disclaimer>Disclaimer&nbsp;<a class=headline-hash href=#disclaimer>¶</a></h2><p><strong>This dialect is actively developed and may change frequently.</strong></p><p>To decrease the maintenance burden and churn, please post a description of
the intended use case on the MLIR forum. A few in-tree use cases are
currently supported:</p><ul><li>high-level transformations on &ldquo;structured ops&rdquo; (i.e. ops that operate on
chunks of data in a way that can be decomposed into operations on
smaller chunks of data and control flow) in Linalg, Tensor and Vector
dialects;</li><li>loop transformations in the SCF dialect.</li></ul><h2 id=overview>Overview&nbsp;<a class=headline-hash href=#overview>¶</a></h2><p>This dialect provides operations that can be used to control transformation
of the IR using a different portion of the IR. It refers to the IR being
transformed as payload IR, and to the IR guiding the transformation as
transform IR.</p><p>The main use case for this dialect is orchestrating fine-grain transformations
on individual IR objects (operations or values) or sets thereof. For example, it
may involve finding loop-like operations with specific properties (e.g., large
size) in the payload IR, applying loop tiling to those and only those
operations, and then applying loop unrolling to the inner loops produced by the
previous transformations. As such, it is not intended as a replacement for the
pass infrastructure, nor for the pattern rewriting infrastructure. In the most
common case, the transform IR will be processed and applied to the payload IR by
a pass. Transformations expressed by the transform dialect may be implemented
using the pattern infrastructure or any other relevant MLIR component.</p><p>The following IR gives a rough idea of what the operations in this dialect
may look like without using actually existing operations:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%0</span> <span class=p>=</span> transform<span class=p>.</span>loop<span class=p>.</span>find <span class=p>{</span> size <span class=p>&gt;</span> <span class=m>42</span> <span class=p>}</span> <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>interface<span class=p>&lt;</span>tileable<span class=p>&gt;</span>
<span class=nv>%1</span> <span class=p>=</span> transform<span class=p>.</span>compute_trailing_tile_size <span class=nv>%0</span> <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>index</span><span class=p>&gt;</span>
<span class=nv>%2</span><span class=p>:</span><span class=nl>2 =</span> transform<span class=p>.</span>loop<span class=p>.</span>tile <span class=nv>%0</span> tile_sizes<span class=p>(</span><span class=m>1</span><span class=p>,</span> <span class=m>4</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
      <span class=p>:</span> <span class=p>(!</span>transform<span class=p>.</span>interface<span class=p>&lt;</span>tileable<span class=p>&gt;)</span>
     <span class=p>-&gt;</span> <span class=p>(!</span>transform<span class=p>.</span>op<span class=p>&lt;</span>loop<span class=p>&gt;,</span> <span class=p>!</span>transform<span class=p>.</span>op<span class=p>&lt;</span>loop<span class=p>&gt;)</span>
<span class=nv>%3</span> <span class=p>=</span> transform<span class=p>.</span>get_op_result <span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=nv>%2#0</span> <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_value
transform<span class=p>.</span>assign_to_fast_memory <span class=nv>%3</span>
transform<span class=p>.</span>loop<span class=p>.</span>unroll <span class=nv>%1#1</span> <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>op<span class=p>&lt;</span>loop<span class=p>&gt;</span>
</code></pre></div><p>The values used in the Transform dialect may correspond to:</p><ul><li><p>sets of operations in the payload IR;</p></li><li><p>sets of values in the payload IR;</p></li><li><p>sets of parameters (attributes) known at the execution time of the
transform dialect.</p></li></ul><p>The former two kinds of values are also referred to as operation and value
<em>handles</em>, respectively. In the example above, <code>%0</code> corresponds to the set of
loops found in the payload IR that satisfy the condition, and <code>%2</code> correspond to
groups of outer and inner loops, respectively, produced by the tiling
transformation. <code>%3</code> corresponds to a set of values that are produced by the
outer loops after tiling. <code>%1</code> corresponds to a list of tile sizes selected for
each of the operations that <code>%0</code> corresponds to.</p><p>An operation handle such as <code>%0</code> may be associated with multiple payload
operations. This is conceptually a set of operations and no assumptions should
be made about the order of ops unless specified otherwise by the operation.
Similarly, a value handle such as <code>%3</code> may be associated with a set of payload
IR values. Transform dialect operations may take as operands and produce an
arbitrary combination of values representing handles and parameters. Most
Transform IR ops support operand values that are mapped to multiple payload
objects. They usually apply the respective transformation for every mapped
object (&ldquo;batched execution&rdquo;). Deviations from this convention are described in
the documentation of Transform IR ops.</p><p>The transform IR values have transform IR types, which should implement exactly one of:</p><ul><li><p><a href=/docs/Dialects/Transform/>TransformHandleTypeInterface</a>,</p></li><li><p><a href=/docs/Dialects/Transform/>TransformValueHandleTypeInterface</a>,</p></li><li><p><a href=/docs/Dialects/Transform/>TransformParamTypeInterface</a>.</p></li></ul><p>The goal of these type interfaces, beyond providing a common base for accepted
types, is to verify the properties of the associated objects. For example, a
handle type interface implementation may check whether all associated payload IR
operations implement the &ldquo;TileableOp&rdquo; interface or have a specific &ldquo;loop&rdquo; kind.
Similarly, a value handle type interface implementation may check if the
associated payload IR values are block arguments or have a specific type, or a
parameter type interface may check whether the associated attributes contain
non-negative integer values. These properties are used to statically indicate
pre- and post-conditions of a transformation connected to a Transform dialect
operation. The conditions are verified when payload objects operations are first
associated with a transform handle. By convention, Transform dialect operations
are expected to indicate narrow preconditions for their operands by enforcing
operand type constraints in the their definitions and verifiers. On the
contrary, operations are expected to have few constraints on their results.
Specific instances of a transform operation can then be created with a more
restricted result type than the constraint in the operation (e.g., the &ldquo;find&rdquo;
operation only constrains the result type to be a transform IR type while its
concrete instance can have a type with stricter constraints such as implementing
the &ldquo;tilable&rdquo; interface). The verification will then happen at transform
execution time. This approach allows one to capture payload IR operation
properties in the transform IR without resorting to excessive use of type casts
or coupling dialect extensions between themselves. It is a trade-off between
verbosity/complexity and static hardening, which can be revised in the future.</p><p>Overall, Transform IR ops are expected to be contained in a single top-level
op. Such top-level ops specify how to apply the transformations described
by the operations they contain, e.g., <code>transform.sequence</code> executes
transformations one by one and fails if any of them fails. Such ops are
expected to have the <code>PossibleTopLevelTransformOpTrait</code> and may be used
without arguments.</p><p>A program transformation expressed using the Transform dialect can be
programmatically triggered by calling:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=n>LogicalResult</span> <span class=n>transform</span><span class=o>::</span><span class=n>applyTransforms</span><span class=p>(</span>
    <span class=n>Operation</span> <span class=o>*</span><span class=n>payloadRoot</span><span class=p>,</span>
    <span class=k>const</span> <span class=n>RaggedArray</span><span class=o>&lt;</span><span class=n>transform</span><span class=o>::</span><span class=n>MappedValue</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>extraMappings</span><span class=p>,</span>
    <span class=n>TransformOpInterface</span> <span class=n>transform</span><span class=p>,</span>
    <span class=k>const</span> <span class=n>TransformOptions</span> <span class=o>&amp;</span><span class=n>options</span><span class=p>);</span>
</code></pre></div><p>that applies the transformations specified by the top-level <code>transform</code> to
payload IR contained in <code>payloadRoot</code>. The payload root operation will be
associated with the first argument of the entry block of the top-level transform
op. This block may have additional arguments, handles or parameters. They will
be associated with values provided as <code>extraMappings</code>. The call will report an
error and return if the wrong number of mappings is provided.</p><h2 id=dialect-extension-mechanism>Dialect Extension Mechanism&nbsp;<a class=headline-hash href=#dialect-extension-mechanism>¶</a></h2><p>This dialect is designed to be extensible, that is, clients of this dialect
are allowed to inject additional operations into this dialect using the
<code>TransformDialectExtension</code> mechanism. This allows the dialect to avoid a
dependency on the implementation of the transformation as well as to avoid
introducing dialect-specific transform dialects. In the example above,
the operations may have been injected by a notional <code>loop</code> dialect rather
than defined in this dialect, hence the common prefix.</p><p>It is recommended to prefix injected operations with one or several
dot-separated words that indicate which extension adds them. For
dialect-specific transformations, the prefix is naturally the name of the
dialect, e.g., <code>transform.affine.reschedule</code>. For dialect-agnostic
transformations (typically implemented using interfaces), the prefix may
be derived from the interface name or from a common concept, e.g.,
<code>transform.loop.tile</code> may apply to any loop-like operation that implements
<code>TileableOpInterface</code>. The C++ classes for the dialect extension should
include the prefix in their name, e.g., <code>AffineTransformDialectExtension</code> or
<code>LoopTransformDialectExtension</code> in the cases above. Unprefixed operation
names are reserved for ops defined directly in the Transform dialect.</p><p>Operations injected into the dialect must:</p><ul><li><p>Implement the <code>TransformOpInterface</code> to execute the corresponding
transformation on the payload IR.</p></li><li><p>Implement the <code>MemoryEffectsOpInterface</code> to annotate the effects of
the transform IR operation on the payload IR as well as on the mapping
between transform IR values and payload IR operations. See below for
the description of available effects.</p></li></ul><p>The presence of interface implementations is checked at runtime when the
dialect is loaded to allow for those implementations to be supplied by
separate dialect extensions if desired.</p><p>Similarly to operations, additional types can be injected into the dialect using
the same extension mechanism. The types must:</p><ul><li>Implement exactly one of <code>TransformHandleTypeInterface</code>,
<code>TransformValueHandleTypeInterface</code>, <code>TransformParamTypeInterface</code>.</li></ul><h2 id=side-effects>Side Effects&nbsp;<a class=headline-hash href=#side-effects>¶</a></h2><p>The Transform dialect relies on MLIR side effect modelling to enable
optimization of the transform IR. More specifically, it provides several
side effect resource objects and expects operations to describe their
effects on these resources.</p><ul><li><p><code>TransformMappingResource</code> - side effect resource corresponding to the
mapping between transform IR values and payload IR operations.</p><ul><li><p>An <code>Allocate</code> effect from this resource means creating a new mapping
entry, it is always accompanied by a <code>Write</code> effect.</p></li><li><p>A <code>Read</code> effect from this resource means accessing the mapping.</p></li><li><p>A <code>Free</code> effect on this resource indicates the removal of the mapping
entry, typically after a transformation that modifies the payload IR
operations associated with one of the transform IR operation&rsquo;s
operands. It is always accompanied by a <code>Read</code> effect.</p></li></ul></li><li><p><code>PayloadIRResource</code> - side effect resource corresponding to the payload
IR itself.</p><ul><li><p>A <code>Read</code> effect from this resource means accessing the payload IR.</p></li><li><p>A <code>Write</code> effect on this resource means mutating the payload IR. It is
almost always accompanied by a <code>Read</code>.</p></li></ul></li></ul><p>The typical flow of values in the transform IR is as follows. Most
operations produce new transform IR values and immediately associate them
with a list of payload IR operations. This corresponds to <code>Allocate</code> and
<code>Write</code> effects on the <code>TransformMappingResource</code>, and often requires at
least a <code>Read</code> effect on the <code>PayloadIRResource</code>. Transform operations that
only inspect the payload IR to produce new handles are usually limited to
these effects on their operands. Transform operations that mutate the
payload IR are thought to <em>consume</em> the handles provided as operands, that
is have the <code>Read</code> and <code>Free</code> effects on them. As with the usual memory
effects, using a value after it was freed is incorrect. In case of the
transform IR, this value is likely associated with payload IR operations
that were modified or even removed by the transformation, so it is
meaningless to refer to them. When further transformations are desired, the
transform operations can return <em>new</em> handles that can be read or consumed
by subsequent operations.</p><h2 id=execution-model>Execution Model&nbsp;<a class=headline-hash href=#execution-model>¶</a></h2><p>The transformation starts at the user-specified top-level transform IR
operation and applies to some user-specified payload IR scope, identified by
the payload IR op that contains the IR to transform. It is the
responsibility of the user to properly select the scope and/or to avoid the
transformations to modify the IR outside of the given scope. The top-level
transform IR operation may contain further transform operations and execute
them in the desired order.</p><p>Transformation application functions produce a tri-state status:</p><ul><li>success;</li><li>recoverable (silenceable) failure;</li><li>irrecoverable failure.</li></ul><p>Transformation container operations may intercept recoverable failures and
perform the required recovery steps thus succeeding themselves. On
the other hand, they must propagate irrecoverable failures. For such
failures, the diagnostics are emitted immediately whereas their emission is
postponed for recoverable failures. Transformation container operations may
also fail to recover from a theoretically recoverable failure, in which case
they can either propagate it to their parent or emit the diagnostic and turn
the failure into an irrecoverable one. A recoverable failure produced by
applying the top-level transform IR operation is considered irrecoverable.</p><p>Transformation container operations are allowed to &ldquo;step over&rdquo; some nested
operations if the application of some previous operation produced a failure.
This can be conceptually thought of as having a global &ldquo;recoverable error
register&rdquo; that is read/write accessed by each transform operation as a side
effect. The transformation is skipped if the register already contains an
error description, and the control flow proceeds to the following operation.</p><p>Note that a silenceable failure, if emitted, is a compiler <em>error</em> rather
than a warning. Transformations are expected to produce silenceable failures
if they haven&rsquo;t yet modified the payload IR, i.e. when reporting a
precondition failure, and an irrecoverable failure when they modified the IR
in a way that is contrary to the semantics of the transform operation or
would fail a postcondition. Some &ldquo;navigation&rdquo; operations that identify
payload IR targets for the following transformation may have a conceptual
&ldquo;failure to match&rdquo; that is considered a successful execution in the
execution model but results in handles associated with empty payload IR
operation lists.</p><h2 id=handle-invalidation>Handle Invalidation&nbsp;<a class=headline-hash href=#handle-invalidation>¶</a></h2><p>The execution model of the transform dialect allows a payload IR operation to be
associated with <em>multiple</em> handles as well as nested payload IR operations to be
associated with different handles. Similarly, a payload IR value may be
associated with multiple transform IR value handles. When a transform IR
operation consumes a handle, it usually indicates that the corresponding payload
IR object was destroyed and should no longer be referenced. Transform IR handles
that <em>may</em> be pointing to an erased payload IR object are <em>invalidated</em>. The
mere presence of an invalidated handle in the transform IR is not a problem, but
<em>using</em> it results in undefined behavior. Invalidated handles can be thought of
as dangling pointers. Note that the <em>entire</em> handle is invalidated, even if some
of the payload IR objects associated with it remain live.</p><p>The following handle invalidation rules apply.</p><ul><li><p>When an operation handle is consumed, are invalidated:</p><ul><li><p>operation handles associated with one of the payload operations that the
consumed handle is associated with;</p></li><li><p>operation handles associated with one of the operations <em>nested</em> in the
payload operations described above;</p></li><li><p>value handles associated with any result of any operation described above;</p></li><li><p>value handles associated with any argument of a block contained in a
region attached to any operation described above.</p></li></ul></li><li><p>When a value handle is consumed, are invalidated:</p><ul><li><p>operation handles associated with payload operations that produce as
result any value associated with the consumed handle (when the associated
is an operation result);</p></li><li><p>operation handles associated with payload operations <em>nested</em> in the
payload operations described above;</p></li><li><p>operation handles associated with payload operations (recursively)
<em>contained</em> in the block that defines as argument any value associated
with the consumed handle (when the associated value is a block argument);
note that the adjacent blocks are not affected;</p></li><li><p>value handles associated with any result of any operation described above,
including all results of the operation defining as result the value
associated with the consumed handle;</p></li><li><p>value handles associated with any argument of a block contained in a
region attached to any operation described above.</p></li></ul></li></ul><p>More intuitively, consuming a handle invalidates any handle that may be pointing
to an object defined or contained in the payload IR subtree rooted at the
closest operation or block.</p><p>The Transform dialect infrastructure has the capability of checking whether
the transform IR op operand is invalidated before applying the
transformation. However, such a check is computationally expensive and
must be enabled explicitly through <code>TransformOptions</code>. Additionally, the
<code>transform-dialect-check-uses</code> pass emits warnings when a handle may be used
after it has been consumed, but does so abstractly, without processing the
payload IR.</p><p>Values associated with parameters (non-handles) cannot be invalidated.</p><h2 id=intended-use-and-integrations>Intended Use and Integrations&nbsp;<a class=headline-hash href=#intended-use-and-integrations>¶</a></h2><p>The transformation control infrastructure provided by this dialect is
positioned roughly between rewrite patterns and passes. A transformation
that is executed by a transform operation is likely to be sufficiently
complex to require at least a set of patterns to be implemented. It is also
expected to be more focused than a pass: a pass typically applies identical
transformations everywhere in the IR, a transform dialect-controlled
transformation would apply to a small subset of operations selected, e.g.,
by a pattern-matching operation or generated by a previous transformation.
It is discouraged, although technically possible, to run a pass pipeline as
part of the transform op implementation.</p><p>One of the main scenarios for using this dialect is fine-grain chaining of
transformations. For example, a loop-like operation may see its iteration
domain split into two parts, implemented as separate loops (transformation
known as index-set splitting), each of which is then transformed differently
(e.g., the first loop is tiled and the second unrolled) with the necessary
enabling and cleanup patterns around the main transformation:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// &lt;generate %loop, e.g., by pattern-matching&gt;
</span><span class=c>// ...
</span><span class=c></span><span class=nv>%parts</span><span class=p>:</span><span class=nl>2 =</span> transform<span class=p>.</span>loop<span class=p>.</span>split <span class=nv>%loop</span> <span class=p>{</span> <span class=nl>upper_bound_divisible_by =</span> <span class=m>8</span> <span class=p>}</span>
transform<span class=p>.</span>loop<span class=p>.</span>tile <span class=nv>%parts#0</span> <span class=p>{</span> <span class=nl>tile_sizes =</span> <span class=p>[</span><span class=m>8</span><span class=p>]</span> <span class=p>}</span>
transform<span class=p>.</span>loop<span class=p>.</span>unroll <span class=nv>%parts#1</span> <span class=p>{</span> full <span class=p>}</span>
</code></pre></div><p>This composition would have been difficult to implement as separate passes
since the hypothetical &ldquo;tiling&rdquo; and &ldquo;unrolling&rdquo; pass would need to somehow
differentiate between the parts of the loop produced by the previous pass
(both are the same operation, and it is likely undesirable to pollute the
operation with pass-specific information). Implementing passes that run the
combined transformation would have run into the combinatorial explosion
issue due to multiple possible transform compositions or into the need for
deep pass parameterization, the ultimate form of which is an ad-hoc dialect
to specify which transformations the pass should run. The transform dialect
provides a uniform, extensible mechanism for controlling transformations in
such cases.</p><p>The transform dialect is supposed to be consumed by an &ldquo;interpreter&rdquo; pass
that drives the application of transformations. To ensure extensibility and
composability, this pass is not expected to actually perform the
transformations specified by the ops. Instead, the transformations are
implemented by the transform ops themselves via <code>TransformOpInterface</code>. The
pass serves as the entry point, handles the flow of transform operations and
takes care of bookkeeping. As such, the transform dialect does not provide
the interpreter pass. Instead, it provides a set of utilities that can be
used by clients to define their own interpreter passes or as part of a more
complex pass. For example, the mapping between values in the transform IR
and operations in the payload IR, or the function that applies the
transformations specified by ops in the given block sequentially. Note that
a transform op may have regions with further transform ops in them, with
the op itself guiding how to dispatch the transformation control flow to
those regions. This approach allows clients to decide on the relative
location of the transform IR in their input (e.g., nested modules, separate
modules, optional regions to certain operations, etc.), register additional
transform operations and perform client-specific bookkeeping.</p><h2 id=effects-on-the-infrastructure>Effects on the Infrastructure&nbsp;<a class=headline-hash href=#effects-on-the-infrastructure>¶</a></h2><p>Although scoped to a single dialect, this functionality conceptually belongs
to the MLIR infrastructure. It aims to be minimally intrusive and opt-in.</p><p>Some infrastructural components may grow extra functionality to support the
transform dialect. In particular, the pattern infrastructure may add extra
hooks to identify the &ldquo;main results&rdquo; of a transformation or to notify
external observers about changes made to certain operations. These are not
expected to affect the existing uses of the infrastructure.</p><p>For the sake of reusability, transformations should be implemented as
utility functions that are called from the interface methods of transform
ops rather than having the methods directly act on the payload IR.</p><h2 id=type-definitions>Type Definitions&nbsp;<a class=headline-hash href=#type-definitions>¶</a></h2><h3 id=anyoptype>AnyOpType&nbsp;<a class=headline-hash href=#anyoptype>¶</a></h3><p>Syntax: <code>!transform.any_op</code></p><p>Transform IR handle that can be associated with a list of arbitrary
Payload IR operations.</p><h3 id=anyvaluetype>AnyValueType&nbsp;<a class=headline-hash href=#anyvaluetype>¶</a></h3><p>Syntax: <code>!transform.any_value</code></p><p>Transform IR value that can be associated with a list of Payload IR values.</p><h3 id=operationtype>OperationType&nbsp;<a class=headline-hash href=#operationtype>¶</a></h3><p>Syntax:</p><pre><code>!transform.op&lt;
  ::llvm::StringRef   # operation_name
&gt;
</code></pre><p>Transform IR handle that can be associated with a list of Payload IR
operations with the specified operation name.</p><h4 id=parameters>Parameters:&nbsp;<a class=headline-hash href=#parameters>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>operation_name</td><td style=text-align:center><code>::llvm::StringRef</code></td><td>Name of the allowed payload operation</td></tr></tbody></table><h3 id=paramtype>ParamType&nbsp;<a class=headline-hash href=#paramtype>¶</a></h3><p>Syntax:</p><pre><code>!transform.param&lt;
  ::mlir::Type   # type
&gt;
</code></pre><p>Transform IR value that can be associated with the list of parameters
of the given type. Types are currently limited to integers, but may be
extended in the future to other types values of which can be contained
in attributes.</p><h4 id=parameters-1>Parameters:&nbsp;<a class=headline-hash href=#parameters-1>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>type</td><td style=text-align:center><code>::mlir::Type</code></td><td>Underlying type of the parameter</td></tr></tbody></table><h2 id=core-operations>Core Operations&nbsp;<a class=headline-hash href=#core-operations>¶</a></h2><h3 id=transformalternatives-mlirtransformalternativesop><code>transform.alternatives</code> (::mlir::transform::AlternativesOp)&nbsp;<a class=headline-hash href=#transformalternatives-mlirtransformalternativesop>¶</a></h3><p>Attempts sequences of transforms until one succeeds</p><p>Syntax:</p><pre><code>operation ::= `transform.alternatives` ($scope^ `:` type($scope))? (`-&gt;` type($results)^)? attr-dict-with-keyword regions
</code></pre><p>This op may have an arbitrary number of regions, each of which represents a
sequence of transform operations to be applied to the same payload IR. The
regions are visited in order of appearance, and transforms in them are
applied in their respective order of appearance. If one of these transforms
fails to apply, the remaining ops in the same region are skipped an the next
region is attempted. If all transformations in a region succeed, the
remaining regions are skipped and the entire &ldquo;alternatives&rdquo; transformation
succeeds. If all regions contained a failing transformation, the entire
&ldquo;alternatives&rdquo; transformation fails.</p><p>It is up to the nested operations to define which errors are &ldquo;recoverable&rdquo;
(or &ldquo;silenceable&rdquo;) and allow another alternatives to be attempted, and which
errors should be propagated without attempting the other alternatives.</p><p>The single operand of this operation is the scope in which the alternative
transformation sequences are attempted, that is, an operation in the payload
IR that contains all the other operations that may be modified by the
transformations. The scope operation must be isolated from above. There is
no check that the transforms are indeed scoped as their &ldquo;apply&rdquo; methods can
be arbitrarily complex. Therefore it is the responsibility of the user to
ensure that the transforms are scoped correctly, or to produce an
irrecoverable error and thus abort the execution without attempting the
remaining alternatives. Note that the payload IR outside of the given scope
is not necessarily in the valid state, or even accessible to the
transformation.</p><p>The changes to the IR within the scope performed by transforms in the failed
alternative region are reverted before attempting the next region.
Practically, this is achieved by cloning the scope. Therefore it is advised
to limit the scope as much as possible and place the most likely
alternatives early in the region list. The operation is also isolated from
above and requires rediscovering the operations within the given scope to
avoid additional handle invalidation. The latter restriction may be lifted
in the future.</p><p>Each of the regions may yield transform IR handles. The handles of the first
successful alternative region are returned as the results of the
&ldquo;alternatives&rdquo; op. Therefore, each alternative region must yield the same
number of results, which should also match the number and the types of the
&ldquo;alternatives&rdquo; op results.</p><p>Remark: this op allows one to implement a simple &ldquo;try&rdquo; construct as follows:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%result</span> <span class=p>=</span> transform<span class=p>.</span>alternatives <span class=nv>%scope</span> <span class=p>{</span>
<span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation<span class=p>):</span>
  <span class=c>// Try a fallible transformation.
</span><span class=c></span>  <span class=nv>%0</span> <span class=p>=</span> transform<span class=p>.</span>fallible <span class=nv>%arg0</span> <span class=c>// ...
</span><span class=c></span>  <span class=c>// If succeeded, yield the the result of the transformation.
</span><span class=c></span>  transform<span class=p>.</span>yield <span class=nv>%0</span> <span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation
<span class=p>},</span> <span class=p>{</span>
<span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation<span class=p>):</span>
  <span class=c>// Otherwise, the second alternative is tried and it always succeeds by
</span><span class=c></span>  <span class=c>// returning the original handle.
</span><span class=c></span>  transform<span class=p>.</span>yield <span class=nv>%arg0</span> <span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation
<span class=p>}</span>
</code></pre></div><p>Traits: IsolatedFromAbove, PossibleTopLevelTransformOpTrait, SingleBlockImplicitTerminator&lt;::mlir::transform::YieldOp></p><p>Interfaces: MemoryEffectOpInterface, RegionBranchOpInterface, TransformOpInterface</p><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>scope</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformcast-mlirtransformcastop><code>transform.cast</code> (::mlir::transform::CastOp)&nbsp;<a class=headline-hash href=#transformcast-mlirtransformcastop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.cast` $input attr-dict `:` type($input) `to` type($output)
</code></pre><p>Traits: TransformEachOpTrait</p><p>Interfaces: CastOpInterface, MemoryEffectOpInterface, TransformOpInterface</p><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>input</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>output</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformforeach_match-mlirtransformforeachmatchop><code>transform.foreach_match</code> (::mlir::transform::ForeachMatchOp)&nbsp;<a class=headline-hash href=#transformforeach_match-mlirtransformforeachmatchop>¶</a></h3><p>Applies named sequences when a named matcher succeeds</p><p>Syntax:</p><pre><code>operation ::= `transform.foreach_match` `in` $root custom&lt;ForeachMatchSymbols&gt;($matchers, $actions) attr-dict `:` functional-type($root, $updated)
</code></pre><p>Given a pair of co-indexed lists of transform dialect symbols (such as
<code>transform.named_sequence</code>), walks the payload IR associated with the root
handle and interprets the symbols as matcher/action pairs by applying the
body of the corresponding symbol definition. The symbol from the first list
is the matcher part: if it results in a silenceable error, the error is
silenced and the next matcher is attempted. Definite failures from any
matcher stop the application immediately and are propagated unconditionally.
If none of the matchers succeeds, the next payload operation in walk order
(post-order at the moment of writing, double check <code>Operation::walk</code>) is
matched. If a matcher succeeds, the co-indexed action symbol is applied and
the following matchers are not applied to the same payload operation. If the
action succeeds, the next payload operation in walk order is matched. If it
fails, both silenceable and definite errors are propagated as the result of
this op.</p><p>The matcher symbol must take one operand of a type that implements the same
transform dialect interface as the <code>root</code> operand (a check is performed at
application time to see if the associated payload satisfies the constraints
of the actual type). It must not consume the operand as multiple matchers
may be applied. The matcher may produce any number of results. The action
symbol paired with the matcher must take the same number of arguments as the
matcher has results, and these arguments must implement the same transform
dialect interfaces, but not necessarily have the exact same type (again, a
check is performed at application time to see if the associated payload
satisfies the constraints of actual types on both sides). The action symbol
may not have results. The actions are expected to only modify payload
operations nested in the <code>root</code> payload operations associated with the
operand of this transform operation.</p><p>This operation consumes the operand and produces a new handle associated
with the same payload. This is necessary to trigger invalidation of handles
to any of the payload operations nested in the payload operations associated
with the operand, as those are likely to be modified by actions. Note that
the root payload operation associated with the operand are not matched.</p><p>The operation succeeds if none of the matchers produced a definite failure
during application and if all of the applied actions produced success. Note
that it also succeeds if all the matchers failed on all payload operations,
i.e. failure to apply is not an error. The operation produces a silenceable
failure if any applied action produced a silenceable failure. In this case,
the resulting handle is associated with an empty payload. The operation
produces a definite failure if any of the applied matchers or actions
produced a definite failure.</p><p>Interfaces: MemoryEffectOpInterface, SymbolUserOpInterface, TransformOpInterface</p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matchers</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>symbol ref array attribute</td></tr><tr><td style=text-align:center><code>actions</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>symbol ref array attribute</td></tr></tbody></table><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>root</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>updated</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformforeach-mlirtransformforeachop><code>transform.foreach</code> (::mlir::transform::ForeachOp)&nbsp;<a class=headline-hash href=#transformforeach-mlirtransformforeachop>¶</a></h3><p>Executes the body for each payload op</p><p>Syntax:</p><pre><code>operation ::= `transform.foreach` $target `:` type($target) (`-&gt;` type($results)^)? $body attr-dict
</code></pre><p>This op has exactly one region with exactly one block (&ldquo;body&rdquo;). The body is
executed for each payload op that is associated to the target operand in an
unbatched fashion. I.e., the block argument (&ldquo;iteration variable&rdquo;) is always
mapped to exactly one payload op.</p><p>This op always reads the target handle. Furthermore, it consumes the handle
if there is a transform op in the body that consumes the iteration variable.
This op does not return anything.</p><p>The transformations inside the body are applied in order of their
appearance. During application, if any transformation in the sequence fails,
the entire sequence fails immediately leaving the payload IR in potentially
invalid state, i.e., this operation offers no transformation rollback
capabilities.</p><p>This op generates as many handles as the terminating YieldOp has operands.
For each result, the payload ops of the corresponding YieldOp operand are
merged and mapped to the same resulting handle.</p><p>Traits: SingleBlockImplicitTerminator&lt;::mlir::transform::YieldOp></p><p>Interfaces: MemoryEffectOpInterface, RegionBranchOpInterface, TransformOpInterface</p><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformget_closest_isolated_parent-mlirtransformgetclosestisolatedparentop><code>transform.get_closest_isolated_parent</code> (::mlir::transform::GetClosestIsolatedParentOp)&nbsp;<a class=headline-hash href=#transformget_closest_isolated_parent-mlirtransformgetclosestisolatedparentop>¶</a></h3><p>Gets handles to the closest isolated-from-above parents</p><p>Syntax:</p><pre><code>operation ::= `transform.get_closest_isolated_parent` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>The handles defined by this Transform op correspond to the closest isolated
from above ancestor of the Payload IR operations associated with its
operand. If any of the given Payload IR ops has no such parent (unlikely as
there usually is a top-level ModuleOp), the transformation is considered to
have failed.</p><p>Ancestor ops follow the same order as the ops associated with the
operand, except for potential duplicates (multiple Payload IR ops associated
with the operand have the same parent) for which the ancestor will only be
listed once for the first time it occurs. For example, given the list
&ldquo;(childof(A), childof(B), childof(B), childof(A), childof(B))&rdquo;, the
resulting list will be just &ldquo;(A, B)&rdquo;. Note that no other semantic ordering
is applied, e.g., &ldquo;B&rdquo; may itself be a parent of &ldquo;A&rdquo;. This may have an impact
on the further transformation applied to the handle produced here.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>parent</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformget_consumers_of_result-mlirtransformgetconsumersofresult><code>transform.get_consumers_of_result</code> (::mlir::transform::GetConsumersOfResult)&nbsp;<a class=headline-hash href=#transformget_consumers_of_result-mlirtransformgetconsumersofresult>¶</a></h3><p>Get handle to the consumers of this operation&rsquo;s result number</p><p>Syntax:</p><pre><code>operation ::= `transform.get_consumers_of_result` $target `[` $result_number `]` attr-dict `:` functional-type(operands, results)
</code></pre><p>The handle defined by this Transform op corresponds to all operations that
consume the SSA value defined by the <code>target</code> and <code>result_number</code>
arguments.
This operation applies to a single payload operation, otherwise it
definitely fails.
The return handle points to the consuming operations operations, which can
be empty.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result_number</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>consumers</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformget_defining_op-mlirtransformgetdefiningop><code>transform.get_defining_op</code> (::mlir::transform::GetDefiningOp)&nbsp;<a class=headline-hash href=#transformget_defining_op-mlirtransformgetdefiningop>¶</a></h3><p>Get handle to the defining op of a value</p><p>Syntax:</p><pre><code>operation ::= `transform.get_defining_op` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>The handle defined by this Transform op corresponds to the defining op of
the targeted value.</p><p>This transform fails silently if the targeted value is a block argument.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformValueHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformget_producer_of_operand-mlirtransformgetproducerofoperand><code>transform.get_producer_of_operand</code> (::mlir::transform::GetProducerOfOperand)&nbsp;<a class=headline-hash href=#transformget_producer_of_operand-mlirtransformgetproducerofoperand>¶</a></h3><p>Get handle to the producer of this operation&rsquo;s operand number</p><p>Syntax:</p><pre><code>operation ::= `transform.get_producer_of_operand` $target `[` $operand_number `]` attr-dict `:` functional-type(operands, results)
</code></pre><p>The handle defined by this Transform op corresponds to operation that
produces the SSA value defined by the <code>target</code> and <code>operand_number</code>
arguments. If the origin of the SSA value is not an operations (i.e. it is
a block argument), the transform silently fails.
The return handle points to only the subset of successfully produced
computational operations, which can be empty.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-2>Attributes:&nbsp;<a class=headline-hash href=#attributes-2>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_number</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>producer</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformget_result-mlirtransformgetresultop><code>transform.get_result</code> (::mlir::transform::GetResultOp)&nbsp;<a class=headline-hash href=#transformget_result-mlirtransformgetresultop>¶</a></h3><p>Get handle to the a result of the targeted op</p><p>Syntax:</p><pre><code>operation ::= `transform.get_result` $target `[` $result_number `]` attr-dict `:` functional-type(operands, results)
</code></pre><p>The handle defined by this Transform op corresponds to the OpResult with
<code>result_number</code> that is defined by the given <code>target</code> operation.</p><p>This transform fails silently if the targeted operation does not have enough
results. It reads the target handle and produces the result handle.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-3>Attributes:&nbsp;<a class=headline-hash href=#attributes-3>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result_number</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformValueHandleTypeInterface instance</td></tr></tbody></table><h3 id=transforminclude-mlirtransformincludeop><code>transform.include</code> (::mlir::transform::IncludeOp)&nbsp;<a class=headline-hash href=#transforminclude-mlirtransformincludeop>¶</a></h3><p>Includes a named transform sequence</p><p>Syntax:</p><pre><code>operation ::= `transform.include` $target `failures` `(` $failure_propagation_mode `)``(` $operands `)` attr-dict `:` functional-type($operands, $results)
</code></pre><p>The application of this transform operation is equivalent to applying the
operations contained in the named transform sequence with operands being
remapped to block arguments. The behavior of the operation when a
transformation in the included named sequence produces a silenceable error
is controlled by the <code>failure_propagation_mode</code> attribute. When set to
<code>propagate</code>, the failure of any nested transformation in the sequence
implies immediate failure of the entire sequence with a silenceable error,
and no further transformation is attempted. When set to <code>suppress</code>,
silenceable errors in nested operations are ignored and further
transformations are applied. Beware that even silenceable errors may leave
the payload IR in a state unsuitable for further transformations. It is the
responsibility of the user to ensure the following transformations are
robust enough when errors are suppressed. Definite errors are propagated
immediately regardless of the mode. The objects associated with the results
of this operation are the same as those associated with the operands of the
<code>transform.yield</code> in the referenced named sequence.</p><p>Interfaces: CallOpInterface, MatchOpInterface, MemoryEffectOpInterface, SymbolUserOpInterface, TransformOpInterface</p><h4 id=attributes-4>Attributes:&nbsp;<a class=headline-hash href=#attributes-4>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td style=text-align:center>::mlir::SymbolRefAttr</td><td>symbol reference attribute</td></tr><tr><td style=text-align:center><code>failure_propagation_mode</code></td><td style=text-align:center>::mlir::transform::FailurePropagationModeAttr</td><td>Silenceable error propagation policy</td></tr></tbody></table><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operands</code></td><td>any transform handle or parameter</td></tr></tbody></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>any transform handle or parameter</td></tr></tbody></table><h3 id=transformmatchoperation_name-mlirtransformmatchoperationnameop><code>transform.match.operation_name</code> (::mlir::transform::MatchOperationNameOp)&nbsp;<a class=headline-hash href=#transformmatchoperation_name-mlirtransformmatchoperationnameop>¶</a></h3><p>Matches a single operation of one of the given kinds</p><p>Syntax:</p><pre><code>operation ::= `transform.match.operation_name` $operand_handle $op_names attr-dict `:` type($operand_handle)
</code></pre><p>Succeeds if the operation associated with the operand handle has one of the
given operation names. Produces a silenceable failure otherwise.</p><p>If more than one payload operation is associated with the operand handle,
produces a definite failure.</p><p>Traits: SingleOpMatcher</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-5>Attributes:&nbsp;<a class=headline-hash href=#attributes-5>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>op_names</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>string array attribute</td></tr></tbody></table><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchparamcmpi-mlirtransformmatchparamcmpiop><code>transform.match.param.cmpi</code> (::mlir::transform::MatchParamCmpIOp)&nbsp;<a class=headline-hash href=#transformmatchparamcmpi-mlirtransformmatchparamcmpiop>¶</a></h3><p>Matches if two parameter lists are associated with the same value</p><p>Syntax:</p><pre><code>operation ::= `transform.match.param.cmpi` $predicate $param `,` $reference attr-dict `:` type($param)
</code></pre><p>Succeeds if all of the co-indexed values associated with the given
parameters relate as specified by the predicate (greater than, less than,
equal to, or their combinations). Comparison treats all values as signed.
Produces a silenceable failure otherwise.</p><p>Traits: SameTypeOperands</p><p>Interfaces: MatchOpInterface, MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-6>Attributes:&nbsp;<a class=headline-hash href=#attributes-6>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>predicate</code></td><td style=text-align:center>::mlir::transform::MatchCmpIPredicateAttr</td><td>allowed 32-bit signless integer cases: 0, 1, 2, 3, 4, 5</td></tr></tbody></table><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>param</code></td><td>TransformParamTypeInterface instance</td></tr><tr><td style=text-align:center><code>reference</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmerge_handles-mlirtransformmergehandlesop><code>transform.merge_handles</code> (::mlir::transform::MergeHandlesOp)&nbsp;<a class=headline-hash href=#transformmerge_handles-mlirtransformmergehandlesop>¶</a></h3><p>Merges handles into one pointing to the union of payload ops</p><p>Syntax:</p><pre><code>operation ::= `transform.merge_handles` ($deduplicate^)? $handles attr-dict `:` type($result)
</code></pre><p>Creates a new Transform IR handle value that points to the same Payload IR
operations as the operand handles. The Payload IR operations are listed
in the same order as they are in the operand handles, grouped by operand
handle, e.g., all Payload IR operations associated with the first handle
come first, then all Payload IR operations associated with the second handle
and so on. If <code>deduplicate</code> is set, do not add the given Payload IR
operation more than once to the final list regardless of it coming from the
same or different handles. Consumes the operands and produces a new handle.</p><p>Traits: SameOperandsAndResultType</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-7>Attributes:&nbsp;<a class=headline-hash href=#attributes-7>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>deduplicate</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-12>Operands:&nbsp;<a class=headline-hash href=#operands-12>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>handles</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformnamed_sequence-mlirtransformnamedsequenceop><code>transform.named_sequence</code> (::mlir::transform::NamedSequenceOp)&nbsp;<a class=headline-hash href=#transformnamed_sequence-mlirtransformnamedsequenceop>¶</a></h3><p>Named transform sequence that can be included elsewhere</p><p>Defines a named (callable, function-like) sequence of other Transform
dialect operations that can be included using <code>transform.include</code> as part of
another Transform dialect construct. This sequence is not processed
immediately but rather dispatched to when the inclusion is processed. The
arguments and results can be used to communicate a subset of mapping into
the named sequence. The sequence must consist of a single block and end with
a <code>transform.yield</code> terminator. The operands of the terminator become the
results of the <code>transform.include</code>.</p><p>When dispatched to, the operations in the named sequence are executed one by
one, similarly to the regular unnamed sequence. The failure propagation mode
is specified on the <code>transform.include</code>. Different inclusions may use
different failure propagation modes. This transform operation always
succeeds by itself, but the inclusion may fail if any of the operations
fail.</p><p>Named sequences can only appear at the top-level of the Transform dialect
nesting structure. That is, they cannot be nested in other Transform dialect
operations. Furthermore, one of the ancestors must have the <code>SymbolTable</code>
trait and have the <code>transform.with_named_sequence</code> attribute attached.</p><p>Named sequences may include other named sequences via <code>transform.include</code>,
but recursion is <em>not</em> allowed.</p><p>Traits: IsolatedFromAbove</p><p>Interfaces: CallableOpInterface, FunctionOpInterface, MemoryEffectOpInterface, Symbol, TransformOpInterface</p><h4 id=attributes-8>Attributes:&nbsp;<a class=headline-hash href=#attributes-8>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>sym_name</code></td><td style=text-align:center>::mlir::StringAttr</td><td>string attribute</td></tr><tr><td style=text-align:center><code>function_type</code></td><td style=text-align:center>::mlir::TypeAttr</td><td>function type attribute</td></tr><tr><td style=text-align:center><code>sym_visibility</code></td><td style=text-align:center>::mlir::StringAttr</td><td>string attribute</td></tr><tr><td style=text-align:center><code>arg_attrs</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Array of dictionary attributes</td></tr><tr><td style=text-align:center><code>res_attrs</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Array of dictionary attributes</td></tr></tbody></table><h3 id=transformpdl_match-mlirtransformpdlmatchop><code>transform.pdl_match</code> (::mlir::transform::PDLMatchOp)&nbsp;<a class=headline-hash href=#transformpdl_match-mlirtransformpdlmatchop>¶</a></h3><p>Finds ops that match the named PDL pattern</p><p>Syntax:</p><pre><code>operation ::= `transform.pdl_match` $pattern_name `in` $root attr-dict `:` functional-type(operands, results)
</code></pre><p>Find Payload IR ops nested within the Payload IR op associated with the
operand that match the PDL pattern identified by its name. The pattern is
expected to be defined in the closest surrounding <code>WithPDLPatternsOp</code>.</p><p>Produces a Transform IR value associated with the list of Payload IR ops
that matched the pattern. The order of results in the list is that of the
Operation::walk, clients are advised not to rely on a specific order though.
If the operand is associated with multiple Payload IR ops, finds matching
ops nested within each of those and produces a single list containing all
of the matched ops.</p><p>The transformation is considered successful regardless of whether some
Payload IR ops actually matched the pattern and only fails if the pattern
could not be looked up or compiled.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-9>Attributes:&nbsp;<a class=headline-hash href=#attributes-9>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>pattern_name</code></td><td style=text-align:center>::mlir::SymbolRefAttr</td><td>symbol reference attribute</td></tr></tbody></table><h4 id=operands-13>Operands:&nbsp;<a class=headline-hash href=#operands-13>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>root</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matched</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformparamconstant-mlirtransformparamconstantop><code>transform.param.constant</code> (::mlir::transform::ParamConstantOp)&nbsp;<a class=headline-hash href=#transformparamconstant-mlirtransformparamconstantop>¶</a></h3><p>Produces a new transform dialect parameter value associated with the given attribute</p><p>Syntax:</p><pre><code>operation ::= `transform.param.constant` $value attr-dict `-&gt;` type($param)
</code></pre><p>Produces a new transform dialect parameter associated with the singleton
list containing the given attribute. The operation itself always succeeds,
but the general association check may fail if the parameter type does not
accept the given kind of attribute as valid.</p><p>Traits: ParamProducerTransformOpTrait</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-10>Attributes:&nbsp;<a class=headline-hash href=#attributes-10>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td style=text-align:center>::mlir::Attribute</td><td>any attribute</td></tr></tbody></table><h4 id=results-12>Results:&nbsp;<a class=headline-hash href=#results-12>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>param</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformprint-mlirtransformprintop><code>transform.print</code> (::mlir::transform::PrintOp)&nbsp;<a class=headline-hash href=#transformprint-mlirtransformprintop>¶</a></h3><p>Dump each payload op</p><p>Syntax:</p><pre><code>operation ::= `transform.print` $target attr-dict (`:` type($target)^)?
</code></pre><p>This op dumps each payload op that is associated with the <code>target</code> operand
to stderr. It also prints the <code>name</code> string attribute. If no target is
specified, the top-level op is dumped.</p><p>This op is useful for printf-style debugging.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-11>Attributes:&nbsp;<a class=headline-hash href=#attributes-11>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>name</code></td><td style=text-align:center>::mlir::StringAttr</td><td>string attribute</td></tr></tbody></table><h4 id=operands-14>Operands:&nbsp;<a class=headline-hash href=#operands-14>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformreplicate-mlirtransformreplicateop><code>transform.replicate</code> (::mlir::transform::ReplicateOp)&nbsp;<a class=headline-hash href=#transformreplicate-mlirtransformreplicateop>¶</a></h3><p>Lists payload ops multiple times in the new handle</p><p>Syntax:</p><pre><code>operation ::= `transform.replicate` `num` `(` $pattern `)` $handles attr-dict `:` type($pattern) `,` type($handles)
</code></pre><p>Produces a new handle associated with a list of payload IR ops that is
computed by repeating the list of payload IR ops associated with the
operand handle as many times as the &ldquo;pattern&rdquo; handle has associated
operations. For example, if pattern is associated with [op1, op2] and the
operand handle is associated with [op3, op4, op5], the resulting handle
will be associated with [op3, op4, op5, op3, op4, op5].</p><p>This transformation is useful to &ldquo;align&rdquo; the sizes of payload IR lists
before a transformation that expects, e.g., identically-sized lists. For
example, a transformation may be parameterized by same notional per-target
size computed at runtime and supplied as another handle, the replication
allows this size to be computed only once and used for every target instead
of replicating the computation itself.</p><p>Note that it is undesirable to pass a handle with duplicate operations to
an operation that consumes the handle. Handle consumption often indicates
that the associated payload IR ops are destroyed, so having the same op
listed more than once will lead to double-free. Single-operand
MergeHandlesOp may be used to deduplicate the associated list of payload IR
ops when necessary. Furthermore, a combination of ReplicateOp and
MergeHandlesOp can be used to construct arbitrary lists with repetitions.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=operands-15>Operands:&nbsp;<a class=headline-hash href=#operands-15>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>pattern</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>handles</code></td><td>any transform handle or parameter</td></tr></tbody></table><h4 id=results-13>Results:&nbsp;<a class=headline-hash href=#results-13>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>replicated</code></td><td>any transform handle or parameter</td></tr></tbody></table><h3 id=transformsequence-mlirtransformsequenceop><code>transform.sequence</code> (::mlir::transform::SequenceOp)&nbsp;<a class=headline-hash href=#transformsequence-mlirtransformsequenceop>¶</a></h3><p>Contains a sequence of other transform ops to apply</p><p>Syntax:</p><pre><code>operation ::= `transform.sequence` custom&lt;SequenceOpOperands&gt;($root, type($root), $extra_bindings, type($extra_bindings)) (`-&gt;` type($results)^)? `failures` `(` $failure_propagation_mode `)` attr-dict-with-keyword regions
</code></pre><p>The transformations indicated by the sequence are applied in order of their
appearance. Each value produced by a transformation within the sequence
corresponds to a group of operations or values in the payload IR, or to a
group of parameters, depending on the type of the value. The behavior of the
operation when a nested transformation produces a silenceable error is
controlled by the <code>failure_propagation_mode</code> attribute. When set to
<code>propagate</code>, the failure of any nested transformation in the sequence
implies immediate failure of the entire sequence with a silenceable error,
and no further transformation is attempted. When set to <code>suppress</code>,
silenceable errors in nested operations are ignored and further
transformations are applied. Beware that even silenceable errors may leave
the payload IR in a state unsuitable for further transformations. It is the
responsibility of the caller to ensure the following transformations are
robust enough when errors are suppressed. Definite errors reported by nested
transformations abort the sequence regardless of the propagation mode. The
set of modes may be extended in the future, e.g., to collect silenceable
errors and report them after attempting all transformations in the sequence.</p><p>The entry block of this operation has a single argument that maps to either
the operand if provided or the top-level container operation of the payload
IR, typically the root operation of the pass interpreting the transform
dialect. Operand omission is only allowed for sequences not contained in
another sequence.</p><p>The body of the sequence terminates with an implicit or explicit
<code>transform.yield</code> op. The operands of the terminator are returned as the
results of the sequence op.</p><p>Traits: AttrSizedOperandSegments, PossibleTopLevelTransformOpTrait, SingleBlockImplicitTerminator&lt;::mlir::transform::YieldOp></p><p>Interfaces: MemoryEffectOpInterface, OpAsmOpInterface, RegionBranchOpInterface, TransformOpInterface</p><h4 id=attributes-12>Attributes:&nbsp;<a class=headline-hash href=#attributes-12>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>failure_propagation_mode</code></td><td style=text-align:center>::mlir::transform::FailurePropagationModeAttr</td><td>Silenceable error propagation policy</td></tr></tbody></table><h4 id=operands-16>Operands:&nbsp;<a class=headline-hash href=#operands-16>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>root</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>extra_bindings</code></td><td>any transform handle or parameter</td></tr></tbody></table><h4 id=results-14>Results:&nbsp;<a class=headline-hash href=#results-14>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformsplit_handles-mlirtransformsplithandlesop><code>transform.split_handles</code> (::mlir::transform::SplitHandlesOp)&nbsp;<a class=headline-hash href=#transformsplit_handles-mlirtransformsplithandlesop>¶</a></h3><p>Splits handles from a union of payload ops to a list</p><p>Syntax:</p><pre><code>operation ::= `transform.split_handles` $handle `in` `[` $num_result_handles `]`
              attr-dict `:` functional-type(operands, results)
</code></pre><p>Creates <code>num_result_handles</code> transform IR handles extracted from the
<code>handle</code> operand. The resulting Payload IR operation handles are listed
in the same order as the operations appear in the source <code>handle</code>.
This is useful for ensuring a statically known number of operations are
tracked by the source <code>handle</code> and to extract them into individual handles
that can be further manipulated in isolation.</p><p>This operation succeeds and returns <code>num_result_handles</code> if the statically
specified <code>num_result_handles</code> corresponds to the dynamic number of
operations contained in the source <code>handle</code>. Otherwise it silently fails.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-13>Attributes:&nbsp;<a class=headline-hash href=#attributes-13>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>num_result_handles</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-17>Operands:&nbsp;<a class=headline-hash href=#operands-17>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-15>Results:&nbsp;<a class=headline-hash href=#results-15>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformwith_pdl_patterns-mlirtransformwithpdlpatternsop><code>transform.with_pdl_patterns</code> (::mlir::transform::WithPDLPatternsOp)&nbsp;<a class=headline-hash href=#transformwith_pdl_patterns-mlirtransformwithpdlpatternsop>¶</a></h3><p>Contains PDL patterns available for use in transforms</p><p>Syntax:</p><pre><code>operation ::= `transform.with_pdl_patterns` ($root^ `:` type($root))? attr-dict-with-keyword regions
</code></pre><p>This op contains a set of named PDL patterns that are available for the
Transform dialect operations to be used for pattern matching. For example,
PDLMatchOp can be used to produce a Transform IR value associated with all
Payload IR operations that match the pattern as follows:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>transform<span class=p>.</span>with_pdl_patterns <span class=p>{</span>
<span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation<span class=p>):</span>
  pdl<span class=p>.</span>pattern <span class=nf>@my_pattern</span> <span class=p>:</span> benefit<span class=p>(</span><span class=m>1</span><span class=p>)</span> <span class=p>{</span>
    <span class=nv>%0</span> <span class=p>=</span> pdl<span class=p>.</span>operation <span class=c>//...
</span><span class=c></span>    <span class=c>// Regular PDL goes here.
</span><span class=c></span>    pdl<span class=p>.</span>rewrite <span class=nv>%0</span> with <span class=s>&#34;transform.dialect&#34;</span>
  <span class=p>}</span>

  sequence <span class=nv>%arg0</span> failures<span class=p>(</span>propagate<span class=p>)</span> <span class=p>{</span>
  <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg1</span><span class=p>:</span> <span class=p>!</span>pdl<span class=p>.</span>operation<span class=p>):</span>
    <span class=nv>%1</span> <span class=p>=</span> pdl_match <span class=nf>@my_pattern</span> in <span class=nv>%arg1</span>
    <span class=c>// Use %1 as handle
</span><span class=c></span>  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>Note that the pattern is expected to finish with a <code>pdl.rewrite</code> terminator
that points to the custom rewriter named &ldquo;transform.dialect&rdquo;. The rewriter
actually does nothing, but the transform application will keep track of the
operations that matched the pattern.</p><p>This op is expected to contain <code>pdl.pattern</code> operations and exactly one
another Transform dialect operation that gets executed with all patterns
available. This op is a possible top-level Transform IR op, the argument of
its entry block corresponds to either the root op of the payload IR or the
ops associated with its operand when provided.</p><p>Traits: NoTerminator, PossibleTopLevelTransformOpTrait, SymbolTable</p><p>Interfaces: MemoryEffectOpInterface, OpAsmOpInterface, TransformOpInterface</p><h4 id=operands-18>Operands:&nbsp;<a class=headline-hash href=#operands-18>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>root</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformyield-mlirtransformyieldop><code>transform.yield</code> (::mlir::transform::YieldOp)&nbsp;<a class=headline-hash href=#transformyield-mlirtransformyieldop>¶</a></h3><p>Yields operation handles from a transform IR region</p><p>Syntax:</p><pre><code>operation ::= `transform.yield` operands attr-dict (`:` type($operands)^)?
</code></pre><p>This terminator operation yields operation handles from regions of the
transform IR ops back to the containing op. It is not itself associated with
any transformation on the payload IR and is used for flow purposes only.</p><p>Traits: Terminator</p><p>Interfaces: MemoryEffectOpInterface</p><h4 id=operands-19>Operands:&nbsp;<a class=headline-hash href=#operands-19>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operands</code></td><td>any transform handle or parameter</td></tr></tbody></table><h2 id=affine-transform-operations>Affine Transform Operations&nbsp;<a class=headline-hash href=#affine-transform-operations>¶</a></h2><h3 id=transformaffinesimplify_bounded_affine_ops-mlirtransformsimplifyboundedaffineopsop><code>transform.affine.simplify_bounded_affine_ops</code> (::mlir::transform::SimplifyBoundedAffineOpsOp)&nbsp;<a class=headline-hash href=#transformaffinesimplify_bounded_affine_ops-mlirtransformsimplifyboundedaffineopsop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.affine.simplify_bounded_affine_ops` $target `with` `[` $bounded_values `]`
              `within` $lower_bounds `and` $upper_bounds attr-dict
</code></pre><p>Simplify the targeted affine.min / affine.max ops given the supplied
lower and upper bounds for values that may be used as target op operands.</p><p>Example:</p><pre><code>%0 = transform.structured.match ops{[&quot;affine.min&quot;, &quot;affine.max&quot;]} in %arg1
%1 = transform.structured.match ops{[&quot;gpu.lane_id&quot;]} in %arg1
transform.affine.simplify_bounded_affine_ops %0 with [%1] within [0] and [32]

// Multiple bounds can be specified.
transform.affine.simplify_bounded_affine_ops %0 with [%1, %2] within [0, 5] and [32, 50]
</code></pre><p>Bounded op handles (<code>%1</code> and `%2) must be mapped to ops that have a single
result of index type. The sets of target ops and bounded ops must not
overlap.</p><h4 id=return-modes>Return modes&nbsp;<a class=headline-hash href=#return-modes>¶</a></h4><p>Target ops must be affine.min or affine.max ops. This transform consumes the
target handle and does not produce any handle. It reads the bounded op
handles.</p><p>TODO: Support affine.apply targets.
TODO: Allow mixed PDL_Operation/int64_t for lower_bounds and upper_bounds.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-14>Attributes:&nbsp;<a class=headline-hash href=#attributes-14>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lower_bounds</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>upper_bounds</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-20>Operands:&nbsp;<a class=headline-hash href=#operands-20>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>bounded_values</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h2 id=bufferization-transform-operations>Bufferization Transform Operations&nbsp;<a class=headline-hash href=#bufferization-transform-operations>¶</a></h2><h3 id=transformbufferizationeliminate_empty_tensors-mlirtransformeliminateemptytensorsop><code>transform.bufferization.eliminate_empty_tensors</code> (::mlir::transform::EliminateEmptyTensorsOp)&nbsp;<a class=headline-hash href=#transformbufferizationeliminate_empty_tensors-mlirtransformeliminateemptytensorsop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.bufferization.eliminate_empty_tensors` $target attr-dict
</code></pre><p>Try to eliminate all <code>tensor.empty</code> ops within the targeted op by replacing
them with a destination tensor.</p><p><code>tensor.empty</code> ops cannot be bufferizes. They can either be converted to
<code>bufferization.alloc_tensor</code> or replaced with another tensor (via this
transform). <code>tensor.empty</code> does not specify the contents of the returned
tensor so their results can be replaced with arbitrary tensor values as long
as the dimensions match.</p><p>This transform looks for <code>tensor.empty</code> ops where the SSA use-def chain of
the result ends in a supported &ldquo;anchor op&rdquo; (always following the aliasing
OpOperand/OpResult chain). Currently supported anchor ops are:</p><ul><li><code>tensor.insert_slice</code></li><li><code>bufferization.yield</code> (inside <code>bufferization.alloc_tensor</code>)</li></ul><p>Example:</p><pre><code>%0 = tensor.empty() : tensor&lt;5xf32&gt;
%1 = linalg.fill ... outs(%0)
%2 = tensor.insert_slice %1 into %t[1][5][1]
</code></pre><p>Is rewritten with:</p><pre><code>%0 = tensor.extract_slice %t[1][5][1]
%1 = linalg.fill ... outs(%0)
%2 = tensor.insert_slice %1 into %t[1][5][1]
</code></pre><p>The above example can bufferize without an allocation (in the absence of
other conflicts) because there is no longer a <code>tensor.empty</code> op.</p><p>See <code>-eliminate-empty-tensors</code> for more details.</p><h4 id=return-modes-1>Return modes&nbsp;<a class=headline-hash href=#return-modes-1>¶</a></h4><p>This transform reads the target handle and modifies the payload. It does
not produce any handle.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=operands-21>Operands:&nbsp;<a class=headline-hash href=#operands-21>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformbufferizationempty_tensor_to_alloc_tensor-mlirtransformemptytensortoalloctensorop><code>transform.bufferization.empty_tensor_to_alloc_tensor</code> (::mlir::transform::EmptyTensorToAllocTensorOp)&nbsp;<a class=headline-hash href=#transformbufferizationempty_tensor_to_alloc_tensor-mlirtransformemptytensortoalloctensorop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.bufferization.empty_tensor_to_alloc_tensor` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Replace a tensor.empty with a bufferization.tensor_alloc.</p><h4 id=return-modes-2>Return modes&nbsp;<a class=headline-hash href=#return-modes-2>¶</a></h4><p>This operation consumes the <code>target</code> handle and produces the <code>transformed</code>
handle. <code>target</code> is expected to be a <code>tensor.empty</code> operation. The transform
always succeeds.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-22>Operands:&nbsp;<a class=headline-hash href=#operands-22>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to tensor.empty operations</td></tr></tbody></table><h4 id=results-16>Results:&nbsp;<a class=headline-hash href=#results-16>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>Transform IR handle to bufferization.alloc_tensor operations</td></tr></tbody></table><h3 id=transformbufferizationone_shot_bufferize-mlirtransformoneshotbufferizeop><code>transform.bufferization.one_shot_bufferize</code> (::mlir::transform::OneShotBufferizeOp)&nbsp;<a class=headline-hash href=#transformbufferizationone_shot_bufferize-mlirtransformoneshotbufferizeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.bufferization.one_shot_bufferize` (`layout` `{` $function_boundary_type_conversion^ `}`)?
              $target attr-dict `:` functional-type($target, results)
</code></pre><p>Indicates that the given <code>target</code> op should be bufferized with One-Shot
Bufferize. The bufferization can be configured with various attributes that
corresponding to options in <code>BufferizationOptions</code> and the
<code>one-shot-bufferize</code> pass. More information can be found in the pass
documentation.</p><p>The targeted ops must be modules or functions. This is because there is
always a single, bufferized replacement op for such targets.</p><p>Note: Only ops that implement <code>BufferizableOpInterface</code> are bufferized. All
other ops are ignored if <code>allow_unknown_ops</code>. If <code>allow_unknown_ops</code> is
unset, this transform fails when an unknown/non-bufferizable op is found.
Many ops implement <code>BufferizableOpInterface</code> via an external model. These
external models must be registered when applying this transform op;
otherwise, said ops would be considered non-bufferizable.</p><h4 id=return-modes-3>Return modes&nbsp;<a class=headline-hash href=#return-modes-3>¶</a></h4><p>This operation consumes the <code>target</code> handle and produces the <code>transformed</code>
handle.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-15>Attributes:&nbsp;<a class=headline-hash href=#attributes-15>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>function_boundary_type_conversion</code></td><td style=text-align:center>::mlir::bufferization::LayoutMapOptionAttr</td><td>option for map layout</td></tr><tr><td style=text-align:center><code>allow_return_allocs</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>allow_unknown_ops</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>bufferize_function_boundaries</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>create_deallocs</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>test_analysis_only</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td style=text-align:center><code>print_conflicts</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-23>Operands:&nbsp;<a class=headline-hash href=#operands-23>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-17>Results:&nbsp;<a class=headline-hash href=#results-17>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h2 id=gpu-transform-operations>GPU Transform Operations&nbsp;<a class=headline-hash href=#gpu-transform-operations>¶</a></h2><h3 id=transformgpumap_forall_to_blocks-mlirtransformmapforalltoblocks><code>transform.gpu.map_forall_to_blocks</code> (::mlir::transform::MapForallToBlocks)&nbsp;<a class=headline-hash href=#transformgpumap_forall_to_blocks-mlirtransformmapforalltoblocks>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.gpu.map_forall_to_blocks` $target
              (`generate_gpu_launch` $generate_gpu_launch^)?
              (`grid_dims` `=` $grid_dims^)?
              attr-dict
</code></pre><p>Target the gpu_launch op and rewrite the top level <code>scf.forall</code>
to distributed gpu.block_id attribute. If <code>generate_gpu_launch</code> attribute
is set, then first generates <code>gpu_launch</code> and moves the top level
<code>scf.forall</code> inside.</p><p>The operation searches top level <code>scf.forall</code> ops under
<code>gpu_launch</code> and maps each such op to GPU blocks. Mapping is
one-to-one and the induction variables of <code>scf.forall</code> are
rewritten to gpu.block_id according to the <code>thread_dim_mapping</code> attribute.</p><p>Dynamic, <code>scf.forall</code> trip counts are currently not supported.
Dynamic block dim sizes are currently not supported.</p><p>Only <strong>bufferized</strong> scf.forall are currently supported.
Only scf.forall distributed to <strong>at most 3 dimensions</strong> are
currently supported.</p><p>The operation alters the block size of the given gpu_launch using the
grid_dims argument.</p><h4 id=return-modes-4>Return modes:&nbsp;<a class=headline-hash href=#return-modes-4>¶</a></h4><p>This operation ignores non-gpu_launch ops and drops them in the return.</p><p>If any scf.forall with tensors is found, the transform definitely
fails.</p><p>If all the scf.forall operations contained within the LaunchOp
referred to by the <code>target</code> PDLOperation lower to GPU properly, the
transform succeeds. Otherwise the transform definitely fails.</p><p>The returned handle points to the same LaunchOp operand, consuming it and
producing a new SSA value to satisfy chaining and linearity of the IR
properties.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-16>Attributes:&nbsp;<a class=headline-hash href=#attributes-16>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>grid_dims</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>generate_gpu_launch</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-24>Operands:&nbsp;<a class=headline-hash href=#operands-24>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-18>Results:&nbsp;<a class=headline-hash href=#results-18>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformgpumap_nested_forall_to_threads-mlirtransformmapnestedforalltothreads><code>transform.gpu.map_nested_forall_to_threads</code> (::mlir::transform::MapNestedForallToThreads)&nbsp;<a class=headline-hash href=#transformgpumap_nested_forall_to_threads-mlirtransformmapnestedforalltothreads>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.gpu.map_nested_forall_to_threads` $target
              `block_dims` `=` $block_dims
              (`warp_dims` `=` $warp_dims^)?
              (`sync_after_distribute` `=` $sync_after_distribute^)?
              attr-dict
</code></pre><p>Target the <code>gpu.launch op</code> and rewrite all <code>scf.forall</code> nested in it to
distributed <code>gpu.thread_id</code> attribute.</p><p>The operation searches for <code>scf.forall</code> ops nested under <code>target</code> and maps
each such op to GPU threads.</p><p><code>scf.forall</code> induction variables are rewritten to <code>gpu.thread_id</code> according
to the <code>mapping</code> attribute.</p><p>Different types of mappings attributes are supported:</p><ul><li>the block_dims is a list of integers that specifies the number of
threads in each dimension. This is a mandatory attribute that is used
to constrain the number of threads in each dimension. If an
<code>scf.forall</code> op is mapped to fewer threads, predication occurs.</li><li>the warp_dims is a list of integers that specifies the number of
warps in each dimension. This is an optional attribute that is used
to constrain the number of warps in each dimension. When present, this
attribute must be specified in a way that is compatible with the
block_dims attribute. If an <code>scf.forall</code> op is mapped to fewer warps,
predicaiton occurs.</li></ul><p>Dynamic <code>scf.forall</code> trip counts are currently not supported.
Dynamic block dim sizes are currently not supported.</p><p>Only <strong>bufferized</strong> <code>scf.forall</code> are currently supported.
Only <code>scf.forall</code> distributed to <strong>at most 3 dimensions</strong> are
currently supported.</p><p>The <code>sync_after_distribute</code>attribute controls whether a <code>gpu.barrier</code> is
inserted after each scf.forall op. At this time, this is an all or nothing
choice. This will need to be tightened in the future.</p><p>The operation alters the block size of the given gpu_launch using the
mandatory block_dims argument.</p><h4 id=return-modes-5>Return modes:&nbsp;<a class=headline-hash href=#return-modes-5>¶</a></h4><p>This operation ignores non-gpu_launch ops and drops them in the return.</p><p>If any scf.forall with tensors is found, the transform definitely
fails.</p><p>If all the scf.forall operations with gpu.thread mapping contained
within the LaunchOp referred to by the <code>target</code> PDLOperation lower to GPU
properly, the transform succeeds. Otherwise the transform definitely
fails.</p><p>scf.forall operations with mappings other than gpu.thread are
ignored.</p><p>The returned handle points to the same LaunchOp operand, consuming it and
producing a new SSA value to satisfy chaining and linearity of the IR
properties.</p><h4 id=example>Example:&nbsp;<a class=headline-hash href=#example>¶</a></h4><pre><code>gpu.launch blocks(%bx, %by, %bz) in (%x = %0, %y = %1, %z = %2)
           threads(%tx, %ty, %tz) in (%tx = %3, %ty = %4, %tz = %5) {
  scf.forall (%i, %j) in (7, 9) {
    ... // body 1
  } {mapping = [#gpu.thread&lt;x&gt;, #gpu.thread&lt;y&gt;, #gpu.thread&lt;z&gt;]}
  scf.forall (%i) in (12) {
    ... // body 2
  } {mapping = [#gpu.thread&lt;x&gt;]}
  gpu.terminator
}
</code></pre><p>is translated to:</p><pre><code>%bdimX = arith.constant 12 : index
%bdimY = arith.constant 9 : index
gpu.launch blocks(%bx, %by, %bz) in (%x = %0, %y = %1, %z = %2)
       threads(%tx, %ty, %tz) in (%tx = %bdimX, %ty = %bdimY, %tz = %5) {
  if (threadIdx.x &lt; 9 &amp;&amp; threadIdx.y &lt; 7) {
    ... // body 1
  }
  gpu.barrier
  if (threadIdx.y &lt; 1) {
    ... // body 2
  }
  gpu.barrier
  gpu.terminator
}
</code></pre><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-17>Attributes:&nbsp;<a class=headline-hash href=#attributes-17>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>block_dims</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>warp_dims</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>sync_after_distribute</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-25>Operands:&nbsp;<a class=headline-hash href=#operands-25>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-19>Results:&nbsp;<a class=headline-hash href=#results-19>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h2 id=loop-scf-transform-operations>Loop (SCF) Transform Operations&nbsp;<a class=headline-hash href=#loop-scf-transform-operations>¶</a></h2><h3 id=transformloopget_parent_for-mlirtransformgetparentforop><code>transform.loop.get_parent_for</code> (::mlir::transform::GetParentForOp)&nbsp;<a class=headline-hash href=#transformloopget_parent_for-mlirtransformgetparentforop>¶</a></h3><p>Gets a handle to the parent &lsquo;for&rsquo; loop of the given operation</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.get_parent_for` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Produces a handle to the n-th (default 1) parent <code>scf.for</code> or <code>affine.for</code>
(when the affine flag is true) loop for each Payload IR operation
associated with the operand. Fails if such a loop cannot be found. The list
of operations associated with the handle contains parent operations in the
same order as the list associated with the operand, except for operations
that are parents to more than one input which are only present once.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-18>Attributes:&nbsp;<a class=headline-hash href=#attributes-18>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>num_loops</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute whose value is positive</td></tr><tr><td style=text-align:center><code>affine</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-26>Operands:&nbsp;<a class=headline-hash href=#operands-26>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-20>Results:&nbsp;<a class=headline-hash href=#results-20>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>parent</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformloopcoalesce-mlirtransformloopcoalesceop><code>transform.loop.coalesce</code> (::mlir::transform::LoopCoalesceOp)&nbsp;<a class=headline-hash href=#transformloopcoalesce-mlirtransformloopcoalesceop>¶</a></h3><p>Coalesces the perfect loop nest enclosed by a given loop</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.coalesce` $target attr-dict `:` functional-type($target, $transformed)
</code></pre><p>Given a perfect loop nest identified by the outermost loop,
perform loop coalescing in a bottom-up one-by-one manner.</p><h4 id=return-modes-6>Return modes&nbsp;<a class=headline-hash href=#return-modes-6>¶</a></h4><p>The return handle points to the coalesced loop if coalescing happens, or
the given input loop if coalescing does not happen.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-27>Operands:&nbsp;<a class=headline-hash href=#operands-27>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-21>Results:&nbsp;<a class=headline-hash href=#results-21>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformloopoutline-mlirtransformloopoutlineop><code>transform.loop.outline</code> (::mlir::transform::LoopOutlineOp)&nbsp;<a class=headline-hash href=#transformloopoutline-mlirtransformloopoutlineop>¶</a></h3><p>Outlines a loop into a named function</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.outline` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Moves the loop into a separate function with the specified name and
replaces the loop in the Payload IR with a call to that function. Takes
care of forwarding values that are used in the loop as function arguments.
If the operand is associated with more than one loop, each loop will be
outlined into a separate function. The provided name is used as a <em>base</em>
for forming actual function names following SymbolTable auto-renaming
scheme to avoid duplicate symbols. Expects that all ops in the Payload IR
have a SymbolTable ancestor (typically true because of the top-level
module). Returns the handle to the list of outlined functions in the same
order as the operand handle.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-19>Attributes:&nbsp;<a class=headline-hash href=#attributes-19>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>func_name</code></td><td style=text-align:center>::mlir::StringAttr</td><td>string attribute</td></tr></tbody></table><h4 id=operands-28>Operands:&nbsp;<a class=headline-hash href=#operands-28>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-22>Results:&nbsp;<a class=headline-hash href=#results-22>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformlooppeel-mlirtransformlooppeelop><code>transform.loop.peel</code> (::mlir::transform::LoopPeelOp)&nbsp;<a class=headline-hash href=#transformlooppeel-mlirtransformlooppeelop>¶</a></h3><p>Peels the last iteration of the loop</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.peel` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Updates the given loop so that its step evenly divides its range and puts
the remaining iteration into a separate loop or a conditional.</p><p>In the absence of sufficient static information, this op may peel a loop,
even if the step always divides the range evenly at runtime.</p><h4 id=return-modes-7>Return modes&nbsp;<a class=headline-hash href=#return-modes-7>¶</a></h4><p>This operation ignores non-scf::ForOp ops and drops them in the return.</p><p>This operation always succeeds and returns the scf::ForOp with the
postcondition: &ldquo;the loop trip count is divisible by the step&rdquo;.
This operation may return the same unmodified loop handle when peeling did
not modify the IR (i.e. the loop trip count was already divisible).</p><p>Note that even though the Payload IR modification may be performed
in-place, this operation consumes the operand handle and produces a new
one.</p><p>TODO: Return both the peeled loop and the remainder loop.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-20>Attributes:&nbsp;<a class=headline-hash href=#attributes-20>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>fail_if_already_divisible</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-29>Operands:&nbsp;<a class=headline-hash href=#operands-29>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to scf.for operations</td></tr></tbody></table><h4 id=results-23>Results:&nbsp;<a class=headline-hash href=#results-23>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformlooppipeline-mlirtransformlooppipelineop><code>transform.loop.pipeline</code> (::mlir::transform::LoopPipelineOp)&nbsp;<a class=headline-hash href=#transformlooppipeline-mlirtransformlooppipelineop>¶</a></h3><p>Applies software pipelining to the loop</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.pipeline` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Transforms the given loops one by one to achieve software pipelining for
each of them. That is, performs some amount of reads from memory before the
loop rather than inside the loop, the same amount of writes into memory
after the loop, and updates each iteration to read the data for a following
iteration rather than the current one.</p><p>The amount is specified by the attributes.</p><p>The values read and about to be stored are transferred as loop iteration
arguments. Currently supports memref and vector transfer operations as
memory reads/writes.</p><h4 id=return-modes-8>Return modes&nbsp;<a class=headline-hash href=#return-modes-8>¶</a></h4><p>This operation ignores non-scf::For ops and drops them in the return.
If all the operations referred to by the <code>target</code> PDLOperation pipeline
properly, the transform succeeds. Otherwise the transform silently fails.
The return handle points to only the subset of successfully produced
pipelined loops, which can be empty.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-21>Attributes:&nbsp;<a class=headline-hash href=#attributes-21>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>iteration_interval</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>read_latency</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-30>Operands:&nbsp;<a class=headline-hash href=#operands-30>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to scf.for operations</td></tr></tbody></table><h4 id=results-24>Results:&nbsp;<a class=headline-hash href=#results-24>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformloopunroll-mlirtransformloopunrollop><code>transform.loop.unroll</code> (::mlir::transform::LoopUnrollOp)&nbsp;<a class=headline-hash href=#transformloopunroll-mlirtransformloopunrollop>¶</a></h3><p>Unrolls the given loop with the given unroll factor</p><p>Syntax:</p><pre><code>operation ::= `transform.loop.unroll` $target attr-dict `:` type($target)
</code></pre><p>Unrolls each loop associated with the given handle to have up to the given
number of loop body copies per iteration. If the unroll factor is larger
than the loop trip count, the latter is used as the unroll factor instead.</p><h4 id=return-modes-9>Return modes&nbsp;<a class=headline-hash href=#return-modes-9>¶</a></h4><p>This operation ignores non-scf::For, non-affine::For ops and drops them in
the return. If all the operations referred to by the <code>target</code> PDLOperation
unroll properly, the transform succeeds. Otherwise the transform silently
fails.</p><p>Does not return handles as the operation may result in the loop being
removed after a full unrolling.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-22>Attributes:&nbsp;<a class=headline-hash href=#attributes-22>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>factor</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute whose value is positive</td></tr></tbody></table><h4 id=operands-31>Operands:&nbsp;<a class=headline-hash href=#operands-31>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformscftake_assumed_branch-mlirtransformtakeassumedbranchop><code>transform.scf.take_assumed_branch</code> (::mlir::transform::TakeAssumedBranchOp)&nbsp;<a class=headline-hash href=#transformscftake_assumed_branch-mlirtransformtakeassumedbranchop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.scf.take_assumed_branch` $target
              (`take_else_branch` $take_else_branch^)?
              attr-dict
              `:` functional-type(operands, results)
</code></pre><p>Given an scf.if conditional, inject user-defined information that it is
always safe to execute only the if or else branch.</p><p>This is achieved by just replacing the scf.if by the content of one of its
branches.</p><p>This is particularly useful for user-controlled rewriting of conditionals
that exist solely to guard against out-of-bounds behavior.</p><p>At the moment, no assume or assert operation is emitted as it is not always
desirable. In the future, this may be controlled by a dedicated attribute.</p><h4 id=return-modes-10>Return modes&nbsp;<a class=headline-hash href=#return-modes-10>¶</a></h4><p>The transform only consumes its operand and does not produce any result.
The transform definitely fails if <code>take_else_branch</code> is specified and the
<code>else</code> region is empty.</p><p>Traits: TransformEachOpTrait</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-23>Attributes:&nbsp;<a class=headline-hash href=#attributes-23>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>take_else_branch</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-32>Operands:&nbsp;<a class=headline-hash href=#operands-32>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h2 id=memref-transform-operations>MemRef Transform Operations&nbsp;<a class=headline-hash href=#memref-transform-operations>¶</a></h2><h3 id=transformmemrefextract_address_computations-mlirtransformmemrefextractaddresscomputationsop><code>transform.memref.extract_address_computations</code> (::mlir::transform::MemRefExtractAddressComputationsOp)&nbsp;<a class=headline-hash href=#transformmemrefextract_address_computations-mlirtransformmemrefextractaddresscomputationsop>¶</a></h3><p>Extract address computations from memory accesses</p><p>Syntax:</p><pre><code>operation ::= `transform.memref.extract_address_computations` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Transformation that extracts address computations from instructions
with memory accesses such that these memory accesses use only a base
pointer.</p><p>For instance,</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>memref</span><span class=p>.</span>load <span class=nv>%base</span><span class=p>[</span><span class=nv>%off0</span><span class=p>,</span> <span class=p>...]</span>
</code></pre></div><p>Will be rewritten in:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%new_base</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>subview <span class=nv>%base</span><span class=p>[</span><span class=nv>%off0</span><span class=p>,...][</span><span class=m>1</span><span class=p>,...][</span><span class=m>1</span><span class=p>,...]</span>
<span class=kt>memref</span><span class=p>.</span>load <span class=nv>%new_base</span><span class=p>[</span><span class=nv>%c0</span><span class=p>,...]</span>
</code></pre></div><p>Note: The current implementation requires that the input operation
is &ldquo;isolated from above&rdquo;.</p><h4 id=return-modes-11>Return modes&nbsp;<a class=headline-hash href=#return-modes-11>¶</a></h4><p>This operation produces <code>definiteFailure</code> if the extraction fails for any
reason.
The operation always returns the handle to the target op that is expected
to be isolated from above.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-33>Operands:&nbsp;<a class=headline-hash href=#operands-33>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-25>Results:&nbsp;<a class=headline-hash href=#results-25>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformmemrefmake_loop_independent-mlirtransformmemrefmakeloopindependentop><code>transform.memref.make_loop_independent</code> (::mlir::transform::MemRefMakeLoopIndependentOp)&nbsp;<a class=headline-hash href=#transformmemrefmake_loop_independent-mlirtransformmemrefmakeloopindependentop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.memref.make_loop_independent` $target attr-dict
</code></pre><p>Rewrite the targeted ops such that their index-typed operands no longer
depend on any loop induction variable of the <code>num_loop</code> enclosing <code>scf.for</code>
loops. I.e., compute an upper bound that is independent of any such loop IV
for every tensor dimension. The transformed op could then be hoisted from
the <code>num_loop</code> enclosing loops. To preserve the original semantics, place a
<code>memref.subview</code> inside the loop.</p><p>Currently supported operations are:</p><ul><li>memref.alloca: Replaced with a new memref.alloca with upper bound sizes,
followed by a memref.subview.</li></ul><h4 id=return-modes-12>Return modes&nbsp;<a class=headline-hash href=#return-modes-12>¶</a></h4><p>This operation fails if at least one induction variable could not be
eliminated. In case the targeted op is already independent of induction
variables, this transform succeeds and returns the unmodified target op.</p><p>Otherwise, the returned handle points to a subset of the produced ops:</p><ul><li>memref.alloca: The returned handle points to the memref.subview op.</li></ul><p>This transform op consumes the target handle and produces a result handle.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-24>Attributes:&nbsp;<a class=headline-hash href=#attributes-24>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>num_loops</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-34>Operands:&nbsp;<a class=headline-hash href=#operands-34>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-26>Results:&nbsp;<a class=headline-hash href=#results-26>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformmemrefmultibuffer-mlirtransformmemrefmultibufferop><code>transform.memref.multibuffer</code> (::mlir::transform::MemRefMultiBufferOp)&nbsp;<a class=headline-hash href=#transformmemrefmultibuffer-mlirtransformmemrefmultibufferop>¶</a></h3><p>Multibuffers an allocation</p><p>Syntax:</p><pre><code>operation ::= `transform.memref.multibuffer` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Transformation to do multi-buffering/array expansion to remove
dependencies on the temporary allocation between consecutive loop
iterations. This transform expands the size of an allocation by
a given multiplicative factor and fixes up any users of the
multibuffered allocation.
If skip analysis is not set the transformation will only apply
if it can prove that there is no data being carried across loop
iterations.</p><h4 id=return-modes-13>Return modes&nbsp;<a class=headline-hash href=#return-modes-13>¶</a></h4><p>This operation returns the new allocation if multi-buffering
succeeds, and failure otherwise.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-25>Attributes:&nbsp;<a class=headline-hash href=#attributes-25>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>factor</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute whose value is positive</td></tr><tr><td style=text-align:center><code>skip_analysis</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-35>Operands:&nbsp;<a class=headline-hash href=#operands-35>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to memref.alloc operations</td></tr></tbody></table><h4 id=results-27>Results:&nbsp;<a class=headline-hash href=#results-27>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h2 id=structured-linalg-match-operations>Structured (Linalg) Match Operations&nbsp;<a class=headline-hash href=#structured-linalg-match-operations>¶</a></h2><h3 id=transformmatchstructuredbody-mlirtransformmatchstructuredbodyop><code>transform.match.structured.body</code> (::mlir::transform::MatchStructuredBodyOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredbody-mlirtransformmatchstructuredbodyop>¶</a></h3><p>Checks if the body of the structured op satisfies some criteria</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.body` $operand_handle attr-dict `:` type($operand_handle)
</code></pre><p>Checks if the body of the structured payload op satisfies one of the
following mutually exclusive criteria specified by attributes:</p><ul><li><p><code>reduction_position</code>: the body of the structured payload op implements
a reduction of the <code>n</code>-th operand (<code>n</code> is the value of the attribute)
using a single combiner operation;</p></li><li><p><code>passthrough</code>: the body of the structured payload op only forwards
inputs to the outputs (copy or broadcast).</p></li></ul><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-14>Return modes&nbsp;<a class=headline-hash href=#return-modes-14>¶</a></h4><p>Succeeds if the operation body satisfies the specified criteria, produces a
silenceable failure otherwise. Produces a definite failure if the operand is
not associated with a single payload op.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-26>Attributes:&nbsp;<a class=headline-hash href=#attributes-26>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>reduction_position</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>passthrough</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-36>Operands:&nbsp;<a class=headline-hash href=#operands-36>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructureddim-mlirtransformmatchstructureddimop><code>transform.match.structured.dim</code> (::mlir::transform::MatchStructuredDimOp)&nbsp;<a class=headline-hash href=#transformmatchstructureddim-mlirtransformmatchstructureddimop>¶</a></h3><p>Checks if the dimensions of the structured op satisfy some criteria</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.dim` $operand_handle `[`custom&lt;StructuredTransformDims&gt;($raw_dim_list, $is_inverted, $is_all)`]` attr-dict `:` custom&lt;SemiFunctionType&gt;(type($operand_handle), type($result))
</code></pre><p>Checks if the dimensions (loop ranges) of the structured payload op satisfy
the criteria specified as attributes. May capture the numeric value of the
dimension into a parameter that it returns.</p><p>The following dimension specifications are supported:</p><ul><li><code>all</code>: all dimensions are checked and captured;</li><li>list of integers: the listed dimensions are checked and captured;</li><li><code>except(</code> list of integers <code>)</code>: all dimensions except the
specified ones are checked and captured.</li></ul><p>Negative indexes are interpreted by counting values from the last one
(similarly to Python). For example, <code>-1</code> means the last dimension and
<code>except(-1)</code> means all dimensions but the last. Indexes must be unique,
including after interpretation of negative ones.</p><p>Produces a silenceable failure in case of index overflow, including backward
counting.</p><p>The following mutually exclusive conditions are available as unit
attributes:</p><ul><li><code>parallel</code>: the dimension corresponds to a parallel loop;</li><li><code>reduction</code>: the dimension corresponds to a reduction loop.</li></ul><p>If the result type is specified, associates the parameter with the (static)
values of dimensions in the same order as listed and preserving the natural
order for <code>all</code> and <code>except</code>. Specifically, if <code>-1, -2</code> are specified, the
parameter will be associated with the value of the second-to-last dimension
followed by the last dimension. If the dimension is dynamic, the parameter
will contain a negative value corresponding to kDynamic in C++.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-15>Return modes&nbsp;<a class=headline-hash href=#return-modes-15>¶</a></h4><p>Succeeds if the specified dimensions satisfy the specified criteria,
produces a silenceable failure otherwise. Produces a definite failure if
the operand is not associated with a single payload op.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-27>Attributes:&nbsp;<a class=headline-hash href=#attributes-27>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>raw_dim_list</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>is_inverted</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>is_all</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>parallel</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>reduction</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-37>Operands:&nbsp;<a class=headline-hash href=#operands-37>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-28>Results:&nbsp;<a class=headline-hash href=#results-28>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructuredelemental_bitwidth-mlirtransformmatchstructuredelementalbitwidthop><code>transform.match.structured.elemental_bitwidth</code> (::mlir::transform::MatchStructuredElementalBitwidthOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredelemental_bitwidth-mlirtransformmatchstructuredelementalbitwidthop>¶</a></h3><p>Captures the bitwidth of the value&rsquo;s elemental type as a parameter</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.elemental_bitwidth` $operand_handle attr-dict `:` functional-type(operands, results)
</code></pre><p>Produces a transform dialect parameter associated with the bitwidth of the
elemental type of the payload value passed as the operand.
This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-16>Return modes&nbsp;<a class=headline-hash href=#return-modes-16>¶</a></h4><p>Succeeds if the operand is associated with exactly one payload value of
<code>ShapedType</code>. Produces a silenceable failure otherwise.</p><p>Traits: SingleValueMatcher</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-38>Operands:&nbsp;<a class=headline-hash href=#operands-38>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformValueHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-29>Results:&nbsp;<a class=headline-hash href=#results-29>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructuredinit-mlirtransformmatchstructuredinitop><code>transform.match.structured.init</code> (::mlir::transform::MatchStructuredInitOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredinit-mlirtransformmatchstructuredinitop>¶</a></h3><p>Captures init operand(s) of a structured operation in an op or value handle</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.init` $operand_handle `[`custom&lt;StructuredTransformDims&gt;($raw_position_list, $is_inverted, $is_all)`]` attr-dict `:` custom&lt;SemiFunctionType&gt;(type($operand_handle), type($result))
</code></pre><p>Produces a transform dialect value handle associated with the payload value
supplied as init(outs) operand to the given structured payload operation,
or an operation handle to the structured payload operation producing said
payload value depending on the result type.</p><p>The following init specifications are supported:</p><ul><li><code>all</code>: all inits are checked and captured;</li><li>list of integers: the listed inits are checked and captured;</li><li><code>except(</code> list of integers <code>)</code>: all inits except the
specified ones are checked and captured.</li></ul><p>Negative indexes are interpreted by counting values from the last one
(similarly to Python). For example, <code>-1</code> means the last init and
<code>except(-1)</code> means all inits but the last. Indexes must be unique,
including after interpretation of negative ones.</p><p>Produces a silenceable failure in case of index overflow, including backward
counting.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-17>Return modes&nbsp;<a class=headline-hash href=#return-modes-17>¶</a></h4><p>Succeeds if all init(outs) indexes are in bounds, produces a silenceable
failure otherwise. Additionally, when the result is an operation handle,
produces a silenceable failure if the init(outs) specification defines
more than one init(outs) or if the operand is not an operation result.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-28>Attributes:&nbsp;<a class=headline-hash href=#attributes-28>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>raw_position_list</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>is_inverted</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>is_all</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>permutation</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>projected_permutation</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-39>Operands:&nbsp;<a class=headline-hash href=#operands-39>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-30>Results:&nbsp;<a class=headline-hash href=#results-30>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>transform operation or value handle</td></tr></tbody></table><h3 id=transformmatchstructuredinput-mlirtransformmatchstructuredinputop><code>transform.match.structured.input</code> (::mlir::transform::MatchStructuredInputOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredinput-mlirtransformmatchstructuredinputop>¶</a></h3><p>Captures input operand(s) of a structured operation in an op or value handle</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.input` $operand_handle `[`custom&lt;StructuredTransformDims&gt;($raw_position_list, $is_inverted, $is_all)`]` attr-dict `:` custom&lt;SemiFunctionType&gt;(type($operand_handle), type($result))
</code></pre><p>Produces a transform dialect value handle associated with the payload value
supplied as input operand to the given structured payload operation, or an
operation handle to the structured payload operation producing said payload
value depending on the result type.</p><p>The following input specifications are supported:</p><ul><li><code>all</code>: all inputs are checked and captured;</li><li>list of integers: the listed inputs are checked and captured;</li><li><code>except(</code> list of integers <code>)</code>: all inputs except the
specified ones are checked and captured.</li></ul><p>Negative indexes are interpreted by counting values from the last one
(similarly to Python). For example, <code>-1</code> means the last input and
<code>except(-1)</code> means all inputs but the last. Indexes must be unique,
including after interpretation of negative ones.</p><p>Produces a silenceable failure in case of index overflow, including backward
counting.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-18>Return modes&nbsp;<a class=headline-hash href=#return-modes-18>¶</a></h4><p>Succeeds if all input indexes are in bounds, produces a silenceable failure
otherwise. Additionally, when the result is an operation handle, produces a
silenceable failure if the input specification defines more than one input
or if the operand is not an operation result.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-29>Attributes:&nbsp;<a class=headline-hash href=#attributes-29>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>raw_position_list</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>is_inverted</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>is_all</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>permutation</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>projected_permutation</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-40>Operands:&nbsp;<a class=headline-hash href=#operands-40>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-31>Results:&nbsp;<a class=headline-hash href=#results-31>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>transform operation or value handle</td></tr></tbody></table><h3 id=transformmatchstructurednum_inits-mlirtransformmatchstructurednuminitsop><code>transform.match.structured.num_inits</code> (::mlir::transform::MatchStructuredNumInitsOp)&nbsp;<a class=headline-hash href=#transformmatchstructurednum_inits-mlirtransformmatchstructurednuminitsop>¶</a></h3><p>Captures the number of init(outs) operands of a structuredoperation as parameter</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.num_inits` $operand_handle attr-dict `:` functional-type(operands, results)
</code></pre><p>Produces a transform dialect parameter value associated with an integer
attribute containing the number of init(outs) operands of the payload
operation associated with the operand handle.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-19>Return modes&nbsp;<a class=headline-hash href=#return-modes-19>¶</a></h4><p>Succeeds if the operand is associated with exactly one structured payload
operation. Produces a silenceable failure otherwise.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-41>Operands:&nbsp;<a class=headline-hash href=#operands-41>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-32>Results:&nbsp;<a class=headline-hash href=#results-32>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructurednum_inputs-mlirtransformmatchstructurednuminputsop><code>transform.match.structured.num_inputs</code> (::mlir::transform::MatchStructuredNumInputsOp)&nbsp;<a class=headline-hash href=#transformmatchstructurednum_inputs-mlirtransformmatchstructurednuminputsop>¶</a></h3><p>Captures the number of input operands of a structured operation as parameter</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.num_inputs` $operand_handle attr-dict `:` functional-type(operands, results)
</code></pre><p>Produces a transform dialect parameter value associated with an integer
attribute containing the number of input operands of the payload operation
associated with the operand handle.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-20>Return modes&nbsp;<a class=headline-hash href=#return-modes-20>¶</a></h4><p>Succeeds if the operand is associated with exactly one structured payload
operation. Produces a silenceable failure otherwise.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-42>Operands:&nbsp;<a class=headline-hash href=#operands-42>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-33>Results:&nbsp;<a class=headline-hash href=#results-33>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructured-mlirtransformmatchstructuredop><code>transform.match.structured</code> (::mlir::transform::MatchStructuredOp)&nbsp;<a class=headline-hash href=#transformmatchstructured-mlirtransformmatchstructuredop>¶</a></h3><p>Matches a structured (linalg) operation with additional conditions</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured` (`failures` `(` $failure_propagation_mode^ `)`)?$current `:` custom&lt;SemiFunctionType&gt;(type($current), type($outputs))attr-dict-with-keyword regions
</code></pre><p>Checks if the payload operation associated with the operand handle is a
structured operation, that is, an operation that implements
<code>LinalgOpInterface</code>, and that all conditions listed in the body of this
operation are satisfied. Produces a silenceable failure if the payload
operation is not structured.</p><p>The transform operations nested in the body region are applied one by one.
If any of them produces a failure, silenceable or definite, the following
operations are not applied. If the failure propagation mode is &ldquo;propagate&rdquo;,
silenceable failures are forwarded as the result of this operation. If it is
&ldquo;suppress&rdquo;, they are ignored and this operation immediately succeeds.
Definite failures are always propagated immediately.</p><p>In case of success, the transform values produced by this operation are
associated with the same payload as the operands of the block terminator. If
any of the nested operations produced a silenceable failure, regardless of
the failure propagation mode, the transform values produced by this
operation that correspond to the already defined terminator operands are
associated with the same payload as the already defined terminator operands.
Other values produced by this operation are associated with empty payloads.</p><p>If the failure propagation mode is not specified, it is considered
&ldquo;propagate&rdquo; by default. The &ldquo;suppress&rdquo; mode can be used to specify optional
matches.</p><h4 id=return-modes-21>Return modes&nbsp;<a class=headline-hash href=#return-modes-21>¶</a></h4><p>This operation only reads all operand handles and produces all resulting
handles. It succeeds in &ldquo;propagate&rdquo; mode if the payload operation is a
structured operation and if all the nested operations succeed. It succeeds
in &ldquo;suppress&rdquo; mode as long as the operand handle is associated with exactly
one payload operation. It produces a definite failure when the handle is
not associated with exactly one payload operation.</p><p>Traits: SingleBlockImplicitTerminator&lt;::mlir::transform::MatchStructuredYieldOp>, SingleOpMatcher</p><p>Interfaces: MatchOpInterface, MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-30>Attributes:&nbsp;<a class=headline-hash href=#attributes-30>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>failure_propagation_mode</code></td><td style=text-align:center>::mlir::transform::FailurePropagationModeAttr</td><td>Silenceable error propagation policy</td></tr></tbody></table><h4 id=operands-43>Operands:&nbsp;<a class=headline-hash href=#operands-43>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>current</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-34>Results:&nbsp;<a class=headline-hash href=#results-34>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>outputs</code></td><td>any transform handle or parameter</td></tr></tbody></table><h3 id=transformmatchstructuredrank-mlirtransformmatchstructuredrankop><code>transform.match.structured.rank</code> (::mlir::transform::MatchStructuredRankOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredrank-mlirtransformmatchstructuredrankop>¶</a></h3><p>Captures the rank of a structured operation as parameter</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.rank` $operand_handle attr-dict `:`custom&lt;SemiFunctionType&gt;(type($operand_handle), type($rank))
</code></pre><p>Produces a transform dialect parameter value associated with an integer
attribute containing the rank of the structured payload operation associated
with the operand handle.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-22>Return modes&nbsp;<a class=headline-hash href=#return-modes-22>¶</a></h4><p>Succeeds if the operand is associated with exactly one structured payload
operation. Produces a silenceable failure otherwise.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-44>Operands:&nbsp;<a class=headline-hash href=#operands-44>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-35>Results:&nbsp;<a class=headline-hash href=#results-35>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>rank</code></td><td>TransformParamTypeInterface instance</td></tr></tbody></table><h3 id=transformmatchstructuredresult-mlirtransformmatchstructuredresultop><code>transform.match.structured.result</code> (::mlir::transform::MatchStructuredResultOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredresult-mlirtransformmatchstructuredresultop>¶</a></h3><p>Captures the result of a structured payload operation in an op or value handle</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.result` $operand_handle `[` $position `]` (`any` $any^)? (`single` $single^)?attr-dict `:` functional-type(operands, results)
</code></pre><p>Produces a transform dialect value handle associated with the payload value
defined as a result of the payload operation associated with the operand
handle, or an operation handle to an operation using the produced result
with additional constraints specified by the attributes as follows.</p><ul><li>If <code>any</code> is specified, binds the resulting handle to any operation using
the result and succeeds.</li><li>If <code>single</code> is specified, binds the resulting handle to the only
operation using the result or fails if there is more than one (or no)
such operation.</li></ul><p>The number of the result is specified as <code>position</code> attribute. It may take
positive and negative values. Negative values are interpreted as counting
results from backwards, e.g., <code>-1</code> means the last result and <code>-2</code> means the
second-to-last result. In any case, the position must be in bounds for the
given payload operation. A silenceable failure is produced for out-of-bounds
positions.</p><p>This op can only appear immediately inside a <code>transform.match.structured</code>
op and apply to its first block argument because it assumes the payload
to have been already checked for being a single structured op.</p><h4 id=return-modes-23>Return modes&nbsp;<a class=headline-hash href=#return-modes-23>¶</a></h4><p>Succeeds if the position is in bounds and if the user operation could be
found when requested. Produces a silenceable failure otherwise.</p><p>Traits: SingleOpMatcher, StructuredPredicate</p><p>Interfaces: MatchOpInterface, MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-31>Attributes:&nbsp;<a class=headline-hash href=#attributes-31>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>position</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>any</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>single</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-45>Operands:&nbsp;<a class=headline-hash href=#operands-45>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operand_handle</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-36>Results:&nbsp;<a class=headline-hash href=#results-36>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>transform operation or value handle</td></tr></tbody></table><h3 id=transformmatchstructuredyield-mlirtransformmatchstructuredyieldop><code>transform.match.structured.yield</code> (::mlir::transform::MatchStructuredYieldOp)&nbsp;<a class=headline-hash href=#transformmatchstructuredyield-mlirtransformmatchstructuredyieldop>¶</a></h3><p>Terminator for transform.match.structured blocks</p><p>Syntax:</p><pre><code>operation ::= `transform.match.structured.yield` $handles attr-dict (`:` type($handles)^)?
</code></pre><p>Forwards the payload association from the operands to the results of the
parent op. Always succeeds.</p><p>Traits: Terminator</p><p>Interfaces: MemoryEffectOpInterface</p><h4 id=operands-46>Operands:&nbsp;<a class=headline-hash href=#operands-46>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>handles</code></td><td>any transform handle or parameter</td></tr></tbody></table><h2 id=structured-linalg-transform-operations>Structured (Linalg) Transform Operations&nbsp;<a class=headline-hash href=#structured-linalg-transform-operations>¶</a></h2><h3 id=transformstructuredbufferize_to_allocation-mlirtransformbufferizetoallocationop><code>transform.structured.bufferize_to_allocation</code> (::mlir::transform::BufferizeToAllocationOp)&nbsp;<a class=headline-hash href=#transformstructuredbufferize_to_allocation-mlirtransformbufferizetoallocationop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.bufferize_to_allocation` $target attr-dict
</code></pre><p>This transform materializes an allocation for the targeted tensor value. It
replaces all original uses of the target with the newly allocated buffer,
wrapped in a <code>bufferization.to_tensor</code> op. It returns a handle to the result
of the <code>to_tensor</code> op.</p><p>Example:</p><pre><code>%0 = &quot;some_op&quot;() : () -&gt; (tensor&lt;10xf32&gt;)
&quot;some_use&quot;(%0) : (tensor&lt;10xf32&gt;) -&gt; ()
</code></pre><p>Is rewritten to:</p><pre><code>%0 = &quot;some_op&quot;() : () -&gt; (tensor&lt;10xf32&gt;)
%1 = memref.alloc() : memref&lt;10xf32&gt;
memref.tensor_store %0, %1 : memref&lt;10xf32&gt;
%2 = bufferization.to_tensor %1 restrict writable : memref&lt;10xf32&gt;
&quot;some_use&quot;(%2) : (tensor&lt;10xf32&gt;) -&gt; ()
</code></pre><p>This transform has optimized lowerings for certain targets that are results
of non-DPS ops. For such targets, not only a buffer allocation is emitted
but also the defining op is bufferized. This is to avoid a second
allocation for the missing destination of the non-DPS op (when subsequently
running a bufferization pass/transform). Currently supported ops with
optimized lowerings:</p><ul><li>tensor.pad</li></ul><p>An optional memory space attribute can be specified for the materialized
buffer allocation.</p><h4 id=return-modes-24>Return modes&nbsp;<a class=headline-hash href=#return-modes-24>¶</a></h4><p>This operation consumes the <code>target</code> handle and produces the <code>transformed</code>
handle. It always succeeds.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-32>Attributes:&nbsp;<a class=headline-hash href=#attributes-32>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>memory_space</code></td><td style=text-align:center>::mlir::Attribute</td><td>any attribute</td></tr></tbody></table><h4 id=operands-47>Operands:&nbsp;<a class=headline-hash href=#operands-47>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td></td></tr></tbody></table><h4 id=results-37>Results:&nbsp;<a class=headline-hash href=#results-37>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td></td></tr></tbody></table><h3 id=transformstructuredconvert_conv2d_to_img2col-mlirtransformconvertconv2dtoimg2colop><code>transform.structured.convert_conv2d_to_img2col</code> (::mlir::transform::ConvertConv2DToImg2ColOp)&nbsp;<a class=headline-hash href=#transformstructuredconvert_conv2d_to_img2col-mlirtransformconvertconv2dtoimg2colop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.convert_conv2d_to_img2col` $target attr-dict `:` functional-type($target, results)
</code></pre><p>Convert linalg.conv_2d_xxx into linalg.generic (for img2col packing)
and linalg.matmul.</p><p>A convolution operation can be written as a matrix-matrix multiplication by
unfolding the cross-correlation between input and filter and explicitly copy
overlapped sliding window inputs.</p><p>Consider 2D input X with single channel input and output and 2x2 filter W:</p><pre><code>[x(0, 0)  , x(0, 1)  , ...,   x(0, n)  ]
[x(1, 0)  , x(1, 1)  , ...,   x(1, n)  ]
[.        ,  .       ,.   ,      .     ]            [w(0, 0), w(0, 1)]
[.        ,  .       , .  ,      .     ]    (conv)  [w(1, 0), w(1, 1)]
[.        ,  .       ,   .,      .     ]
[x(n-1, 0), x(n-1, 1), ..., x(n-1, n-1)]
</code></pre><p>The packed input data (img2col) is a matrix with |rows| = output spatial
size, |columns| = filter spatial size. To compute the output Y(i, j) we need
to calculate the dot product between filter window at input X(x, y)) and the
filter which will look like the following where r.h.s is the img2col matrix
and l.h.s is the flattned filter:</p><pre><code>[x(0,0), x(0,1), x(1,0), x(1,1)]
[x(0,1), x(1,1), x(0,2), x(1,2)] (matmul) [w(0,0), w(0,1), w(1,0), w(1,1)]
[x(0,1), x(1,1), x(0,2), x(1,2)]
[   .  ,    .  ,    .  ,    .  ]
</code></pre><p>In general for 2D case with (N, H, W, C) input and (Kh, Kw, C, D) filter
and output (N, Ho, Wo, D) the convolution is the following matrix-matrix
multiplication (Ho x Wo, Kh x Kw x C) * (Kh x Kw x C, D) for each input in
the N input. For the case where N > 1 its a batched matrxi-matrix
multplication.</p><p>Returns two handles:</p><ul><li>One on the operation that produces the img2col tensor.</li><li>One on the final operation of the sequence that replaces the original
convolution.</li></ul><h4 id=return-modes-25>Return modes:&nbsp;<a class=headline-hash href=#return-modes-25>¶</a></h4><p>Returns a definite failure if target is not isolated from above.
Returns a silenceable failure if the pattern application failed.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-48>Operands:&nbsp;<a class=headline-hash href=#operands-48>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-38>Results:&nbsp;<a class=headline-hash href=#results-38>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>img2col_tensor</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructureddecompose-mlirtransformdecomposeop><code>transform.structured.decompose</code> (::mlir::transform::DecomposeOp)&nbsp;<a class=headline-hash href=#transformstructureddecompose-mlirtransformdecomposeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.decompose` $target attr-dict
</code></pre><p>Decomposes named complex operations, such as higher-dimensional
(depthwise) convolutions, into combinations of lower-dimensional equivalents
when possible.</p><h4 id=return-modes-26>Return modes&nbsp;<a class=headline-hash href=#return-modes-26>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
If all the operations referred to by the <code>target</code> PDLOperation decompose
properly, the transform succeeds. Otherwise the transform silently fails.
The return handle points to only the subset of successfully produced
computational operations, which can be empty.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-49>Operands:&nbsp;<a class=headline-hash href=#operands-49>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-39>Results:&nbsp;<a class=headline-hash href=#results-39>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredfuse_into_containing_op-mlirtransformfuseintocontainingop><code>transform.structured.fuse_into_containing_op</code> (::mlir::transform::FuseIntoContainingOp)&nbsp;<a class=headline-hash href=#transformstructuredfuse_into_containing_op-mlirtransformfuseintocontainingop>¶</a></h3><p>Fuse a producer into a containing operation.</p><p>Syntax:</p><pre><code>operation ::= `transform.structured.fuse_into_containing_op` $producer_op `into` $containing_op attr-dict
</code></pre><p>Fuses the <code>producer_op</code> into the <code>containing_op</code>.
Returns a handle to the fused ops.</p><p>The producer is typically a slice of a tileable op (i.e., implements
TilingInterface). In that case, this transform computes the accessed
producer slice inside of the containing op (&ldquo;tile and fuse&rdquo;). Otherwise,
the entire producer is cloned inside the containing op (&ldquo;clone and fuse&rdquo;).</p><p>The containing op handle must be associated with exactly one payload op. The
producer op handle may be associated with multiple payload ops. This
transform fuses producers one-by-one, always picking an unspecified producer
that has at least one use inside the containing op among the
producers.</p><p>Note: If a producer has multiple uses inside the containing op, it is
currently tiled and/or cloned multiple times into the containing op.
TODO: Reuse already fused OpResults instead of tiling/cloning a second time
when possible. Fuse producers according to a topological sorting to achieve
the largest amount of reuse.</p><h4 id=return-modes-27>Return modes&nbsp;<a class=headline-hash href=#return-modes-27>¶</a></h4><p>If at least one producer could not be fused, this operation fails silently.
This is the case when tiling fails or when no producer op could be found
among the remaining producers that has at least one use within the
containing op. I.e., &ldquo;producers&rdquo; that are not consumed within the containing
op are rejected by this operation.</p><p>This operation reads and frees the producer handle.
This operation reads the containing op handle.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=operands-50>Operands:&nbsp;<a class=headline-hash href=#operands-50>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>producer_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>containing_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-40>Results:&nbsp;<a class=headline-hash href=#results-40>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>fused_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredfuse-mlirtransformfuseop><code>transform.structured.fuse</code> (::mlir::transform::FuseOp)&nbsp;<a class=headline-hash href=#transformstructuredfuse-mlirtransformfuseop>¶</a></h3><p>Tiles the operations pointed to by the target handle and fuses their
producers greedily using the options provided as attributes.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-33>Attributes:&nbsp;<a class=headline-hash href=#attributes-33>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tile_sizes</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>tile_interchange</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></tbody></table><h4 id=operands-51>Operands:&nbsp;<a class=headline-hash href=#operands-51>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-41>Results:&nbsp;<a class=headline-hash href=#results-41>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>loops</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredgeneralize-mlirtransformgeneralizeop><code>transform.structured.generalize</code> (::mlir::transform::GeneralizeOp)&nbsp;<a class=headline-hash href=#transformstructuredgeneralize-mlirtransformgeneralizeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.generalize` $target attr-dict
</code></pre><p>Transforms a named structured operation into the generic form with the
explicit attached region.</p><h4 id=return-modes-28>Return modes&nbsp;<a class=headline-hash href=#return-modes-28>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
If all the operations referred to by the <code>target</code> PDLOperation generalize
properly, the transform succeeds. Otherwise the transform silently fails.
The return handle points to only the subset of successfully produced
equivalent generic operations, which can be empty or contain the original
ops if they were already in generic form.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-52>Operands:&nbsp;<a class=headline-hash href=#operands-52>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-42>Results:&nbsp;<a class=headline-hash href=#results-42>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredhoist_padbuild_packing_loop_nest-mlirtransformhoistpadbuildpackingloopnestop><code>transform.structured.hoist_pad.build_packing_loop_nest</code> (::mlir::transform::HoistPadBuildPackingLoopNestOp)&nbsp;<a class=headline-hash href=#transformstructuredhoist_padbuild_packing_loop_nest-mlirtransformhoistpadbuildpackingloopnestop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.hoist_pad.build_packing_loop_nest` $target
              `above` $loop
              (`,` `transpose` `by` $transpose^)?
              attr-dict
              `:` functional-type(operands, results)
</code></pre><p>Helper transform used to hoist a tensor.pad target operation. This operation
creates the packing loop nest required by the hoist_pad operation and makes
that functionality available independently.</p><p>TODO: In the future, we should consider rewriting as a tensor.pack after
hoisting since this abstraction is now available.</p><h4 id=return-modes-29>Return modes&nbsp;<a class=headline-hash href=#return-modes-29>¶</a></h4><p>This operation ignores non-tensor.pad ops and drops them in the result.
If any non-tensor.pad is passed, the transform emits a silenceable failure.</p><p>The return handle points to only the subset of successfully created packing
loop nests, which can be empty.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-34>Attributes:&nbsp;<a class=headline-hash href=#attributes-34>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transpose</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-53>Operands:&nbsp;<a class=headline-hash href=#operands-53>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>loop</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-43>Results:&nbsp;<a class=headline-hash href=#results-43>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>packing_loop</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredhoist_pad-mlirtransformhoistpadop><code>transform.structured.hoist_pad</code> (::mlir::transform::HoistPadOp)&nbsp;<a class=headline-hash href=#transformstructuredhoist_pad-mlirtransformhoistpadop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.hoist_pad` $target
              `by` $num_loops `loops`
              (`,` `transpose` `by` $transpose^)?
              attr-dict
              `:` functional-type(operands, results)
</code></pre><p>Hoist the tensor.pad target operation by at most the given number of loops.
Optionally apply the transpose attribute to the inner dimensions.</p><p>TODO: In the future, we should consider rewriting as a tensor.pack after
hoisting since this abstraction is now available.
TODO: Maybe also return the linalg.generic transpose created at some point.</p><h4 id=return-modes-30>Return modes&nbsp;<a class=headline-hash href=#return-modes-30>¶</a></h4><p>This operation ignores non-tensor.pad ops and drops them in the result.
If any non-tensor.pad is passed, the transform emits a silenceable failure.</p><p>If all the operations referred to by the <code>target</code> handle padproperly, the
transform succeeds. Otherwise the transform silently fails.</p><p>The return handle points to only the subset of successfully hoisted
tensor.pad operations, which can be empty.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-35>Attributes:&nbsp;<a class=headline-hash href=#attributes-35>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>num_loops</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>transpose</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-54>Operands:&nbsp;<a class=headline-hash href=#operands-54>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-44>Results:&nbsp;<a class=headline-hash href=#results-44>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredhoist_redundant_tensor_subsets-mlirtransformhoistredundanttensorsubsetsop><code>transform.structured.hoist_redundant_tensor_subsets</code> (::mlir::transform::HoistRedundantTensorSubsetsOp)&nbsp;<a class=headline-hash href=#transformstructuredhoist_redundant_tensor_subsets-mlirtransformhoistredundanttensorsubsetsop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.hoist_redundant_tensor_subsets` $target
              attr-dict
              `:` functional-type(operands, results)
</code></pre><p>Hoists supported tensor subset extract/insert operation pairs out of
immediately enclosing loop iteratively, if the following conditions
are true:</p><ol><li>The 2 ops access the same tensor subset.</li><li>All operands are invariant under the enclosing loop.</li></ol><p>The supported subset extract/insert operation pairs currently comprise:</p><ul><li>tensor.extract_slice / tensor.insert_slice</li><li>vector.transfer_read / vector.transfer_write on tensors</li></ul><p>Only scf.for loops are currently supported.</p><p>When applied to:</p><ol><li>an scf.for loop, hoist out of this loop only.</li><li>a non-loop op, apply hoisting to all the contained loop ops.</li></ol><h4 id=return-modes-31>Return modes:&nbsp;<a class=headline-hash href=#return-modes-31>¶</a></h4><p>The operation always succeeds and returns nothing.</p><p>Traits: TransformEachOpTrait</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=operands-55>Operands:&nbsp;<a class=headline-hash href=#operands-55>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredhoist_redundant_vector_transfers-mlirtransformhoistredundantvectortransfersop><code>transform.structured.hoist_redundant_vector_transfers</code> (::mlir::transform::HoistRedundantVectorTransfersOp)&nbsp;<a class=headline-hash href=#transformstructuredhoist_redundant_vector_transfers-mlirtransformhoistredundantvectortransfersop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.hoist_redundant_vector_transfers` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Hoist vector.transfer_read / vector.transfer_write pairs out of immediately
enclosing scf::ForOp iteratively, if the following conditions are true:</p><ol><li>The 2 ops access the same memref with the same indices.</li><li>All operands are invariant under the enclosing scf::ForOp.</li><li>No uses of the memref either dominate the transfer_read or are
dominated by the transfer_write (i.e. no aliasing between the write and
the read across the loop)</li></ol><p>WARNING: This hoisting does not model parallelism and is generally incorrect
when used on distributed loops with memref semantics!
TODO: obsolete and should be retired.</p><h4 id=return-modes-32>Return modes:&nbsp;<a class=headline-hash href=#return-modes-32>¶</a></h4><p>The operation always succeeds and returns a handle to the transformed
function op.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-56>Operands:&nbsp;<a class=headline-hash href=#operands-56>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-45>Results:&nbsp;<a class=headline-hash href=#results-45>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredinsert_slice_to_copy-mlirtransforminsertslicetocopyop><code>transform.structured.insert_slice_to_copy</code> (::mlir::transform::InsertSliceToCopyOp)&nbsp;<a class=headline-hash href=#transformstructuredinsert_slice_to_copy-mlirtransforminsertslicetocopyop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.insert_slice_to_copy` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Targeted rewrite of an tensor.insert_slice to linalg.copy.
This is useful to materialize copies explicitly before bufferization and
transform them, avoiding the need to rediscover them after bufferization.</p><p>If the insert_slice source is already a linalg.copy, only return the source
op (i.e. do not create an additional linalg.copy op).</p><h4 id=return-modes-33>Return modes:&nbsp;<a class=headline-hash href=#return-modes-33>¶</a></h4><p>The operation always succeeds and returns a handle to the relevant
linalg.copy op.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-57>Operands:&nbsp;<a class=headline-hash href=#operands-57>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-46>Results:&nbsp;<a class=headline-hash href=#results-46>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredinterchange-mlirtransforminterchangeop><code>transform.structured.interchange</code> (::mlir::transform::InterchangeOp)&nbsp;<a class=headline-hash href=#transformstructuredinterchange-mlirtransforminterchangeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.interchange` $target
              (`iterator_interchange` `=` $iterator_interchange^)? attr-dict
</code></pre><p>Interchanges the iterators of the operations pointed to by the target handle
using the iterator interchange attribute.</p><h4 id=return-modes-34>Return modes&nbsp;<a class=headline-hash href=#return-modes-34>¶</a></h4><p>This operation ignores non-linalg::Generic ops and drops them in the return.
This operation fails if the interchange attribute is invalid.
If all the operations referred to by the <code>target</code> PDLOperation interchange
properly, the transform succeeds.
If any interchange fails, the transform definitely fails.
The return handle points to only the subset of successfully produced
interchanged operations, which can be empty.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-36>Attributes:&nbsp;<a class=headline-hash href=#attributes-36>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>iterator_interchange</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute whose value is non-negative</td></tr></tbody></table><h4 id=operands-58>Operands:&nbsp;<a class=headline-hash href=#operands-58>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-47>Results:&nbsp;<a class=headline-hash href=#results-47>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredlower_pack-mlirtransformlowerpackop><code>transform.structured.lower_pack</code> (::mlir::transform::LowerPackOp)&nbsp;<a class=headline-hash href=#transformstructuredlower_pack-mlirtransformlowerpackop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.lower_pack` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Rewrite a tensor.pack into tensor.pad + tensor.expand_shape + linalg.transpose.</p><h4 id=return-modes-35>Return modes&nbsp;<a class=headline-hash href=#return-modes-35>¶</a></h4><p>This operation ignores non-pack ops and drops them in the return.
This operation produces a silenceableFailure if the rewrite fails for any
reason.
If all the operations referred to by the <code>target</code> are rewritten, the
transform succeeds.
Return handles to the newly produced pad, expand_shape and transpose ops.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-59>Operands:&nbsp;<a class=headline-hash href=#operands-59>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to tensor.pack operations</td></tr></tbody></table><h4 id=results-48>Results:&nbsp;<a class=headline-hash href=#results-48>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>pad_op</code></td><td>Transform IR handle to tensor.pad operations</td></tr><tr><td style=text-align:center><code>expand_shape_op</code></td><td>Transform IR handle to tensor.expand_shape operations</td></tr><tr><td style=text-align:center><code>transpose_op</code></td><td>Transform IR handle to linalg.transpose operations</td></tr></tbody></table><h3 id=transformstructuredlower_unpack-mlirtransformlowerunpackop><code>transform.structured.lower_unpack</code> (::mlir::transform::LowerUnPackOp)&nbsp;<a class=headline-hash href=#transformstructuredlower_unpack-mlirtransformlowerunpackop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.lower_unpack` $target attr-dict `:` functional-type(operands, results)
</code></pre><p>Lower a tensor.unpack into empty + linalg.transpose + tensor.collapse_shape +
tensor.extract_slice.</p><h4 id=return-modes-36>Return modes&nbsp;<a class=headline-hash href=#return-modes-36>¶</a></h4><p>This operation ignores non-unpack ops and drops them in the return.
This operation produces a silenceableFailure if the rewrite fails for any
reason.
If all the operations referred to by the <code>target</code> are rewritten, the
transform succeeds.
Return handles to the newly produced empty, transpose, collapse_shape and extract_slice ops.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-60>Operands:&nbsp;<a class=headline-hash href=#operands-60>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>Transform IR handle to tensor.unpack operations</td></tr></tbody></table><h4 id=results-49>Results:&nbsp;<a class=headline-hash href=#results-49>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>empty_op</code></td><td>Transform IR handle to tensor.empty operations</td></tr><tr><td style=text-align:center><code>transpose_op</code></td><td>Transform IR handle to linalg.transpose operations</td></tr><tr><td style=text-align:center><code>collapse_shape_op</code></td><td>Transform IR handle to tensor.collapse_shape operations</td></tr><tr><td style=text-align:center><code>extract_slice_op</code></td><td>Transform IR handle to tensor.extract_slice operations</td></tr></tbody></table><h3 id=transformstructuredmasked_vectorize-mlirtransformmaskedvectorizeop><code>transform.structured.masked_vectorize</code> (::mlir::transform::MaskedVectorizeOp)&nbsp;<a class=headline-hash href=#transformstructuredmasked_vectorize-mlirtransformmaskedvectorizeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.masked_vectorize` $target
              `vector_sizes` custom&lt;DynamicIndexList&gt;($vector_sizes,
              $static_vector_sizes)
              attr-dict
</code></pre><p>Vectorize the target ops, which must be Linalg ops, with masked vectors
of the specified size.</p><p>The vector sizes can be either static or dynamic (SSA values). In case of
SSA values, the handle must be mapped to exactly one payload op with
exactly one index-typed result.</p><p>Note: The input vector sizes must be bigger than or equal to their
counterpart iteration space sizes.</p><p>Typically this operator should be applied to linalg operations that have
already be tiled to the appropriate sizes.</p><h4 id=return-modes-37>Return modes:&nbsp;<a class=headline-hash href=#return-modes-37>¶</a></h4><p>This operation produces a definite failure if the dynamic vector sizes (SSA
values) do not satify the constraints mentioned above. It produces a
silenceable failure if at least one target op is not a Linalg op or fails to
vectorize.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-37>Attributes:&nbsp;<a class=headline-hash href=#attributes-37>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vectorize_nd_extract</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>static_vector_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-61>Operands:&nbsp;<a class=headline-hash href=#operands-61>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>vector_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredmatch-mlirtransformmatchop><code>transform.structured.match</code> (::mlir::transform::MatchOp)&nbsp;<a class=headline-hash href=#transformstructuredmatch-mlirtransformmatchop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.match` (`ops` `{` $ops^ `}`)?
              (`interface` `{` $interface^ `}`)?
              (`attributes` $op_attrs^)?
              (`filter_result_type` `=` $filter_result_type^)?
              `in` $target attr-dict
              `:` functional-type($target, results)
</code></pre><p>Match op with the specified constraints, within the target op.</p><p>The following constraints are supported:</p><ul><li>interface: an optional MatchInterfaceEnum specifying an enum
representation for an interface to target.</li><li>ops: an optional StrArrayAttr specifying the concrete name of an op.
Multiple names can be specified. Matched ops must have one of specified
names.</li><li>attribute: the matched op must have all specified attributes (with their
specified values).</li><li>filter_result_type: the matched op must return exactly this one type.</li></ul><p>Note: Only ops that satisfy all specified constraints are matched.</p><p>TODO: Extend with regions to allow a limited form of constraints.</p><h4 id=return-modes-38>Return modes&nbsp;<a class=headline-hash href=#return-modes-38>¶</a></h4><p>This op traverses the ops nested under <code>target</code> and returns the handles to
all the operations that match the requirements.</p><p>This op fails if the target is not a handle to exactly one operation.
Otherwise it succeeds.</p><p>This operation does not consume the target handle and produces new handles:
it is a navigation op.</p><p>Traits: NavigationTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-38>Attributes:&nbsp;<a class=headline-hash href=#attributes-38>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>ops</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>string array attribute</td></tr><tr><td style=text-align:center><code>interface</code></td><td style=text-align:center>mlir::transform::MatchInterfaceEnumAttr</td><td>An interface to match</td></tr><tr><td style=text-align:center><code>op_attrs</code></td><td style=text-align:center>::mlir::DictionaryAttr</td><td>dictionary of named attribute values</td></tr><tr><td style=text-align:center><code>filter_result_type</code></td><td style=text-align:center>::mlir::TypeAttr</td><td>any type attribute</td></tr></tbody></table><h4 id=operands-62>Operands:&nbsp;<a class=headline-hash href=#operands-62>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-50>Results:&nbsp;<a class=headline-hash href=#results-50>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredmultitile_sizes-mlirtransformmultitilesizesop><code>transform.structured.multitile_sizes</code> (::mlir::transform::MultiTileSizesOp)&nbsp;<a class=headline-hash href=#transformstructuredmultitile_sizes-mlirtransformmultitilesizesop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.multitile_sizes` $target attr-dict `:` custom&lt;MultitileSizesTypes&gt;(type($target), type($low_size), type($high_size), type($split_point))
</code></pre><p>Emits the IR computing the tile sizes <code>s1</code> and <code>s2</code> such that:</p><ul><li>there exists a combination of <code>n</code> tiles of size <code>s1</code> and <code>m</code> tiles of
size <code>s2</code> that covers the entirety of the iteration space <code>dimension</code> of
the target structured op;</li><li><code>s1</code>, <code>s2</code> is less than or equal to <code>target_size</code>;</li><li><code>s1</code> and <code>s2</code> are divisible by `divisor.</li></ul><p>For example, for a dimension of size 54 with target size 12 and divisor 2,
this can emit the IR computing the tile size 10, used for 3 tiles, and 12,
used for 2 tiles, totally 10<em>3 + 12</em>2 = 54. Note that when the divisor does
not divide the original dimension size, it is impossible to compute such
tile sizes. An assertion is emitted to guard against this in the dynamic
case.</p><p>Expects the target size and the divisor to be strictly positive. Folds the
IR as much as possible, normally obtaining constant sizes and numbers of
tiles for a statically known dimension.</p><p>This does <em>not</em> consume the target handle and produces three handles each
pointing to single-result index-typed operations (which may be arithmetic
constant operations) defining the two respective tile sizes and the product
of the first tile size with the number of tiles of that size (useful for
splitting the iteration space).</p><p>This operation composes with the regular tiling when applied per-dimension:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%sz1</span><span class=p>,</span> <span class=nv>%sz2</span><span class=p>,</span> <span class=nv>%split</span> <span class=p>=</span> structured<span class=p>.</span>multitile_sizes <span class=nv>%target</span>
                     <span class=p>{</span> <span class=nl>target_size =</span> <span class=m>10</span><span class=p>,</span> <span class=nl>dimension =</span> <span class=m>1</span> <span class=p>}</span>
                   <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;,</span>
                     <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;,</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;</span>
<span class=nv>%low</span><span class=p>,</span> <span class=nv>%high</span> <span class=p>=</span> structured<span class=p>.</span>split <span class=nv>%target</span> after <span class=nv>%split</span> <span class=p>{</span> <span class=nl>dimension =</span> <span class=m>1</span> <span class=p>}</span>
            <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;</span>
<span class=nv>%tiled_low</span><span class=p>,</span> <span class=nv>%loop1</span> <span class=p>=</span> structured<span class=p>.</span>tile <span class=nv>%low</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=nv>%sz1</span><span class=p>]</span>
                   <span class=p>:</span> <span class=p>(!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;)</span>
                  <span class=p>-&gt;</span> <span class=p>(!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>)</span>
<span class=nv>%tiled_high</span><span class=p>,</span> <span class=nv>%loop2</span> <span class=p>=</span> structured<span class=p>.</span>tile <span class=nv>%high</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=nv>%sz2</span><span class=p>]</span>
                    <span class=p>:</span> <span class=p>(!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>param<span class=p>&lt;</span><span class=k>i64</span><span class=p>&gt;)</span>
                   <span class=p>-&gt;</span> <span class=p>(!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>)</span>
<span class=nv>%common</span> <span class=p>=</span> merge_handles <span class=nv>%tiled_low</span><span class=p>,</span> <span class=nv>%tiled_high</span> <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op

<span class=nv>%sz3</span><span class=p>,</span> <span class=nv>%sz4</span><span class=p>,</span> <span class=nv>%split</span> <span class=p>=</span> structured<span class=p>.</span>multitile_size <span class=nv>%target</span>
                     <span class=p>{</span> <span class=nl>target_size =</span> <span class=m>42</span><span class=p>,</span> <span class=nl>dimension =</span> <span class=m>0</span> <span class=p>}</span>
                   <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span>
                     <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op
<span class=nv>%sz3r</span><span class=p>,</span> <span class=nv>%sz4r</span><span class=p>,</span> <span class=nv>%splitr</span> <span class=p>=</span> replicate num<span class=p>(</span><span class=nv>%common</span><span class=p>)</span> <span class=nv>%sz3</span><span class=p>,</span> <span class=nv>%sz4</span><span class=p>,</span> <span class=nv>%splitr</span>
         <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op
structured<span class=p>.</span>split <span class=nv>%common</span> after <span class=nv>%splitr</span> <span class=p>{</span> <span class=nl>dimension =</span> <span class=m>0</span> <span class=p>}</span>
         <span class=p>:</span> <span class=p>!</span>transform<span class=p>.</span>any_op<span class=p>,</span> <span class=p>!</span>transform<span class=p>.</span>any_op
<span class=c>// ...
</span></code></pre></div><p>Traits: TransformEachOpTrait</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-39>Attributes:&nbsp;<a class=headline-hash href=#attributes-39>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dimension</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>target_size</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>divisor</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-63>Operands:&nbsp;<a class=headline-hash href=#operands-63>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-51>Results:&nbsp;<a class=headline-hash href=#results-51>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>low_size</code></td><td>transform &lsquo;param&rsquo; type or any handle type</td></tr><tr><td style=text-align:center><code>high_size</code></td><td>transform &lsquo;param&rsquo; type or any handle type</td></tr><tr><td style=text-align:center><code>split_point</code></td><td>transform &lsquo;param&rsquo; type or any handle type</td></tr></tbody></table><h3 id=transformstructuredpack_greedily-mlirtransformpackgreedilyop><code>transform.structured.pack_greedily</code> (::mlir::transform::PackGreedilyOp)&nbsp;<a class=headline-hash href=#transformstructuredpack_greedily-mlirtransformpackgreedilyop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.pack_greedily` $target
              oilist(
              `matmul_packed_sizes` `=` custom&lt;DynamicIndexList&gt;($matmul_packed_sizes,
              $static_matmul_packed_sizes)
              (`matmul_padded_sizes_next_multiple_of` `=`
              $matmul_padded_sizes_next_multiple_of^)?
              `matmul_inner_dims_order` `=` $matmul_inner_dims_order
              )
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Target a Linalg op and rewrite it into packed LinalgOp form by trying to
infer whether a known suboperation is embedded</p><p>Different packing strategies are applied in order, when one applies
successfully, the transform returns:</p><ol><li><p>Matmul packing: Try to infer a matmul operation embedded in the target op.
Specifically, this looks for 2 parallel dimensions that participate in
an outer-product and 1 reduction dimension.
These dimensions are referred as (m, n, k) to match canonical matmul
terminology.</p><p>The packed sizes for (m, n, k) are specified by <code>matmul_packed_sizes</code>
and the optional <code>matmul_padded_sizes_next_multiple_of</code>.
When an entry <code>matmul_packed_sizes[i]</code> is non-0, the corresponding
dimension is packed by <code>matmul_packed_sizes[i]</code>.
Otherwise, the dimension is merely padded to the next multiple of
<code>matmul_padded_sizes_next_multiple_of[i]</code>.</p><p><code>matmul_padded_sizes_next_multiple_of</code> is optional and is expected to
either be empty or of size <code>3</code>, matching the size of <code>matmul_packed_sizes</code>.
For each individual element of <code>matmul_packed_sizes</code> and
<code>matmul_padded_sizes_next_multiple_of</code>, only one of them is allowed to
be non-zero.</p><p>The ordering of the packed dimensions (mm, nn, kk) is specified by the
<code>matmul_inner_dims_order</code> attribute.</p></li></ol><p>Packing occurs as follows:</p><ol><li>Find the dimensions to pack according to the strategy.</li><li>The target is converted to linalg.generic form.</li><li>An interchange transform is applied to isolate the dimensions to pack as
the most minor indexing dimensions of the linalg.generic. The most minor
dimensions are themselves ordered according to <code>inner_dims_order</code>.</li><li>An elementwise traversal of <code>matmul_packed_sizes</code> and
<code>matmul_padded_sizes_next_multiple_of</code> is performed and for each
dimension <code>d</code>, either pack to <code>matmul_packed_sizes[d]</code> or pad to the
<code>matmul_padded_sizes_next_multiple_of[d]</code>.</li><li>Packing/padding is performed by the amounts determined in step 4. and
following <code>inner_dims_order</code>.</li></ol><p>By normalizing the most minor dimensions to <code>inner_dims_order</code>, the transform
guarantees that packing immediately generates inner dimensions in a desirable
layout.</p><p>Outer dimension layout permutations are not controlled by this transform op
at the moment and can be obtained by composing with the pack_transpose
transformation.</p><h4 id=return-modes-39>Return modes&nbsp;<a class=headline-hash href=#return-modes-39>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
It returns the list of packed Linalg ops or the original op when all available
packing strategies failed to apply.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-40>Attributes:&nbsp;<a class=headline-hash href=#attributes-40>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_matmul_packed_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute with exactly 3 elements</td></tr><tr><td style=text-align:center><code>matmul_padded_sizes_next_multiple_of</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute with 0 or 3 elements</td></tr><tr><td style=text-align:center><code>matmul_inner_dims_order</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute with exactly 3 elements</td></tr></tbody></table><h4 id=operands-64>Operands:&nbsp;<a class=headline-hash href=#operands-64>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>matmul_packed_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-52>Results:&nbsp;<a class=headline-hash href=#results-52>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>packed_op</code></td><td>Transform IR handle to linalg.generic operations</td></tr></tbody></table><h3 id=transformstructuredpack-mlirtransformpackop><code>transform.structured.pack</code> (::mlir::transform::PackOp)&nbsp;<a class=headline-hash href=#transformstructuredpack-mlirtransformpackop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.pack` $target
              `packed_sizes` `=` custom&lt;DynamicIndexList&gt;($packed_sizes,
              $static_packed_sizes)
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Pack a LinalgOp by applying a data tiling transformation on the op and
packing the operands according to the <code>packed_sizes</code> specification.</p><p>Iterator dimensions are tiled in their canonical order in the op spec.
Operands are packed according to the same canonical order of the op iterator
dimensions.</p><p>Specifying a packed size of 0 for an iterator removes it from consideration
for packing.</p><p><code>tensor.pack</code> (resp. <code>tensor.unpack</code>) operations are inserted for the operands
(resp. results) that need to be packed (resp. unpacked) according to the
<code>packed_sizes</code> specification.</p><h4 id=example-1>Example&nbsp;<a class=headline-hash href=#example-1>¶</a></h4><p>Consider a <code>linalg.matmul</code> with indexing maps:</p><pre><code>  //              M   N   K       M   K
  // affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
  //                              K   N
  // affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
  //                              M   N
  // affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
  %0 = linalg.matmul  ins(%A, %B: tensor&lt;?x?xf32&gt;, tensor&lt;?x?xf32&gt;)
                     outs(    %C: tensor&lt;?x?xf32&gt;)
</code></pre><p>Specifying packed_sizes [2, 3, 4] results in tiling the iterator dimensions
M, N and K, in this order, in both the op and its operands.</p><pre><code>  //              M   N   K   m   n   k       M   K   m   k
  // affine_map&lt;(d0, d1, d2, d3, d4, d5) -&gt; (d0, d2, d3, d5)&gt;
  //                                          K   N   n   k
  // affine_map&lt;(d0, d1, d2, d3, d4, d5) -&gt; (d2, d1, d4, d5)&gt;
  //                                          M   N   m   n
  // affine_map&lt;(d0, d1, d2, d3, d4, d5) -&gt; (d0, d1, d3, d4)&gt;
  %0 = linalg.generic_representing_some_higher_d_matmul  
        ins(%A, %B: tensor&lt;?x?x2x4xf32&gt;, tensor&lt;?x?x4x3xf32&gt;)
       outs(    %C: tensor&lt;?x?x2x3xf32&gt;)
</code></pre><p>In particular, note that the second operand <code>B</code> has shape <code>KxNxnxk</code> (and not
<code>KxNxkxn</code> as one could expect by looking <strong>only</strong> at the operand).</p><p>Other layouts can be obtained unsurprisingly from this canonical
transformation by composing the resulting operation with a (future)
<code>transform.structured.pack_transpose</code> op.
This composition allows separating concerns and composes better compared
to adding additional permutation attributes to this transform op.</p><h4 id=return-modes-40>Return modes&nbsp;<a class=headline-hash href=#return-modes-40>¶</a></h4><p>This operation applies to a single Linalg op, otherwise it fails.
This operation may produce a definiteFailure if the packing fails for any
reason.</p><p>The returned handle point to the packed LinalgOp.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-41>Attributes:&nbsp;<a class=headline-hash href=#attributes-41>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_packed_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-65>Operands:&nbsp;<a class=headline-hash href=#operands-65>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>packed_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-53>Results:&nbsp;<a class=headline-hash href=#results-53>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>packed_op</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredpack_transpose-mlirtransformpacktransposeop><code>transform.structured.pack_transpose</code> (::mlir::transform::PackTransposeOp)&nbsp;<a class=headline-hash href=#transformstructuredpack_transpose-mlirtransformpacktransposeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.pack_transpose` $target_pack_or_un_pack_op
              `with_compute_op` `(` $target_linalg_op `)`
              (`outer_perm` `=` $outer_perm^ )?
              (`inner_perm` `=` $inner_perm^ )?
              attr-dict
              `:` functional-type(operands, results)
</code></pre><p>Apply a transposition to a single <code>tensor.pack</code> (resp. <code>tensor.unpack</code>) and
update the <code>linalg.generic</code> op that consumes (resp. produces) the operation.</p><p>This transform allows composing a simple <code>structured.pack</code> with additional
transpositions to e.g. match the data format required by a specific library
call or ISA instruction.</p><p>The transpose spec must specify at least one of <code>outer_perm</code> or <code>inner_perm</code>
attributes, which will act upon the <code>outer_dims_perm</code> or <code>inner_dims_pos</code> of
the specified <code>tensor.pack</code> or <code>tensor.unpack</code> op.</p><p>If the <code>target</code> of this op is a <code>tensor.pack</code> then a new <code>tensor.empty</code> will
be created along with transposed versions of the <code>tensor.pack</code> and the
consuming <code>linalg.generic</code>, which is expected to be the sole consumer.</p><p>If the <code>target</code> of this op is a <code>tensor.unpack</code> then the whole pack / compute
/ unpack chain will be transposed and transposed clones of <code>tensor.pack</code>,
the consuming <code>linalg.generic</code> and the tail <code>tensor.pack</code> will be created.</p><h4 id=return-modes-41>Return modes&nbsp;<a class=headline-hash href=#return-modes-41>¶</a></h4><p>This operation targets a single <code>tensor.pack</code> / <code>tensor.unpack</code> op and a
single matching <code>linalg.generic</code> that consumes / produces the op. Otherwise,
it produces a silenceableFailure.</p><p>This operation may produce a silenceableFailure if the transpose spec is
ill-formed (i.e. <code>outer_perm</code> or <code>inner_perm</code> are not permutations of the
proper rank) or if the tranposition of all involved operations fails for any
reason.</p><p>This operation returns 3 handles, one to the transformed LinalgOp, one to
the transformed <code>tensor.pack</code> and one to the transformed <code>tensor.unpack</code>.
The last handle for <code>tensor.unpack</code> is empty if <code>target_pack_or_unpack_op</code>
was not itself a <code>tensor.unpack</code>.</p><p>Traits: FunctionalStyleTransformOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-42>Attributes:&nbsp;<a class=headline-hash href=#attributes-42>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>outer_perm</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>inner_perm</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-66>Operands:&nbsp;<a class=headline-hash href=#operands-66>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target_pack_or_un_pack_op</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>target_linalg_op</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-54>Results:&nbsp;<a class=headline-hash href=#results-54>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>packed_op</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>pack_op</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>un_pack_op</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredpad-mlirtransformpadop><code>transform.structured.pad</code> (::mlir::transform::PadOp)&nbsp;<a class=headline-hash href=#transformstructuredpad-mlirtransformpadop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.pad` $target attr-dict
</code></pre><p>Pads the operations pointed to by the target handle using the options
provides as operation attributes.</p><h4 id=return-modes-42>Return modes&nbsp;<a class=headline-hash href=#return-modes-42>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
This operation may produce a definiteFailure if the padding fails for any
reason.
If all the operations referred to by the <code>target</code> PDLOperation pad
properly, the transform succeeds. Otherwise the transform silently fails.
The return handle points to only the subset of successfully produced
padded operations, which can be empty.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-43>Attributes:&nbsp;<a class=headline-hash href=#attributes-43>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>padding_values</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>array attribute</td></tr><tr><td style=text-align:center><code>padding_dimensions</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>pack_paddings</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>transpose_paddings</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>array of arrays of i64</td></tr></tbody></table><h4 id=operands-67>Operands:&nbsp;<a class=headline-hash href=#operands-67>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-55>Results:&nbsp;<a class=headline-hash href=#results-55>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredpromote-mlirtransformpromoteop><code>transform.structured.promote</code> (::mlir::transform::PromoteOp)&nbsp;<a class=headline-hash href=#transformstructuredpromote-mlirtransformpromoteop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.promote` $target attr-dict
</code></pre><p>Promotes the specified operands of the target into a separate memory buffer.</p><p>At this point, this transform does not allow customizing alloc/dealloc
functions nor the behavior on copy in/out operations.</p><h4 id=return-modes-43>Return modes&nbsp;<a class=headline-hash href=#return-modes-43>¶</a></h4><p>This operation applies to a single Linalg op that satisfies the
<code>promoteSubviewsPrecondition</code>, otherwise it fails.</p><p>If the operations referred to by the <code>target</code> PDLOperation promote
properly, the transform succeeds.</p><p>When successful, the return handle points to the $target operation that
was modified inplace.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-44>Attributes:&nbsp;<a class=headline-hash href=#attributes-44>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operands_to_promote</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td style=text-align:center><code>use_full_tile_buffers</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>1-bit boolean array attribute</td></tr><tr><td style=text-align:center><code>use_full_tiles_by_default</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>use_alloca</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>mapping</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Device Mapping array attribute</td></tr><tr><td style=text-align:center><code>alignment</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-68>Operands:&nbsp;<a class=headline-hash href=#operands-68>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-56>Results:&nbsp;<a class=headline-hash href=#results-56>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredreplace-mlirtransformreplaceop><code>transform.structured.replace</code> (::mlir::transform::ReplaceOp)&nbsp;<a class=headline-hash href=#transformstructuredreplace-mlirtransformreplaceop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.replace` $target attr-dict-with-keyword regions
</code></pre><p>Replace all <code>target</code> payload ops with the single op that is contained in
this op&rsquo;s region. All targets must have zero arguments and must be isolated
from above.</p><p>This op is for debugging/experiments only.</p><h4 id=return-modes-44>Return modes&nbsp;<a class=headline-hash href=#return-modes-44>¶</a></h4><p>This operation consumes the <code>target</code> handle.</p><p>Traits: HasOnlyGraphRegion, IsolatedFromAbove, NoTerminator, SingleBlock</p><p>Interfaces: MemoryEffectOpInterface, RegionKindInterface, TransformOpInterface</p><h4 id=operands-69>Operands:&nbsp;<a class=headline-hash href=#operands-69>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-57>Results:&nbsp;<a class=headline-hash href=#results-57>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>replacement</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredrewrite_in_destination_passing_style-mlirtransformrewriteindestinationpassingstyleop><code>transform.structured.rewrite_in_destination_passing_style</code> (::mlir::transform::RewriteInDestinationPassingStyleOp)&nbsp;<a class=headline-hash href=#transformstructuredrewrite_in_destination_passing_style-mlirtransformrewriteindestinationpassingstyleop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.rewrite_in_destination_passing_style` $target attr-dict
              `:` functional-type($target, results)
</code></pre><p>Rewrite a supported tensor operation that is not in destination-passing style
into a form that is in destination-passing style.
Currently supported operations are:</p><ul><li>tensor.pad</li><li>tensor.generate</li><li>tensor.from_elements
This dichotomy hints at a future interface, for now the implementation just
switches between different implementation.</li></ul><h4 id=return-modes-45>Return modes&nbsp;<a class=headline-hash href=#return-modes-45>¶</a></h4><p>This operation ignores non-unsupported ops and drops them from the return.
If all the operations referred to by the <code>target</code> PDLOperation generalize
properly, the transform succeeds. Otherwise the transform silently fails.
The return handle points to a subset of successfully produced operations:</p><ul><li>tensor.pad case, the returned handle points to the tensor.insert_slice.</li><li>tensor.generate case, the returned handle points to the linalg.generic.</li><li>tensor.from_elements case, the returned handle points to the last
tensor.insert.</li></ul><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-70>Operands:&nbsp;<a class=headline-hash href=#operands-70>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-58>Results:&nbsp;<a class=headline-hash href=#results-58>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredscalarize-mlirtransformscalarizeop><code>transform.structured.scalarize</code> (::mlir::transform::ScalarizeOp)&nbsp;<a class=headline-hash href=#transformstructuredscalarize-mlirtransformscalarizeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.scalarize` $target attr-dict
</code></pre><p>Indicates that ops of a specific kind in the given function should be
scalarized (i.e. their dynamic dimensions tiled by 1).</p><h4 id=return-modes-46>Return modes:&nbsp;<a class=headline-hash href=#return-modes-46>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
This operation produces <code>definiteFailure</code> if the scalarization fails for any
reason.
If all the operations referred to by the <code>target</code> PDLOperation scalarize
properly, the transform succeeds. Otherwise the transform silently fails.</p><p>The return handle points to only the subset of successfully produced
tiled-by-1 operations, which can be empty.</p><p>This operation does not return handles to the tiled loop.
We make this design choice because it is hard to know ahead of time the
number of loops that will be produced (it depends on the number of dynamic
dimensions after multiple transformations have been applied).
Loops can always be recovered by navigating from the tiled operations if
needed.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-71>Operands:&nbsp;<a class=headline-hash href=#operands-71>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-59>Results:&nbsp;<a class=headline-hash href=#results-59>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredsplit-mlirtransformsplitop><code>transform.structured.split</code> (::mlir::transform::SplitOp)&nbsp;<a class=headline-hash href=#transformstructuredsplit-mlirtransformsplitop>¶</a></h3><p>Indicates that the given <code>target</code> op should be split into two complementary
parts, which combined cover the entire iteration domain of the original op.
The split is performed along the iteration space dimension provided as
attribute. In case of dimension overflow, the transformation fails. The
split is performed at the dimension iterator value specified as either the
static split point attribute when it is known at transform IR construction
time or as the handle to an operation producing a single index-typed value
when it is computed by payload IR. In the latter case, the static split
point must be set to <code>ShapedType::kDynamic</code> and the dynamic size handle
must point to as many value-producing operations as there are structured
operations pointed to by the target handle.</p><p>The operation consumes the target handle, but preserves the split point
handle if provided. It produces two new handles pointing to the two parts
of the structured op after splitting, in the same order as the target
operand, with the first handle corresponding to the part with lower
iteration space indices.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-45>Attributes:&nbsp;<a class=headline-hash href=#attributes-45>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dimension</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>static_split_point</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-72>Operands:&nbsp;<a class=headline-hash href=#operands-72>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>dynamic_split_point</code></td><td>transform &lsquo;param&rsquo; type or any handle type</td></tr></tbody></table><h4 id=results-60>Results:&nbsp;<a class=headline-hash href=#results-60>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>first</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>second</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredsplit_reduction-mlirtransformsplitreductionop><code>transform.structured.split_reduction</code> (::mlir::transform::SplitReductionOp)&nbsp;<a class=headline-hash href=#transformstructuredsplit_reduction-mlirtransformsplitreductionop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.split_reduction` $target attr-dict
</code></pre><p>Indicates that the given <code>target</code> op should be transformed with the
<code>splitReduction</code> transformation and split factor provided as attribute.</p><p>The <code>splitReduction</code> transformation splits the first single linalg op
reduction into a parallel and reduction dimension.
A new <code>linalg.generic</code> op is created to perform the rest of the reduction.</p><p>The transformation supports different configurations attributes:</p><ul><li>split_factor: the factor by which to split (i.e. the size of the
remaining reduction after splitting).</li><li>insert_split_dimension: the dimension in the temporary tensor into
which the new parallel dimension is inserted.</li><li>inner_parallel: specifies whether the parallel dimension is before or
after the reduction dimension in the splitting op.</li><li>use_scaling_algorithm: whether to use a scaling based formulation that
does not create an ExpandShapeOp (default: do not use scaling)</li><li>use_alloc: whether to use an alloc op to allocate the temporary
tensor (default: do not use alloc op)</li></ul><h4 id=return-modes-47>Return modes&nbsp;<a class=headline-hash href=#return-modes-47>¶</a></h4><p>This operation ignores non-Linalg ops and drops them in the return.
This operation produces <code>definiteFailure</code> if the splitting fails for any
reason.</p><p>If all the operations referred to by the <code>target</code> PDLOperation split
properly, the transform succeeds. Otherwise the transform silently fails.
The 4 returned handles points to only the subset of successfully produced
computational operations, which can all be empty.
This 4 returned handles point to:</p><ul><li>the init op (or tensor_alloc op if use_alloc = true),</li><li>the fill op used to initialize the neutral element,</li><li>the split op and</li><li>the result-combining op.</li></ul><h4 id=example-default-use_scaling_algorithm--false-use_alloc--false>Example (default: <code>use_scaling_algorithm = false, use_alloc = false</code>):&nbsp;<a class=headline-hash href=#example-default-use_scaling_algorithm--false-use_alloc--false>¶</a></h4><pre><code>  %r = linalg.generic {indexing_maps = [affine_map&lt;(d0) -&gt; (d0)&gt;,
                                        affine_map&lt;(d0) -&gt; ()&gt;],
        iterator_types = [&quot;reduction&quot;]}
  ins(%in : tensor&lt;32xf32&gt;)
  outs(%out : tensor&lt;f32&gt;) {
  ^bb0(%arg1: f32, %arg2: f32):
    %y = arith.addf %arg1, %arg2 : f32
    linalg.yield %y : f32
  } -&gt; tensor&lt;f32&gt;
</code></pre><p>is split into:</p><pre><code>  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.expand_shape %in [[0, 1]] : tensor&lt;32xf32&gt; into tensor&lt;4x8xf32&gt;
  %1 = tensor.empty() : tensor&lt;4xf32&gt;
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor&lt;4xf32&gt;) -&gt; tensor&lt;4xf32&gt;
  %3 = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;,
                                        affine_map&lt;(d0, d1) -&gt; (d0)&gt;],
    iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]}
    ins(%0 : tensor&lt;4x8xf32&gt;) outs(%2 : tensor&lt;4xf32&gt;) {
    ^bb0(%arg3: f32, %arg5: f32):
    %5 = arith.addf %arg3, %arg4 : f32
    linalg.yield %5 : f32
  } -&gt; tensor&lt;4xf32&gt;
  %r = linalg.generic {indexing_maps = [affine_map&lt;(d0) -&gt; (d0)&gt;,
                                        affine_map&lt;(d0) -&gt; ()&gt;],
    iterator_types = [&quot;reduction&quot;]}
    ins(%3 : tensor&lt;4xf32&gt;) outs(%out : tensor&lt;f32&gt;) {
    ^bb0(%arg3: f32, %arg4: f32):
    %5 = arith.addf %arg3, %arg4 : f32
    linalg.yield %5 : f32
  } -&gt; tensor&lt;f32&gt;
</code></pre><h4 id=example-use_scaling_algorithm--true-use_alloc--true>Example (<code>use_scaling_algorithm = true, use_alloc = true</code>):&nbsp;<a class=headline-hash href=#example-use_scaling_algorithm--true-use_alloc--true>¶</a></h4><p>Instead of introducing an ExpandShapeOp, this scaling-based implementation
rewrites a reduction dimension <code>k</code> into <code>k * split_factor + kk</code>.
The dimension <code>kk</code> is added as an extra parallel dimension to the
intermediate output tensor at position <code>insert_split_dimension</code>.</p><p>Consider a minimal example where <code>k</code> is reduced:
O(i, j) += I(i, j, k)
Assume i=3, j=5, k=128, split_factor=16 and insert_split_dimension=0.
The compute is rewritten as:
a. O_i(kk, i, j) += I(i, j, 16 * k + kk)
b. O(i, j) += O_i(kk, i, j)
The intermediate tensor O_i is of shape (128/16)x3x5 == 8x3x5.</p><h4 id=example-2>Example:&nbsp;<a class=headline-hash href=#example-2>¶</a></h4><pre><code> %0 = linalg.matmul ins(%A, %B: tensor&lt;16x256xf32&gt;, tensor&lt;256x32xf32&gt;)
   outs(%C: tensor&lt;16x32xf32&gt;) -&gt; tensor&lt;16x32xf32&gt;
</code></pre><p>Is transformed to:</p><pre><code> #map0 = affine_map&lt;(d0, d1, d2, d3) -&gt; (d0, d2 * 4 + d3)&gt;
 #map1 = affine_map&lt;(d0, d1, d2, d3) -&gt; (d2 * 4 + d3, d1)&gt;
 #map2 = affine_map&lt;(d0, d1, d2, d3) -&gt; (d2, d3)&gt;
 #map3 = affine_map&lt;(d0, d1, d2, d3) -&gt; (d0, d1, d2)&gt;
 #map4 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1, d2)&gt;
 #map5 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
 %0 = tensor.empty() : tensor&lt;16x32x64xf32&gt;
 %cst = arith.constant 0.000000e+00 : f32
 %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor&lt;16x32x64xf32&gt;) -&gt;
    tensor&lt;16x32x64xf32&gt;
 %2 = tensor.empty() : tensor&lt;64x4xi1&gt;

 %3 = linalg.generic {indexing_maps = [#map0, #map1, #map2, #map3],
   iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;reduction&quot;]}
   ins(%A, %B, %2 : tensor&lt;16x256xf32&gt;, tensor&lt;256x32xf32&gt;, tensor&lt;64x4xi1&gt;)
   outs(%1 : tensor&lt;16x32x64xf32&gt;) {
     ^bb0(%arg3: f32, %arg4: f32, %arg5: i1, %arg6: f32):
       %5 = arith.mulf %arg3, %arg4 : f32
       %6 = arith.addf %arg6, %5 : f32
       linalg.yield %6 : f32
 } -&gt; tensor&lt;16x32x64xf32&gt;

 %4 = linalg.generic {indexing_maps = [#map4, #map5],
   iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;, &quot;reduction&quot;]}
   ins(%3 : tensor&lt;16x32x64xf32&gt;)
   outs(%C : tensor&lt;16x32xf32&gt;) {
     ^bb0(%arg3: f32, %arg4: f32):
       %5 = arith.addf %arg3, %arg4 : f32
       linalg.yield %5 : f32
 } -&gt; tensor&lt;16x32xf32&gt;

 return %4 : tensor&lt;16x32xf32&gt;
</code></pre><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-46>Attributes:&nbsp;<a class=headline-hash href=#attributes-46>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>split_factor</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>insert_split_dimension</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>inner_parallel</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>use_scaling_algorithm</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>use_alloc</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-73>Operands:&nbsp;<a class=headline-hash href=#operands-73>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-61>Results:&nbsp;<a class=headline-hash href=#results-61>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>init_or_alloc_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>fill_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>split_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>combining_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredtile-mlirtransformtileop><code>transform.structured.tile</code> (::mlir::transform::TileOp)&nbsp;<a class=headline-hash href=#transformstructuredtile-mlirtransformtileop>¶</a></h3><p>Indicates that the given <code>target</code> op should be tiled with the given sizes.
This transform generates a loop nest with a smaller (&ldquo;tiled&rdquo;) target
operation in its body. Currently limited to LinalgOps.</p><p>Tile sizes may be known at transformation time, in which case they are
expected to be provided in the <code>static_size</code> attribute, or not, in which
case the tile value must be computed by the payload IR and the handle to the
operation computing it must be provided through <code>dynamic_sizes</code>. When the
sizes are not known statically, the corresponding entry in the
<code>static_sizes</code> attribute must be set to <code>ShapedType::kDynamic</code>. Only
the dynamic sizes must be provided in <code>dynamic_sizes</code>, i.e., there should
be as many handles as <code>ShapedType::kDynamic</code> values in the
<code>static_sizes</code> attribute. A static size of <code>0</code> indicates that the dimension
should not be tiled. No loop will be generated for such dimensions. If all
tile sizes are <code>0</code>, this transform is effectively a no-op.</p><p>This op returns handles to the tiled op (in the generated loop nest) and the
generated loops. The number of loops is the number of tile sizes that are
statically known to be non-zero.</p><h4 id=return-modes-48>Return modes&nbsp;<a class=headline-hash href=#return-modes-48>¶</a></h4><p>On success, the resulting handles are associated with co-indexed lists of
tiled operations and loops around them.</p><p>This operation only supports Linalg ops and produces a silenceable failure
if the input contains any non-Linalg ops. The ops preceding it in the list
associated with the <code>target</code> handle will have been tiled.</p><p>This operation produces a silenceable failure if the <code>dynamic_sizes</code> handles
are associated with lists of payload operations of a size different than
that of the list associated with the <code>target</code> handle.</p><p>If the internal implementation of tiling for any of the operations fails,
produces a definite failure.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-47>Attributes:&nbsp;<a class=headline-hash href=#attributes-47>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>interchange</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-74>Operands:&nbsp;<a class=headline-hash href=#operands-74>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>dynamic_sizes</code></td><td>transform &lsquo;param&rsquo; type or any handle type</td></tr></tbody></table><h4 id=results-62>Results:&nbsp;<a class=headline-hash href=#results-62>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tiled_linalg_op</code></td><td>TransformHandleTypeInterface instance</td></tr><tr><td style=text-align:center><code>loops</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformstructuredtile_reduction_using_forall-mlirtransformtilereductionusingforallop><code>transform.structured.tile_reduction_using_forall</code> (::mlir::transform::TileReductionUsingForallOp)&nbsp;<a class=headline-hash href=#transformstructuredtile_reduction_using_forall-mlirtransformtilereductionusingforallop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.tile_reduction_using_forall` $target
              `by`
              (`num_threads` `=` $num_threads^)?
              (`,` `tile_sizes` `=` $tile_sizes^)?
              (`,` `mapping` `=` $mapping^)?
              attr-dict
</code></pre><p>Tile a PartialReductionOpInterface op to a tiled <code>scf.forall</code> doing
partial reduction.</p><p>This transformation tiles the <code>target</code> along the reduction dimensions. It
creates a tensor initialized with the identity value. Then it creates a
<code>scf.forall</code> loops with the number threads given by <code>num_threads</code>.
The op is tiled op with a size equal to <code>floordiv(size, num_threads)</code>.
All the partial reduction value is are parallel inserted to create a new
tensor. After the loop a merge operation is created to do a final reduction
with the partial reductions tensor.
If an extra <code>tile_sizes</code> parameter is passed the tiles are cyclically
distributed on the threads of the <code>scf.foralls</code> loop.</p><h4 id=return-modes-49>Return modes&nbsp;<a class=headline-hash href=#return-modes-49>¶</a></h4><p>This 4 returned handles point to:</p><ul><li>the parent forall op,</li><li>the fill op used to initialize the neutral element,</li><li>the parallel tiled op and</li><li>the result-combining op.</li></ul><h4 id=example-3>Example:&nbsp;<a class=headline-hash href=#example-3>¶</a></h4><pre><code>  %red = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;,
                                          affine_map&lt;(d0, d1) -&gt; (d0)&gt;],
  iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]}
  ins(%arg0 : tensor&lt;?x?xf32&gt;)
  outs(%out : tensor&lt;?xf32&gt;) {
    ^bb0(%arg7: f32, %arg9: f32):
    %1 = arith.addf %arg7, %arg9 : f32
    linalg.yield %1 : f32
  } -&gt; tensor&lt;?xf32&gt;
  return %red : tensor&lt;?xf32&gt;
</code></pre><p>is transformed into:</p><pre><code>  %0 = tensor.empty(%dim_1) : tensor&lt;?x5xf32&gt;
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor&lt;?x5xf32&gt;) -&gt; tensor&lt;?x5xf32&gt;
  %2 = scf.forall (%arg2) in (%c5) shared_outs(%arg3 = %1) -&gt; (tensor&lt;?x5xf32&gt;) {
    %4 = affine.min #map(%arg2)[%dim_0]
    %5 = affine.max #map1(%4)
    %extracted_slice = tensor.extract_slice %arg3[0, %arg2] [%dim, 1] [1, 1] : tensor&lt;?x5xf32&gt; to tensor&lt;?xf32&gt;
    %6 = affine.apply #map2(%arg2)[%dim_0]
    %extracted_slice_2 = tensor.extract_slice %arg0[0, %6] [%dim, %5] [1, 1] : tensor&lt;?x?xf32&gt; to tensor&lt;?x?xf32&gt;
    %extracted_slice_3 = tensor.extract_slice %extracted_slice[0] [%dim] [1] : tensor&lt;?xf32&gt; to tensor&lt;?xf32&gt;
    %7 = linalg.generic {indexing_maps = [#map3, #map4], iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]} ins(%extracted_slice_2 : tensor&lt;?x?xf32&gt;) outs(%extracted_slice_3 : tensor&lt;?xf32&gt;) {
    ^bb0(%in: f32, %out: f32):
      %9 = arith.addf %in, %out : f32
      linalg.yield %9 : f32
    } -&gt; tensor&lt;?xf32&gt;
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %7 into %arg3[0, %arg2] [%dim, 1] [1, 1] : tensor&lt;?xf32&gt; into tensor&lt;?x5xf32&gt;
    }
  } {mapping = []}
  %3 = linalg.generic {indexing_maps = [#map3, #map4], iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]} ins(%2 : tensor&lt;?x5xf32&gt;) outs(%arg1 : tensor&lt;?xf32&gt;) {
  ^bb0(%in: f32, %out: f32):
    %4 = arith.addf %in, %out : f32
    linalg.yield %4 : f32
  } -&gt; tensor&lt;?xf32&gt;
</code></pre><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-48>Attributes:&nbsp;<a class=headline-hash href=#attributes-48>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>num_threads</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>tile_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>mapping</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Device Mapping array attribute</td></tr></tbody></table><h4 id=operands-75>Operands:&nbsp;<a class=headline-hash href=#operands-75>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-63>Results:&nbsp;<a class=headline-hash href=#results-63>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>forall_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>fill_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>split_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>combining_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredtile_reduction_using_scf-mlirtransformtilereductionusingscfop><code>transform.structured.tile_reduction_using_scf</code> (::mlir::transform::TileReductionUsingScfOp)&nbsp;<a class=headline-hash href=#transformstructuredtile_reduction_using_scf-mlirtransformtilereductionusingscfop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.tile_reduction_using_scf` $target
              `by` `tile_sizes` `=` $tile_sizes
              attr-dict
</code></pre><p>Indicates that the given <code>target</code> op should be transformed with the
<code>tileReduction</code> transformation with the tile size provided as attribute.</p><p>This transformation tiles the <code>target</code> along the reduction dimensions. It
creates a tensor initialized with the identity value. Then it creates nested
loops with a parallel version of <code>target</code> op inside. The parallel op
dimensions are less or equal to the tile size passed by user.
After the loop a merge operation is created to do a final reduction with the
partial reductions.
The initial tensor always uses the tile size dimension. This may overallocate
if the tile size is greater than the reduction dimension.</p><h4 id=return-modes-50>Return modes&nbsp;<a class=headline-hash href=#return-modes-50>¶</a></h4><p>This 4 returned handles point to:</p><ul><li>the parent for op,</li><li>the fill op used to initialize the neutral element,</li><li>the parallel tiled op and</li><li>the result-combining op.</li></ul><h4 id=example-4>Example:&nbsp;<a class=headline-hash href=#example-4>¶</a></h4><pre><code>  %red = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;,
                                          affine_map&lt;(d0, d1) -&gt; (d0)&gt;],
  iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]}
  ins(%arg0 : tensor&lt;?x?xf32&gt;)
  outs(%out : tensor&lt;?xf32&gt;) {
    ^bb0(%arg7: f32, %arg9: f32):
    %1 = arith.addf %arg7, %arg9 : f32
    linalg.yield %1 : f32
  } -&gt; tensor&lt;?xf32&gt;
  return %red : tensor&lt;?xf32&gt;
</code></pre><p>is transformed into:</p><pre><code>  %0 = tensor.empty(%dim_1) : tensor&lt;?x5xf32&gt;
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor&lt;?x5xf32&gt;) -&gt; tensor&lt;?x5xf32&gt;
  %2 = scf.for %arg2 = %c0 to %dim_0 step %c5 iter_args(%arg3 = %1) -&gt; (tensor&lt;?x5xf32&gt;) {
    %extracted_slice = tensor.extract_slice %1[0, 0] [%dim, 5] [1, 1] : tensor&lt;?x5xf32&gt; to tensor&lt;?x5xf32&gt;
    %extracted_slice_2 = tensor.extract_slice %arg0[0, %arg2] [%dim, 5] [1, 1] : tensor&lt;?x?xf32&gt; to tensor&lt;?x5xf32&gt;
    %4 = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;,
                                          affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;],
    iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;]}
    ins(%extracted_slice_2 : tensor&lt;?x5xf32&gt;)
    outs(%extracted_slice : tensor&lt;?x5xf32&gt;) {
    ^bb0(%in: f32, %out: f32):
      %5 = arith.addf %in, %out : f32
      linalg.yield %5 : f32
    } -&gt; tensor&lt;?x5xf32&gt;
    %dim_3 = tensor.dim %1, %c0 : tensor&lt;?x5xf32&gt;
    %inserted_slice = tensor.insert_slice %4 into %arg3[0, 0] [%dim_3, 5] [1, 1] : tensor&lt;?x5xf32&gt; into tensor&lt;?x5xf32&gt;
    scf.yield %inserted_slice : tensor&lt;?x5xf32&gt;
  }
  %3 = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;,
                                        affine_map&lt;(d0, d1) -&gt; (d0)&gt;],
  iterator_types = [&quot;parallel&quot;, &quot;reduction&quot;]}
  ins(%2 : tensor&lt;?x5xf32&gt;)
  outs(%arg1 : tensor&lt;?xf32&gt;) {
  ^bb0(%in: f32, %out: f32):
    %4 = arith.addf %in, %out : f32
    linalg.yield %4 : f32
  } -&gt; tensor&lt;?xf32&gt;
</code></pre><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-49>Attributes:&nbsp;<a class=headline-hash href=#attributes-49>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tile_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-76>Operands:&nbsp;<a class=headline-hash href=#operands-76>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-64>Results:&nbsp;<a class=headline-hash href=#results-64>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>for_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>fill_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>split_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>combining_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredtile_to_forall_op-mlirtransformtiletoforallop><code>transform.structured.tile_to_forall_op</code> (::mlir::transform::TileToForallOp)&nbsp;<a class=headline-hash href=#transformstructuredtile_to_forall_op-mlirtransformtiletoforallop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.tile_to_forall_op` $target oilist(
              `num_threads` custom&lt;PackedOrDynamicIndexList&gt;($packed_num_threads,
              $num_threads,
              $static_num_threads) |
              `tile_sizes` custom&lt;PackedOrDynamicIndexList&gt;($packed_tile_sizes,
              $tile_sizes,
              $static_tile_sizes))
              (`(` `mapping` `=` $mapping^ `)`)? attr-dict
</code></pre><p>Tile a TilingInterface op to a tiled <code>scf.forall</code>.</p><p>Tiling is applied by either specifying <code>num_threads</code> or <code>tile_size</code>. If
<code>num_threads</code> is specified, then the tile size for each dimension <code>i</code> is
calculated dynamically via <code>ceilDiv(dimSize[i], num_threads[i])</code>.
<code>num_threads</code> and <code>tile_size</code> can be either static index attributes or SSA
values of PDL operation handle type (or a mix thereof). Operation handles
must be mapped to exactly one op that has exactly one result of index type.</p><p>Static zero tile sizes indicate that the dimension is not tiled and can be
thought of as tiling by the full size of data.</p><p>It is the user&rsquo;s responsibility to ensure that <code>num_threads/tile_sizes</code> is
a valid tiling specification (i.e. that only tiles parallel dimensions,
e.g. in the Linalg case).</p><p>If non-empty, the <code>mapping</code> is added as an attribute to the
resulting <code>scf.forall</code>.</p><p>Note: <code>tile_sizes</code> and <code>num_threads</code> are variadic. Each tile size/number of
threads can be an index attribute or a transform handle that is mapped to
exactly one payload op with exactly one index result.</p><h4 id=return-modes-51>Return modes&nbsp;<a class=headline-hash href=#return-modes-51>¶</a></h4><p>This operation ignores ops that do not implement the TilingInterface and
drops them in the return.</p><p>If all the operations referred to by the <code>target</code> PDLOperation tile
successfully, the transform succeeds.
Otherwise the transform silently fails.</p><p>The two returned handles point to only the subset of successfully produced
tiled operations, which can all be empty.</p><p>These two returned handles point to:</p><ul><li>the new scf.forall op,</li><li>the tiled op that implements TilingInterface.</li></ul><h4 id=example-using-num_threads>Example using <code>num_threads</code>&nbsp;<a class=headline-hash href=#example-using-num_threads>¶</a></h4><pre><code>%0 = pdl_match @match_matmul in %arg1
%3:2 = transform.structured.tile_to_forall_op %0 num_threads [10, 20]
</code></pre><h4 id=example-using-tile_sizes>Example using <code>tile_sizes</code>&nbsp;<a class=headline-hash href=#example-using-tile_sizes>¶</a></h4><pre><code>%0 = pdl_match @match_matmul in %arg1
%sz = pdl_match @match_size_op in %arg1
%3:2 = transform.structured.tile_to_forall_op %0 tile_sizes [0, %sz, 20]
</code></pre><p>Traits: AttrSizedOperandSegments</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-50>Attributes:&nbsp;<a class=headline-hash href=#attributes-50>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_num_threads</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>static_tile_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>mapping</code></td><td style=text-align:center>::mlir::ArrayAttr</td><td>Device Mapping array attribute</td></tr></tbody></table><h4 id=operands-77>Operands:&nbsp;<a class=headline-hash href=#operands-77>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>num_threads</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>tile_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>packed_num_threads</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>packed_tile_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-65>Results:&nbsp;<a class=headline-hash href=#results-65>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>forall_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>tiled_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredtile_to_scf_for-mlirtransformtiletoscfforop><code>transform.structured.tile_to_scf_for</code> (::mlir::transform::TileToScfForOp)&nbsp;<a class=headline-hash href=#transformstructuredtile_to_scf_for-mlirtransformtiletoscfforop>¶</a></h3><p>Indicates that the given <code>target</code> op should be tiled with the given sizes.
This transform generates a loop nest with a smaller (&ldquo;tiled&rdquo;) target
operation in its body. The target must implement TilingInterface.</p><p>Tile sizes may be known at transformation time, in which case they are
expected to be provided in the <code>static_size</code> attribute, or not, in which
case the tile value must be computed by the payload IR and the handle to the
operation computing it must be provided through <code>dynamic_sizes</code>. When the
sizes are not known statically, the corresponding entry in the
<code>static_sizes</code> attribute must be set to <code>ShapedType::kDynamic</code>. Only
the dynamic sizes must be provided in <code>dynamic_sizes</code>, i.e., there should
be as many handles as <code>ShapedType::kDynamic</code> values in the
<code>static_sizes</code> attribute. A static size of <code>0</code> indicates that the dimension
should not be tiled. No loop will be generated for such dimensions. If all
tile sizes are <code>0</code>, this transform is effectively a no-op.</p><p>This op returns handles to the tiled op (in the generated loop nest) and the
generated loops. The number of loops is the number of tile sizes that are
statically known to be non-zero.</p><h4 id=return-modes-52>Return modes&nbsp;<a class=headline-hash href=#return-modes-52>¶</a></h4><p>On success, the resulting handles are associated with co-indexed lists of
tiled operations and loops around them.</p><p>This operation only supports TilingInterface ops and produces a silenceable
failure if the input contains any non-TilingInterface ops. The ops preceding
it in the list associated with the <code>target</code> handle will have been tiled.</p><p>This operation produces a silenceable failure if the <code>dynamic_sizes</code> handles
are associated with lists of payload operations of a size different than
that of the list associated with the <code>target</code> handle.</p><p>If the internal implementation of tiling for any of the operations fails,
produces a definite failure.</p><p>Interfaces: MemoryEffectOpInterface, TransformOpInterface</p><h4 id=attributes-51>Attributes:&nbsp;<a class=headline-hash href=#attributes-51>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>static_sizes</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td style=text-align:center><code>interchange</code></td><td style=text-align:center>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></tbody></table><h4 id=operands-78>Operands:&nbsp;<a class=headline-hash href=#operands-78>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>dynamic_sizes</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-66>Results:&nbsp;<a class=headline-hash href=#results-66>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tiled_linalg_op</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr><tr><td style=text-align:center><code>loops</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h3 id=transformstructuredvectorize-mlirtransformvectorizeop><code>transform.structured.vectorize</code> (::mlir::transform::VectorizeOp)&nbsp;<a class=headline-hash href=#transformstructuredvectorize-mlirtransformvectorizeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.structured.vectorize` $target attr-dict
</code></pre><p>Indicates that the given <code>target</code> op all the ops it contains should be
vectorized with the configuration specified by the attributes of this op.
This vectorization only handles structured ops that operate on shaped types
and does not vectorize loops or straight-line. Internally, it applies a
set of rewrite patterns, some of which enable vectorization and some of
which clean up the results. Therefore, it can only be applied to an op with
the &ldquo;isolated from above property&rdquo;. If finer granularity is required, it can
be achieved by outlining the target part of the payload IR into, e.g., a
function, performing the transformation, and inlining it back. This
transformation only fails if the entire pattern rewriting failed, i.e., it
does <strong>not</strong> fail when no ops were vectorized.</p><p>Note that this transformation is invalidating the handles to any payload IR
operation that is contained inside the vectorization target.</p><p>This transformation supports the following attributes:</p><ul><li><code>vectorize_padding</code>: a UnitAttr to activate the vectorization of
<code>tensor.pad</code> ops. Different pipelines may prefer to lower such ops to
loops.</li><li><code>disable_multi_reduction_to_contract_patterns</code>: a UnitAttr to deactivate
the rewrite of <code>vector.multi_reduction</code> to <code>vector.contract</code>. This is
intended to be used in tests only.</li><li><code>disable_transfer_permutation_map_lowering_patterns</code>: a UnitAttr to
deactivate the rewrite of <code>vector.transfer</code> with permutation maps into
explicit <code>vector.transpose</code> operations. This is intended to be used in
tests only but may be promotoed to a first class attribute in the future.</li></ul><h4 id=return-modes-53>Return modes:&nbsp;<a class=headline-hash href=#return-modes-53>¶</a></h4><p>This operation produces <code>definiteFailure</code> if vectorization fails for any
reason.
The operation always returns the handle to the target op that is expected
to be isolated from above.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-52>Attributes:&nbsp;<a class=headline-hash href=#attributes-52>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vectorize_padding</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>vectorize_nd_extract</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>disable_multi_reduction_to_contract_patterns</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td style=text-align:center><code>disable_transfer_permutation_map_lowering_patterns</code></td><td style=text-align:center>::mlir::UnitAttr</td><td>unit attribute</td></tr></tbody></table><h4 id=operands-79>Operands:&nbsp;<a class=headline-hash href=#operands-79>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h4 id=results-67>Results:&nbsp;<a class=headline-hash href=#results-67>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>transformed</code></td><td>PDL handle to an <code>mlir::Operation *</code></td></tr></tbody></table><h2 id=vector-transform-operations>Vector Transform Operations&nbsp;<a class=headline-hash href=#vector-transform-operations>¶</a></h2><h3 id=transformvectorapply_rank_reducing_subview_patterns-mlirtransformapplyrankreducingsubviewpatternsop><code>transform.vector.apply_rank_reducing_subview_patterns</code> (::mlir::transform::ApplyRankReducingSubviewPatternsOp)&nbsp;<a class=headline-hash href=#transformvectorapply_rank_reducing_subview_patterns-mlirtransformapplyrankreducingsubviewpatternsop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.apply_rank_reducing_subview_patterns` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Apply opt-in vector transfer permutation patterns that include:</p><ul><li>TransferReadDropUnitDimsPattern</li><li>TransferWriteDropUnitDimsPattern</li></ul><p>These patterns have the effect of rewriting a vector.transfer with unit
dimensions into a rank-reduced version thanks to subview operations.
This is complemented by shape_cast folding patterns.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-80>Operands:&nbsp;<a class=headline-hash href=#operands-80>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-68>Results:&nbsp;<a class=headline-hash href=#results-68>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorapply_transfer_permutation_patterns-mlirtransformapplytransferpermutationpatternsop><code>transform.vector.apply_transfer_permutation_patterns</code> (::mlir::transform::ApplyTransferPermutationPatternsOp)&nbsp;<a class=headline-hash href=#transformvectorapply_transfer_permutation_patterns-mlirtransformapplytransferpermutationpatternsop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.apply_transfer_permutation_patterns` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Apply opt-in vector transfer permutation patterns that include:</p><ul><li>TransferReadPermutationLowering</li><li>TransferWritePermutationLowering</li><li>TransferOpReduceRank</li><li>TransferWriteNonPermutationLowering</li></ul><p>These patterns have the effect of rewriting a vector.transfer with an
arbitrary permutation_map to a vector.transfer with a permutation_map that is
a minor identity followed by a vector.transpose.</p><p>In other words, this makes the vector.transfer contiguous on the most minor
dimensions and materializes the permutation_map as a vector.transpose.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-81>Operands:&nbsp;<a class=headline-hash href=#operands-81>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-69>Results:&nbsp;<a class=headline-hash href=#results-69>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_broadcast-mlirtransformlowerbroadcastop><code>transform.vector.lower_broadcast</code> (::mlir::transform::LowerBroadcastOp)&nbsp;<a class=headline-hash href=#transformvectorlower_broadcast-mlirtransformlowerbroadcastop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_broadcast` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector outerproduct operations nested under the isolated
from above op <code>target</code> should be lowered to finer-grained vector primitives.</p><p>This is usally a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-82>Operands:&nbsp;<a class=headline-hash href=#operands-82>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-70>Results:&nbsp;<a class=headline-hash href=#results-70>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_contraction-mlirtransformlowercontractionop><code>transform.vector.lower_contraction</code> (::mlir::transform::LowerContractionOp)&nbsp;<a class=headline-hash href=#transformvectorlower_contraction-mlirtransformlowercontractionop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_contraction` $target
              (`lowering_strategy` `=` $lowering_strategy^)?
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector contraction-like operations nested under the
isolated from above op <code>target</code> should be lowered to finer-grained vector
primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-53>Attributes:&nbsp;<a class=headline-hash href=#attributes-53>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lowering_strategy</code></td><td style=text-align:center>::mlir::vector::VectorContractLoweringAttr</td><td>control the lowering of <code>vector.contract</code> operations.</td></tr></tbody></table><h4 id=operands-83>Operands:&nbsp;<a class=headline-hash href=#operands-83>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-71>Results:&nbsp;<a class=headline-hash href=#results-71>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_masked_transfers-mlirtransformlowermaskedtransfersop><code>transform.vector.lower_masked_transfers</code> (::mlir::transform::LowerMaskedTransfersOp)&nbsp;<a class=headline-hash href=#transformvectorlower_masked_transfers-mlirtransformlowermaskedtransfersop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_masked_transfers` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that masked vector.transfer and vector.gather operations nested
under the isolated from above op <code>target</code> should be lowered to finer-grained
vector primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-84>Operands:&nbsp;<a class=headline-hash href=#operands-84>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-72>Results:&nbsp;<a class=headline-hash href=#results-72>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_masks-mlirtransformlowermasksop><code>transform.vector.lower_masks</code> (::mlir::transform::LowerMasksOp)&nbsp;<a class=headline-hash href=#transformvectorlower_masks-mlirtransformlowermasksop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_masks` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector.create_mask and vector.constant_mask operations
nested under the isolated from above op <code>target</code> should be lowered to
finer-grained vector primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-85>Operands:&nbsp;<a class=headline-hash href=#operands-85>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-73>Results:&nbsp;<a class=headline-hash href=#results-73>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_multi_reduction-mlirtransformlowermultireductionop><code>transform.vector.lower_multi_reduction</code> (::mlir::transform::LowerMultiReductionOp)&nbsp;<a class=headline-hash href=#transformvectorlower_multi_reduction-mlirtransformlowermultireductionop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_multi_reduction` $target
              (`lowering_strategy` `=` $lowering_strategy^)?
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector multi_reduction-like operations nested under the
isolated from above op <code>target</code> should be lowered to finer-grained vector
primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-54>Attributes:&nbsp;<a class=headline-hash href=#attributes-54>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lowering_strategy</code></td><td style=text-align:center>::mlir::vector::VectorMultiReductionLoweringAttr</td><td>control the lowering of <code>vector.multi_reduction</code>.</td></tr></tbody></table><h4 id=operands-86>Operands:&nbsp;<a class=headline-hash href=#operands-86>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-74>Results:&nbsp;<a class=headline-hash href=#results-74>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_outerproduct-mlirtransformlowerouterproductop><code>transform.vector.lower_outerproduct</code> (::mlir::transform::LowerOuterProductOp)&nbsp;<a class=headline-hash href=#transformvectorlower_outerproduct-mlirtransformlowerouterproductop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_outerproduct` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector outerproduct operations nested under the isolated
from above op <code>target</code> should be lowered to finer-grained vector primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-87>Operands:&nbsp;<a class=headline-hash href=#operands-87>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-75>Results:&nbsp;<a class=headline-hash href=#results-75>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_shape_cast-mlirtransformlowershapecastop><code>transform.vector.lower_shape_cast</code> (::mlir::transform::LowerShapeCastOp)&nbsp;<a class=headline-hash href=#transformvectorlower_shape_cast-mlirtransformlowershapecastop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_shape_cast` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector shape_cast operations nested under the
isolated from above op <code>target</code> should be lowered to finer-grained vector
primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-88>Operands:&nbsp;<a class=headline-hash href=#operands-88>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-76>Results:&nbsp;<a class=headline-hash href=#results-76>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_transfer-mlirtransformlowertransferop><code>transform.vector.lower_transfer</code> (::mlir::transform::LowerTransferOp)&nbsp;<a class=headline-hash href=#transformvectorlower_transfer-mlirtransformlowertransferop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_transfer` $target
              (`max_transfer_rank` `=` $max_transfer_rank^)?
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector transfer operations nested under the
isolated from above op <code>target</code> should be lowered to finer-grained vector
primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-55>Attributes:&nbsp;<a class=headline-hash href=#attributes-55>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>max_transfer_rank</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></tbody></table><h4 id=operands-89>Operands:&nbsp;<a class=headline-hash href=#operands-89>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-77>Results:&nbsp;<a class=headline-hash href=#results-77>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorlower_transpose-mlirtransformlowertransposeop><code>transform.vector.lower_transpose</code> (::mlir::transform::LowerTransposeOp)&nbsp;<a class=headline-hash href=#transformvectorlower_transpose-mlirtransformlowertransposeop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.lower_transpose` $target
              oilist (
              `lowering_strategy` `=` $lowering_strategy
              | `avx2_lowering_strategy` `=` $avx2_lowering_strategy
              )
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector transpose-like operations nested under the
isolated from above op <code>target</code> should be lowered to finer-grained vector
primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-56>Attributes:&nbsp;<a class=headline-hash href=#attributes-56>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lowering_strategy</code></td><td style=text-align:center>::mlir::vector::VectorTransposeLoweringAttr</td><td>control the lowering of <code>vector.transpose</code> operations.</td></tr><tr><td style=text-align:center><code>avx2_lowering_strategy</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-90>Operands:&nbsp;<a class=headline-hash href=#operands-90>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-78>Results:&nbsp;<a class=headline-hash href=#results-78>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectormaterialize_masks-mlirtransformmaterializemasksop><code>transform.vector.materialize_masks</code> (::mlir::transform::MaterializeMasksOp)&nbsp;<a class=headline-hash href=#transformvectormaterialize_masks-mlirtransformmaterializemasksop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.materialize_masks` $target
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that mask operations nested under the isolated from above op
<code>target</code> should be lowered to fine-grained arithemtic operations.</p><p>This is usually the last step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=operands-91>Operands:&nbsp;<a class=headline-hash href=#operands-91>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-79>Results:&nbsp;<a class=headline-hash href=#results-79>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectorsplit_transfer_full_partial-mlirtransformsplittransferfullpartialop><code>transform.vector.split_transfer_full_partial</code> (::mlir::transform::SplitTransferFullPartialOp)&nbsp;<a class=headline-hash href=#transformvectorsplit_transfer_full_partial-mlirtransformsplittransferfullpartialop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.split_transfer_full_partial` $target
              (`split_transfer_strategy` `=` $split_transfer_strategy^)?
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector transfer operations nested under the
isolated from above op <code>target</code> should be split to full and partial parts.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-57>Attributes:&nbsp;<a class=headline-hash href=#attributes-57>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>split_transfer_strategy</code></td><td style=text-align:center>::mlir::vector::VectorTransferSplitAttr</td><td>control the splitting of <code>vector.transfer</code> operations into in-bounds and out-of-bounds variants.</td></tr></tbody></table><h4 id=operands-92>Operands:&nbsp;<a class=headline-hash href=#operands-92>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-80>Results:&nbsp;<a class=headline-hash href=#results-80>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h3 id=transformvectortransfer_to_scf-mlirtransformtransfertoscfop><code>transform.vector.transfer_to_scf</code> (::mlir::transform::TransferToScfOp)&nbsp;<a class=headline-hash href=#transformvectortransfer_to_scf-mlirtransformtransfertoscfop>¶</a></h3><p>Syntax:</p><pre><code>operation ::= `transform.vector.transfer_to_scf` $target
              oilist (
              `max_transfer_rank` `=` $max_transfer_rank
              | `full_unroll` `=` $full_unroll
              )
              attr-dict
              `:` functional-type($target, results)
</code></pre><p>Indicates that the vector transfer operations nested under the
isolated from above op <code>target</code> should be rewritten with scf.for loops over
finer-grained vector primitives.</p><p>This is usually a late step that is run after bufferization as part of the
process of lowering to e.g. LLVM or NVVM.</p><p>Traits: FunctionalStyleTransformOpTrait, TransformEachOpTrait, TransformWithPatternsOpTrait</p><p>Interfaces: MemoryEffectsOpInterface, TransformOpInterface</p><h4 id=attributes-58>Attributes:&nbsp;<a class=headline-hash href=#attributes-58>¶</a></h4><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>max_transfer_rank</code></td><td style=text-align:center>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td style=text-align:center><code>full_unroll</code></td><td style=text-align:center>::mlir::BoolAttr</td><td>bool attribute</td></tr></tbody></table><h4 id=operands-93>Operands:&nbsp;<a class=headline-hash href=#operands-93>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>target</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h4 id=results-81>Results:&nbsp;<a class=headline-hash href=#results-81>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>TransformHandleTypeInterface instance</td></tr></tbody></table><h2 id=transformhandletypeinterface-transformhandletypeinterface>TransformHandleTypeInterface (<code>TransformHandleTypeInterface</code>)&nbsp;<a class=headline-hash href=#transformhandletypeinterface-transformhandletypeinterface>¶</a></h2><p>Types that can be used for the Transform dialect operation handle values.
Such types define the properties of Payload IR operations associated with
the handle. A user of such a handle can assume that these properties have
been verified for any Payload IR operation associated with it.</p><h3 id=methods>Methods:&nbsp;<a class=headline-hash href=#methods>¶</a></h3><h4 id=checkpayload><code>checkPayload</code>&nbsp;<a class=headline-hash href=#checkpayload>¶</a></h4><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>DiagnosedSilenceableFailure</span> <span class=n>checkPayload</span><span class=p>(</span><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Location</span> <span class=n>loc</span><span class=p>,</span> <span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>ArrayRef</span><span class=o>&lt;::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Operation</span> <span class=o>*&gt;</span> <span class=n>payload</span><span class=p>);</span>
</code></pre></div><p>Checks if the given associated objects (Payload IR operations or attributes)
satisfy the conditions defined by this type. If not, produces a silenceable
error at the specified location.</p><p>NOTE: This method <em>must</em> be implemented by the user.</p><h2 id=transformparamtypeinterface-transformparamtypeinterface>TransformParamTypeInterface (<code>TransformParamTypeInterface</code>)&nbsp;<a class=headline-hash href=#transformparamtypeinterface-transformparamtypeinterface>¶</a></h2><p>Types that can be used for the Transform dialect parameter values. Such types
define the structure of the parameters associated with the value, e.g., their
underlying type. A user of the value can assume that the parameter has been
verified.</p><h3 id=methods-1>Methods:&nbsp;<a class=headline-hash href=#methods-1>¶</a></h3><h4 id=checkpayload-1><code>checkPayload</code>&nbsp;<a class=headline-hash href=#checkpayload-1>¶</a></h4><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>DiagnosedSilenceableFailure</span> <span class=n>checkPayload</span><span class=p>(</span><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Location</span> <span class=n>loc</span><span class=p>,</span> <span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>ArrayRef</span><span class=o>&lt;::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Attribute</span><span class=o>&gt;</span> <span class=n>payload</span><span class=p>);</span>
</code></pre></div><p>Checks if the given associated objects (Payload IR operations or attributes)
satisfy the conditions defined by this type. If not, produces a silenceable
error at the specified location.</p><p>NOTE: This method <em>must</em> be implemented by the user.</p><h2 id=transformvaluehandletypeinterface-transformvaluehandletypeinterface>TransformValueHandleTypeInterface (<code>TransformValueHandleTypeInterface</code>)&nbsp;<a class=headline-hash href=#transformvaluehandletypeinterface-transformvaluehandletypeinterface>¶</a></h2><p>Types that can be used for the Transform dialect handle values pointing to
Payload IR values. Such types define the properties of Payload IR values
associated with the handle. Users of such a handle can assume that these
properties have been verified for any Payload IR value associated with it.</p><h3 id=methods-2>Methods:&nbsp;<a class=headline-hash href=#methods-2>¶</a></h3><h4 id=checkpayload-2><code>checkPayload</code>&nbsp;<a class=headline-hash href=#checkpayload-2>¶</a></h4><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>DiagnosedSilenceableFailure</span> <span class=n>checkPayload</span><span class=p>(</span><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Location</span> <span class=n>loc</span><span class=p>,</span> <span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>ArrayRef</span><span class=o>&lt;::</span><span class=n>mlir</span><span class=o>::</span><span class=n>Value</span><span class=o>&gt;</span> <span class=n>payload</span><span class=p>);</span>
</code></pre></div><p>Checks if the given associated objects (Payload IR operations or attributes)
satisfy the conditions defined by this type. If not, produces a silenceable
error at the specified location.</p><p>NOTE: This method <em>must</em> be implemented by the user.</p><h2 id=transformopinterface-transformopinterface>TransformOpInterface (<code>TransformOpInterface</code>)&nbsp;<a class=headline-hash href=#transformopinterface-transformopinterface>¶</a></h2><p>This interface is to be implemented by operations that identify
transformations to be performed on other operations. The former are referred
to as transform IR operations. The latter are referred to as payload IR
operations. Such transform IR operations provide a fine-grain control
mechanism over how transformations are applied by using and defining
transform IR values, referred to as handles, that correspond to sets of
operations in the payload IR. Transformations are applied starting from the
operations identified by handles, but may affect other operations as well.
Further restrictions may be imposed by flows that rely on transform IR
operations to control transformations.</p><h3 id=methods-3>Methods:&nbsp;<a class=headline-hash href=#methods-3>¶</a></h3><h4 id=apply><code>apply</code>&nbsp;<a class=headline-hash href=#apply>¶</a></h4><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>DiagnosedSilenceableFailure</span> <span class=n>apply</span><span class=p>(</span><span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>transform</span><span class=o>::</span><span class=n>TransformResults</span> <span class=o>&amp;</span><span class=n>transformResults</span><span class=p>,</span> <span class=o>::</span><span class=n>mlir</span><span class=o>::</span><span class=n>transform</span><span class=o>::</span><span class=n>TransformState</span> <span class=o>&amp;</span><span class=n>state</span><span class=p>);</span>
</code></pre></div><p>Applies the transformation represented by the current operation. This
accepts as arguments the object that must be populated with results of
the current transformation and a transformation state object that can be
used for queries, e.g., to obtain the list of operations on which the
transformation represented by the current op is targeted. Returns a
special status object indicating whether the transformation succeeded
or failed, and, if it failed, whether the failure is recoverable or not.</p><p>NOTE: This method <em>must</em> be implemented by the user.</p><h4 id=allowsrepeatedhandleoperands><code>allowsRepeatedHandleOperands</code>&nbsp;<a class=headline-hash href=#allowsrepeatedhandleoperands>¶</a></h4><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=kt>bool</span> <span class=nf>allowsRepeatedHandleOperands</span><span class=p>();</span>
</code></pre></div><p>Indicates whether the op instance allows its handle operands to be
associated with the same payload operations.</p><p>NOTE: This method <em>must</em> be implemented by the user.</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Dialects/TOSA/ title="Tensor Operator Set Architecture (TOSA) Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Tensor Operator Set Architecture (TOSA) Dialect</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Interfaces/ title=Interfaces>Next - Interfaces <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/AMDGPUPasses/></a></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/TensorTransformOps/></a></li><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li class=active><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=https://mlir.llvm.org/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>